[
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "D OMVS,O to chekc all the current options of OMVS env. and also the parmlibs used from IEASYSxx"
  },
  {
    "VendCor": "ibm",
    "component/product": "omvs",
    "type": "",
    "info": "super user batch -- ensure that your line numbers are not present in the JCL from 72 to 80 column.\r\nEnables super user in batch.\r\n//STEP1 EXEC PGM=BPXBATCH, \r\n// PARM='SH echo id | su' \r\n//*TEPLIB DD DSN=SYS1.SCEERUN,DISP=SHR \r\n//STDERR DD SYSOUT=* \r\n//STDOUT DD SYSOUT=* \r\n/* \r\n//STEP1 EXEC PGM=BPXBATCH \r\n//STDERR DD SYSOUT=* \r\n//STDOUT DD SYSOUT=* \r\n//STDPARM DD * \r\nSH  \r\necho id | su; \r\n/*"
  },
  {
    "Vendor": "IBM",
    "component/product": "Webserver",
    "type": "Ver check",
    "info": "STC IMW*"
  },
  {
    "Vendor": "ibm",
    "component/product": "abend",
    "type": "soc4",
    "info": "As a programmer, one of the major challenges we face is in the area of Storage Protection. It is a major way that z/OS maintains integrity of the system. So what is a Protection Exception (S0C4) and how can it exist, especially in the execution of a Cobol Program. Some background is needed. There are 16 Storage Protection keys in z/OS, numbered 0-15. z/OS Subsystems use keys 0-7, and keys 8-15 are for Users (Batch, TSO). JES2 uses key 1, MQ uses key 7 etc. Check the Program Properties Table in the SCHED00 in Sys1.Parmlib for more information. CICS uses key 8 and can use key 9 if Storage protection is enabled for that region. So every z/OS 4k Page has a number of bits associated with it. 4 of them are the Storage Protection bits. So when a MOVE in any program wants to move Working Storage data onto a Page, the Storage Protection bit assigned to that page is compared with the Storage Protection bit in the PSW. If they match, then the move is allowed to happen. So if we are a batch Cobol program in key 8, how can that move fail with an S0C4. I'll explain in the next part"
  },
  {
    "Vendor": "NETC /SDS",
    "component/product": "CAFC (CICS Application file control facility)",
    "type": "Ver check",
    "info": "Check in CICS region."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Common Services",
    "type": "commands",
    "info": "to find the verison if ENF is running then issue the command /ENF STATUS"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Common Services",
    "type": "components",
    "info": "if we have tasks running with PGM=JVMLDMxx then we can say that CA Common services is using APACHE TOMCAT."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Common Services",
    "type": "load module check",
    "info": "we can use the below jcl if we are running any CA products to check on the load modules versions and also figure out if maintenance is applied or not.\r\n//STEP1 EXEC PGM=IKJEFT01 \r\n//SYSTSPRT DD SYSOUT=* \r\n//SYSTSIN DD * \r\nCAMODID DSNAME(LIBSYS.LIBR.V44.LVL1.CALJLINK) DETAIL\r\n/* the module CAMODID is part of CA Common services."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Common Services",
    "type": "agent",
    "info": "to check if agent technology is running in ca-common services\r\nFrom a UNIX shell session or batch job with superuser privileges, issue \"ps -ef\" (or the z/OS command \"D OMVS,A=ALL\") and verify that these processes are running:\r\nEvent Management opr component requires caiopr, cailgr and newdaylog processes. Optionally, if store and forward is required, an oprsafd processing should be running.\r\nStar component requires stardaemon process\r\nCalendar component requires calendar process\r\nJava running class CA.Unicenter.comm.w2RmiServerImp\r\nlogonserver.exe\r\nw2Tree.exe\r\nCaemRtS\r\nEMServer.exe\r\nAgent Technologies:\r\nAre all the required processes running?\r\nFull Agent Technology requires awservices, aws_orb and aws_sadmin processes to be running. From a UNIX shell session or batch job with superuser (su) privileges, issue \"ps - ef\" (or the z/OS command \"D OMVS,A=ALL\") and verify that these processes are running."
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "recycle",
    "info": "You can use the ps -ef command to list all the java processes that are running and find the Process ID (PID) of the DataReceiver process.\r\n To shutdown the process submit kill \"PID\"\r\n 2. run the startup script in /opt/CDPz directory called startup_cdpz.bash"
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "commands",
    "info": "f cdpsmfde,display status -- smf cdp status -- tells us the no. of records that got recrods and sent for data streamer for ftp"
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "issues",
    "info": "issue : on one system the custom written SMF70 records are being captured. the same policy used in other plex systems is capturing the recrods.\r\nRes: I was able to resolve the issue and the records are being captured now. we have smf exits 83,84,85,96 active on the MM99 system though not shown in D SMF,O output. But they are active through exit definition in PROGxx I believe. I have updated the HBO exit for all the 83,84,85,86 exits and then it started working."
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "issues",
    "info": "issue : Not able to get data on the splunk side when using REXX API. i ran the default REXX API itself.\r\nREs : In the meta data missed the line item APP/stream name"
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "issues",
    "info": "issue: Datastreamer not able to establish connection with splunk server\r\nHBO6058E A connection to glat.mmm.com : 51401 cannot be established.\r\nREs : found that the TCPARMS had IPSECURE and FWSECURE turned one and so we were not able to connect to the splunk server."
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "issues",
    "info": "issue : IBM CDP not transferring data to splunk.\r\nwe are running logforwarder and datastreamer and trying to send data to splunk. but data is not seen on splunk server.\r\nRes: splunk team update some java on splunk to java 8 and we were able to see some files. we will work for couple of more days and if we are able to see all the data, we can close this ticket."
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "program issues",
    "info": "1. SUM( ) -- is adding the last value again. Kind of doubling or adding one more time\r\n2. Not able to use same condition for 2 differnt calculation in the same sections.\r\nEx : the below condition fails with U0002 -- so we need to create to seperate sections to calculate these values.\r\nED_TIME = CASE WHEN SMF70CIX = 1 THEN SMF70EDT ELSE 0.00000000 END and TD_TIME = CASE WHEN SMF70CIX = 1 THEN SMF70PDT ELSE 0.00000000 END"
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "joblog",
    "info": "to read joblogs directly use the CRLF splitter"
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "policy",
    "info": "only when a splitter option is selected we can select a subscriber to send the data"
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "Logforwarder",
    "info": "error when trying to start teh logforwarder.\r\ncommon stroage not available. Check if the log forwarder exits are enabled."
  },
  {
    "Vendor": "IBM",
    "component/product": "cdp",
    "type": "config",
    "info": "regex filter. we cannot use $HASP100 as the Filter as \"$\" is the special char in Regex and it asserts position at the end of a line. So filter doesn't found HASP100 in the line. You need to change the expression to:\r\n[$]HASP100"
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "checks",
    "info": "Line entries -- this message in the Data streamer task will tell us how many lines are being written to splunk when in every set of data that it writes."
  },
  {
    "Vendor": "ibm",
    "component/product": "CEA",
    "type": "setup",
    "info": "CEA - Common even adapter. It is a system task and is automatically started during the IPL. Check the IPL log to find the proc it is executing and look for the proc for its setup."
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "logon",
    "info": "CESN-- supports 8 char password. CESL supports password phrase."
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "commands",
    "info": "CEOT -- display your terminal information."
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "commands",
    "info": "CMSG -- send messages to other terminal users in CICS"
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "commands",
    "info": "CMSG R=ALL,‘GOOD MORNING#TODAY IS FRIDAY FEB 1',S"
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "commands",
    "info": "CEDF -- working on terminal and trying to debug an application"
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "commands",
    "info": "CEDX -- working in a web based application and trying to debug."
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "commands",
    "info": "set prog(xxx) newcopy -- to update the program in cics memory"
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "commands",
    "info": "CEDA/CEDB/CEDC -- Activate,define,update,view"
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "svc issue",
    "info": "if we need to update or dynamically load a CICS SVC. Use the below jcl\r\n//SVCUPD EXEC PGM=DFHCSVCU,PARM=('SVC216=DFHCSVC')\r\n//STEPIB DD DISP=SHR,DSN=**.SDFHAUTH"
  },
  {
    "Vendor": "cloud compiler",
    "component/product": "cloud compiler",
    "type": "notes",
    "info": "cloud compiler works in 2 ways: 1) we have our own compiler on a small system and install cloud compiler on all the remaining systems and it would send all our compile jobs to the small system and get back our compiled output to the submitting system.\r\n 2)we can install cloud compiler and setitup to use the vendors cloud system to do the compiles. here we install the product on ht mainfram and configure to send our compile jcl to vendor system through net and get the compiled output back to our system."
  },
  {
    "Vendor": "ibm",
    "component/product": "cobol",
    "type": "",
    "info": "JCL To get a load module from COBOL source code.\r\n//STEP1 EXEC IGYCRCTL,PARM=RMODE,DYNAM,SSRANGE //SYSIN DD DISP=SHR,DSN=SYS5.CTS.JCL.SMF.CNTL(SMFJZIPP) //SYSLMOD DD DISP=SHR,DSN=SYS5.CTS.COBOL.SMF.LOAD(SMFJZIPP) //SYSPRINT DD SYSOUT=* //*"
  },
  {
    "Vendor": "ibm",
    "component/product": "COBOL",
    "type": "reserved words",
    "info": "You can get the full list from *.SIGYSAMP(IGY8RWRD) in V4.2 and *.SIGYSAMP(IGY8RWRD) in V6.2"
  },
  {
    "Vendor": "ibm",
    "component/product": "cobol",
    "type": "performance",
    "info": "The ARCH parm is what we used for Cobol 6.2. Till 6.1 ARCH(10) was used and from 6.2 ARCH(12) can be used while doing the compiles and it really saves CPU if the code is having more computational statements rather than I/O Statements. This ARCH parm exploits z13, z14 Hardware Upgrades and changes at the hardware Level"
  },
  {
    "Vendor": "ibm",
    "component/product": "cobol",
    "type": "modernization",
    "info": "https://www.gotostage.com/channel/7df10b0b81334df9afe1838c006b1d94"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Common Services",
    "type": "Ver check",
    "info": "Look for ENF* STC or CAS9 * STC - CAS9075I"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "common services",
    "type": "components",
    "info": "CA Global Subsystem : is a support services component that provides a simplified communication interface. This\r\ninterface lets various CA products communicate easily, seamlessly, and reliably, allowing quick access to information from various sources. CA GSS provides connectivity by using a collection of one or more REXX subroutines that are edited, compiled, and executed as a single program"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "common services",
    "type": "components",
    "info": "CA Health Checker Common Service : provides a simple and consistent method for CA products to create health checks to run under the IBM Health Checker for z/OS. The IBM Health Checker for z/OS helps you identify potential problems in your z/OS environment by checking system or product parameters and system status against recommended settings"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "common services",
    "type": "components",
    "info": "CA Common Communications Interface : provides CA enterprise applications with a common communications software layer. This layer insulates the applications from dealing with protocol specifics, error recovery, and system connection establishment.\r\nEnvironments Supported Transparently / Peer-to-Peer Communication / Transmission Management / Optional Queuing of Received Data / Performance Optimization / Simplified Installation / CAICCI Generic Resources / CAICCI SPAWN"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "common services",
    "type": "components",
    "info": "CA Resource Initialization Manager: prepares your operating system environment for all CA applications and starts them."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "common services",
    "type": "enf",
    "info": "MODE(CICS,ON) does not establishes security intercepts in CICS region. ensure to use the CICSREL with parm or use the DD CAIENFLIB in the CICS region. this is important for CA-Top secret and CA ACF2."
  },
  {
    "Vendor": "Open systems",
    "component/product": "comparision",
    "type": "Mainframe V/S Openssytem",
    "info": "HYPERVISOR (ALlows hosting multiple virtual computers on a physical computer. Hardware resources are shared and we can only share what is available) (Ex VM WARE, virtual box from oracle(free open soruce)) EQ z/VM -- helps in enabling multiple systems running in a single Hardware.\r\nContainer (docker) similar to zVM --- helps in running different applications with thier own requirements irrespective of the hardware running. zVM does it only till the OS level (we can run zOS, zTPX, zLinux upon a zVM) but containers go a steps ahead and make applications independent of the hardware and os requirements. Both of the call their intances as IMAGES that are creted.\r\nLimitation for Docker you can only run the contrainer for a linux based appicaiton on a linux based server or a windows based applicaiton on a windows server running DOCKER ."
  },
  {
    "Vendor": "ibm",
    "component/product": "compatibility",
    "type": "website",
    "info": "https://www.ibm.com/software/reports/compatibility/clarity/index.html \r\nwebsite to check for hard ware and software compatibility for IBM products."
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "usually to suppress the message from display at a z/OS console, and to indicate that automation processing is not required. It can also issue commands, for example, to cancel the user or process.\r\nSpecific:\r\nAction:\r\nRegular :"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "usually to suppress the message from display at a z/OS console, and to indicate that automation processing is not required. It can also issue commands, for example, to cancel the user or process.\r\nSpecific:\r\nAction:\r\nRegular :"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "Disable message flood checking -- SETMF OFF\r\nenable message flood checking -- SETMF ON"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "Enable the collection of message rate information. -- SETMF MONITORON"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "Disable the collection of message rate information. -- SETMF MONITOROFF"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "Re-initialize the counts, indicators and actions, and read the specified MSGFLDxx PARMLIB member.-- SET MSGFLD=xx"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "Modify the counts and parameters used by Message Flood Automation. -- SETMF MSGTYPE=msgtype, keyword=value[,keyword=value]"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "Display the counts and parameters used by Message Flood Automation. -- D MSGFLD,PARAMETERS"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "Display the status of the Message Flood Automation function. -- D MSGFLD,STATUS"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "Display whether intensive mode is active for the different classes of messages. -- D MSGFLD,MODE"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFA",
    "info": "Display message rate information collected by the message rate monitoring function. -- D MSGFLD,MSGRATE[,n][,m]"
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "MFS",
    "info": "MSGFLDxx suffix can be specified in CONSOLxx. MSGFLD is the parmlib for message flood automation."
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "definition",
    "info": "Multiple Console Support (MCS) consoles are devices that are locally attached to a z/OS system and provide the basic communication between operators and z/OS. MCS consoles are attached to control devices that do not support systems network architecture or SNA protocols. 99 is the maximum no. of consoles that can be defined for a system in sysplex. In general physical console devices attached to the Mainframe."
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "definition",
    "info": "SNA Multiple Console Support (SMCS) consoles are devices that do not have to be locally attached to a z/OS system and provide the basic communication between operators and z/OS. SMCS consoles use z/OS Communications Server to provide communication between operators and z/OS, instead of direct I/O to the console device. Consoles that are connected via TCP/IP and SNA to Mainframe."
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "definition",
    "info": "Extended Multiple Console Support (EMCS) --to have console beyond the limit of MCS. connected to TSO/E SYSLOG."
  },
  {
    "Vendor": "ibm",
    "component/product": "console",
    "type": "definition",
    "info": "cross-coupling services (XCF) providing signalling paths that allow MCS or SMCS consoles on different systems to communicate with each other. In a sysplex, you can define your MCS or SMCS consoles so that any MCS or SMCS console can receive messages from any system, and commands entered on any MCS or SMCS console can be processed on any system."
  },
  {
    "Vendor": "Open systems",
    "component/product": "containers",
    "type": "theory",
    "info": "Containers are software that contains the necessary components to run in any environment without the need for physical components. It is portable and lightweight and streamlined to work in any environment.\r\nDcocker Container Image : A light weight standalone executable software package that has everything needed to run the application irrespective of the hardware.\r\nContainers : Build, ship, deploy, scale with ease -- is a technology that could help in building an appicaiton to be able to run on any system by packaging the required libraries and other dependent libraries for the application to run into one succinct manifest that can be version controlled, allowing for easy replication of your application across developers on your team and machines in your cluster. Each application may have multiple containers based on the requirements of the application.\r\nExamples : Amazon Elastic Container Service (Amazon ECS), Mirantis Kubernetes Engine (formerly Docker Enterprise), Kubernetes, IBM Cloud Kubernetes Service.\r\nDocker is one of the widely used container engine.\r\nSetup is Hardware (cpu-Hp, dell, windows) + Software(window, linux) + Container Engine (docker or other) + (continer- an application with libraries and dependencies along with it.)\r\nThey have light OS instead of a ful OS packaged with the application."
  },
  {
    "Vendor": "open systems",
    "component/product": "containers",
    "type": "theory",
    "info": "No need to run full copy of an operating system.\r\n   Unlike VMs container run directly on the kernel of a hosting operating system, which makes it lightweight and fast.\r\nVersioning of Images : Necessary controls to easily rollback to previous verison.\r\nAgility to deploy new applications: \r\n\r\nApplication portability and Colocation of data (zcx will help to have the data from system developed applicaiton on z)."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "csm",
    "type": "product isntall",
    "info": "while installing the products we need provide file owner and group owner for the uss directory.. Check for the directory that you want to use in the ishell and properties for these values. Or try the command \"id\" in the omvs to get the group value."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "csm",
    "type": "product isntall",
    "info": "while installing products if you have to provide the omvs path then make sure that the LLQ is different for the paths beings specfifed as the CSM looks at LLQ only to distinguish. (during Deployment)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "csm",
    "type": "product isntall",
    "info": "while installaing for the OMVS segements that are going to get deployed give the HLQ for OMVS datasets in the Containername* (during deployment)."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CSM",
    "type": "startup",
    "info": "Sequence to start CA CSM tasks:\r\nPlease shutdown the MSM Tomcat server, but also the CSM DB Server and the CSM MUF... Then start the MUF again... Wait until you see the message :\r\nDB00215I - CA Datacom/DB Version 14.0 (14.02) Then start the CSM DB server and wait until you see :\r\nDSV00049I-CA Datacom Server Version 14.02 Initialized-CSM31P60 Then start the CSM Tomcat server.."
  },
  {
    "Vendor": "ibm",
    "component/product": "cssmtp",
    "type": "jcl",
    "info": "//IEBGENER EXEC PGM=IEBGENER \r\n //SYSIN DD DUMMY \r\n //SYSPRINT DD DUMMY,SYSOUT=* \r\n //SYSUT2 DD SYSOUT=A,DEST=SMTP,DCB=(LRECL=80,RECFM=F) \r\n //SYSUT1 DD * \r\n HELO TECH.MMM.COM \r\n MAIL FROM:<syst@xxxxx.com> \r\n RCPT TO:<yugesh@xxxxxx.com> \r\n DATA \r\n Date: Tue, 03/12/2019 \r\n From: abc <syst@xxxxx.com> \r\n to: xyz <yugesh@xxxxx.com> \r\n subject: a test mail \r\n Message1 \r\n Message2 \r\n QUIT \r\n /*"
  },
  {
    "Vendor": "IBM",
    "component/product": "dasd",
    "type": "tape",
    "info": "if we have a tapedata set use CA-1 to check for the created date and created job"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "d u,vol=xxxxxx -- to identify the unit address and state of any exsisting volume."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "d sms,vol(xxxxxx) -- to identify the unit address and state of any sms volume."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "d sms -- display the scds information and other info."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "alias",
    "info": "If the non VSAM data set has aliases that are defined using SYMBOLICRELATE parameter, the ALIAS entries are NOT deleted when you use the DELETE command. This way we can avoid to delete the alias and define it again with a new dataset. the symbol &PRODR is taken from IEASYMxx member\r\nDEFINE ALIAS (NAME(SYS1.PRODUCT) -\r\nSYMBOLICRELATE('SYS1.&PRODVR..PRODUCT'))"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "tracks",
    "info": "dasd type and tracks\r\n 16695 then DASD_Model = '3390 Model 1' \r\n 33390 then DASD_Model = '3390 Model 2' \r\n 50085 then DASD_Model = '3390 Model 3' \r\n 150255 then DASD_Model = '3390 Model 9' \r\n 491400 then DASD_Model = '3390 Model 27' \r\n 982800 then DASD_Model = '3390 Model 54'"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "tracks",
    "info": "3390 - 1 track = 56664bytes = 55.3KB\r\n1 cylinder = 15 tracks = 830KB"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "hsend QUERY CDSVERSIONBACKUP -- to the CDS backup dataset names and available no of backups"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "hsend q cds --> query the CDS datasets for utilization"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "hsend backvol cds --> to take backup of CDS and journal"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "hsend query cdsversionbackup ---> to check the latest qualifier used for backups"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "hsend list dsn('dsname') both term --> to check if the ds has any backup and migrated versiobs"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "hsend recall 'dsname' --> for recalling ds"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "hsend recover 'dsname'"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "hsend recover 'dsname' newname('new-ds-name') --> to recover and rename"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "while recalling a non-sms dataset, we need to provide the UNIT and VOL parameter as well.\r\n hsend recall 'ds-name' UNIT(3390) VOL(volser-name)"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "EXPDT next to a dataset to set a migration date"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "commands",
    "info": "alter / managementclass -- to change the mangement class of a dataset after creation -- issue it next to the dataset"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "website -- catalog",
    "info": "https://www.lascon.co.uk/ICF-Catalog-Structure.php"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "catalog",
    "info": "to define a new alias for a HLQ.\r\n/* IDCAMS COMMAND */ DEFINE ALIAS (NAME(HLQ) - RELATE(user catalog) - ) CATALOG(master catalog)"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "recover",
    "info": "Job to recover any SMS dataset from backup.\r\n//STEP010 EXEC PGM=IKJEFT01 //SYSPRINT DD SYSOUT=* //SYSTSPRT DD SYSOUT=* //SYSOUT DD SYSOUT=* //SYSTSIN DD * HSEND RECYCLE EXECUTE ALL PERCENTVALID(100) + ODS(A8N9VZZ.TSO.CNTL9) VOLUME(XXXXXX) /*\r\n•\tDo you have to specify the volume – or will it try to restore it back to the same volume by default? - No need to specify volume if it is SMS managed, but if it is non-SMS then yes, you need to specify the volser where you need to recall.\r\n•\tDoes it automatically restore from the latest backup? What if you want an earlier one? – You can use the VERSION(version-number) parameter to recall from a particular version.\r\n•\tCan it overlay (replace) existing datasets or do they have to be deleted first if they exist? – Use the REPLACE parameter and it will overwrite the existing one. Please use this with caution since you will lose the current data."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "ismf",
    "info": "LISTVOL -- to list all the volumes of a storage group"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "parmlib",
    "info": "the arccmdxx can be used to specify the DFSMSdss dump type, frequency and other dump characteristics."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "command",
    "info": "These incremental backups can be used to recover individual data sets using the HRECOVER command"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "command",
    "info": "to backup a dataset -- issue the command HBACKDS we can use it in ISPF or for more options try it in ISMF"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "command",
    "info": "recover * tovolume(original_volume) unit(unittype) fromdump(dumpvolume(tapenumber) applyincremental)"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "dfhsm",
    "info": "The backing-up of data sets is determined through SMS storage group and management class routines.\r\nThe HBACKDS command is used to create an incremental backup of a data set.\r\nThe management class backup frequency attribute is used to define the number of days between backups for data sets.\r\nThe management class ADM/USR backup attribute controls whether you have authority to enter DFSMShsm commands.\r\nHRECOVER command is used to reover a dataset from backup."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "dump",
    "info": "Storage group and copy pool SMS constructs contain various volume related dump attributes."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "command",
    "info": "DFSMSrmm commands\r\nF DFRMM,ABEND(tasktoken)\r\nF DFRMM,CANCEL() / HOLD () /RELEASE ()/ QUIESCE / CMD= /M=xx/ query active/ PDA=OFF/ON / PDALOG=OPPF/ON/SWAP\r\nF DFRMM,RESTART LISTENER/STOP LISTENER"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "tape init.",
    "info": "job to init/Erase/scan tapes\r\n//tapeinit exec pgm=edginers\r\n//sysprint dd sysout=*\r\n//tape dd unit=(3390,,defer)\r\n//sysin dd *\r\nINIT VOLUME(xxxxx) LABLE(SL)\r\nERASE VOLUME(yyyyy) RACK(aaaa)\r\nSCAN VOLUME(ccccc)\r\n/*\r\nby command\r\n/S LABEL,OPT=,U=,SOUT='SYSOUT=a' -- The EDGINERS utility can also be initiated from a console using a special LABEL procedure supplied with the DFSMSrmm product. The procedure is invoked by specifying a start command.\r\nwe will get a reply command and we need to reply R XX,INIT / ERASE /SCAN\r\nIf the volume cannot be mounted, replying S will skip the processing of that volume."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "dfsms rmm",
    "info": "before tapes can be considered for automatic initialization or erasure as part of inventory management - Their status needs to be set to initialize or erase, action pending"
  },
  {
    "Vendor": "IBM",
    "component/product": "DASD",
    "type": "types",
    "info": "Disk -- rotating plates and an arm to read and write\r\nSSD -- solid state drives. Better speed than the disk drives. SLC(Single Level Cell), MLC, eMLC, TLC"
  },
  {
    "Vendor": "IBM",
    "component/product": "DASD",
    "type": "storage system",
    "info": "https://community.ibm.com/community/user/ibmz-and-linuxone/blogs/destination-z1/2019/12/23/a-brief-history-of-mainframe-memory-technology"
  },
  {
    "Vendor": "IBM",
    "component/product": "DASD",
    "type": "RAID",
    "info": "Redundant Array of Independent Disks (RAID) : Most companies will use disk subsystems, rather than individual disks. Intelligent use of the many disks within a storage subsystem can improve reliability and performance."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "ickdsf",
    "info": "ICKDSF can also be executed in 'standalone' mode for z/VM and z/OS. In this mode, ICKDSF is IPLed in a System z mainframe LPAR or z/VM image, and operated from mainframe consoles.\r\nThis allows disks to be initialized in a new mainframe, or where there is no operational z/VM or z/OS system. It is ideal for disaster recovery."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "ickdsf",
    "info": "//sysin dd *\r\ninit unitaddress(0471) verify -- initializes the 0471 with the old volume name\r\ninit unitaddress(047A) VOLID(VOL001) noverify -- initializes the o471 unit with a volume name as VOL001 - noverify generally used for new volumes.\r\nBOOTSTRAP IPLDD(SAMPLIB,OBJ) -- IPL disk. SYS1.SAMPLIB loaded into the volume.\r\nNODSEXIST -- if datasets exists on the volume the unit is not initialized.\r\nREFVTOC -- the REFORMAT REFVTOC recreaes teh VTOC in its current location.\r\nREFORMAT UNITADDRESS(0471) VERIFY(VOL01l) VOLID(VOL020) -- renames the disk from VOL011 to VOL020. the disk must be offline to be renamed.\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "dfsms",
    "info": "dfp -- storage polices when new datasets are created.\r\ndss -- backup dataset and volume level\r\nhsm -- managers dasd by moving less used data to a cheaper and slower storage mediums\r\nrmm -- removable media manager -- tapes\r\ntvs -- allows sharing of vsam datasets."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "command",
    "info": "HBACKDS -- to take hsm backup of a dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "MIGRAT2",
    "info": "to find the tape volume to which the dataset is migrated when in MIGRAT2 status or to find out if there are any backups available for a dataset.\r\nhsend list dsn(/) both term"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "datasets",
    "info": "Job that helps in the movement of non sms datasets across volumes.\r\n//ZSMPT1 EXEC PGM=ADRDSSU \r\n//SYSPRINT DD SYSOUT=* \r\n//DASD DD VOL=SER=ZDBP01,UNIT=3390,DISP=SHR\r\n//OUT DD VOL=SER=ZDBP0A,UNIT=3390,DISP=SHR\r\n//SYSIN DD * \r\nCOPY INDDNAME(DASD) \r\nOUTDDNAME(OUT) \r\nDELETE - \r\nDATASET(INCLUDE(#ECD001.JCL.CNTL))"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "cbruxent",
    "info": "D SMS,OAM F OAM,D,OAM,L=INTERNAL-Z CBR1100I OAM status: 282 TAPE TOT ONL TOT TOT TOT TOT TOT ONL AVL TOTAL LIB LIB AL VL VCL ML DRV DRV DRV SCRTCH 1 1 0 0 1 0 220 220 219 333951 There are also 2 VTS distributed libraries defined. Category count scratch transition ENABLED. CBRUXCUA processing ENABLED. CBRUXEJC processing ENABLED. CBRUXENT processing OPERATOR-DISABLED. CBRUXVNL processing ENABLED."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "Ver check",
    "info": "STC -- for all products."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "Environment",
    "info": "Job that helps us to identify the DATCAOM environment.\r\n//STATUS EXEC PGM=DBUTLTY \r\n//STEPLIB DD DSN=BEPCA7AD.CA7.BE07.MUF.LOADLIB, \r\n// DISP=SHR \r\n// DD DSN=ESLCA.DATACOM.AD14.CUSLIB, \r\n// DISP=SHR \r\n// DD DSN=ESLCA.DATACOM.AD.CAAXLOAD, \r\n// DISP=SHR \r\n//SYSPRINT DD SYSOUT=* \r\n//SYSOUT DD SYSOUT=* \r\n//SYSIN DD * \r\nCOMM OPTION=STATUS \r\n/*"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "Environment",
    "info": "//REPORT EXEC PGM=DBUTLTY \r\n//STEPLIB DD DSN=XXXX.DATACOM.AD14.CUSLIB, \r\n// DISP=SHR \r\n// DD DSN=XXXX.DATACOM.AD.CAAXLOAD, \r\n// DISP=SHR \r\n//CXX DD DSN=XXXX.DATACOM.AD14.CXX, \r\n// DISP=SHR \r\n//SYSPRINT DD SYSOUT=* \r\n//SYSOUT DD SYSOUT=* \r\n//SYSIN DD * \r\nREPORT MEMORY=MVS --- can list all the MUF that are running on a system and their version. \r\nREPORT AREA=CXX --- provide all the databases name and their configuration specific to that CUSLIB. /*\r\nREPORT AREA=CXX,DBID=4000,TYPE=A  -- to provide database space stats alone."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "upgrade",
    "info": "Datacom/Ad from V14 to V15.\r\nhttps://knowledge.broadcom.com/external/article?articleId=198137\r\n\r\nhttps://community.broadcom.com/mainframesoftware/communities/community-home/digestviewer/viewthread?GroupId=2035&MessageKey=a912bc8a-e7d3-4bf6-9c9e-62116d13ef90&CommunityKey=c66cac08-5724-4f3e-8734-56dffb11f900&tab=digestviewer"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "AD / DB -- system datasets",
    "info": "CXX -- Contains the definitions of all databases accessible in this CA Datacom® environment.\r\nCatalog/Directory – metadata used at run-time\r\nLXX -- Contains user transaction data (including data rows) used to support transaction back out and database restart (after a failure). transaction Log.\r\nFXX -- Contains user transaction data (not including data rows) used to support fast database restart (after a failure). Force area – long running transactions\r\nRXX -- Contains user transaction data (including data rows) used to support database recovery from a backup after a data loss. Recovery file – LXX goes here at SPILL time. Typically on a tape, most AD using products do not use\r\nPXX –- Statistics and Diagnostics Area (used for monitoring and debugging)\r\nThe system data set names for CXX,FXX,LXX are known via the DBSIDPR DSN_XXX= when running with SIMPLIFY_MODE=YES. That is the case for all CA Datacom/AD sites.\r\nThen for the user data bases . When you run DBUTLTY INIT AREA= , DBID=nnnnn we attach that data set to the CXX and store the name of the data set in the CXX . When the MUF or DBUTLTY opens a database we fetch the name of the data set in the CXX and do a dynamic allocation for the file. You can see the names of the data sets by running a full CXX report on the DBID or a complete CXX report .\r\nRun DBUTLTY REPORT AREA=CXX to see all data set names."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "AD - system databases",
    "info": "CA Datacom® Datadictionary -- Database 0002 -- Contains the metadata definitions of all databases accessible in this CA Datacom® environment\r\nData Definition Directory - DDD -- Database 0015 -- Contains the SQL metadata definitions of all databases that are SQL accessible in this CA Datacom® environment\r\nUser Databases -- Each user database is commonly referred to by its functional purpose and by its assigned database ID (DBID). There are one or more index areas and one or more data areas for each database. Each of these areas has one associated z/OS data set. To refer to the data sets making up the database, we typically use the z/OS DDNAME. The actual data set name depends on the site."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "datacom",
    "type": "System Database DBIDs",
    "info": "•0001, 0010 – Small sample databases used for install verification\r\n•0002, 0015 – Meta data dictionary used to house all data definitions\r\n•0006, 1006 – Navigational (CBS) query optimization databases\r\n•0016, 0017 – SQL Temporary table and work area databases\r\n•0003 – Dataquery product database\r\n•1000 – Dynamic system tables database similar to DB2 catalog with a variety of statistics, tuning and debugging information\r\n•0001 – 0020, 1000 – 1020, 2000 – 2020, 3000-3020, 4000-4020, 5000 - reserved"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "DBUTLTY",
    "info": "use the command SET OPTION1='DATANO=9999;DXXNO=9999;IXXNO=999' to improve the performance of the DBUTLTY\r\n•Initialization (INIT) – Index and Data Areas\r\n•LOAD – Data Areas only, Index build automatically\r\n•Backup\r\n•Recovery\r\n•Reports\r\n•Sending commands to MUF\r\n•Making databases offline/online\r\n•Automated monitoring (AutoStatus, AutoCollect)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "datacom",
    "type": "MUF",
    "info": "Standalone address space that manages the access to the databases\r\n•Utilizes buffering, memory resident data, etc. for high performance access\r\n•Synchronizes all update activity to allow row-level locking\r\n•Allows thousands of users to access the same table for update at the same time\r\n•Provide data integrity features: logging, restart (warm), and recovery\r\n•Symmetrical Multi-processing (SMP)\r\n•Highly zIIP enabled •Navigational and SQL access APIs"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "datacom",
    "type": "products",
    "info": ".CA Datacom/DB is CA's strategic Database management system for the mainframe platform. It is being widely used in the industry and many large corporations depend on it. 14 Different licensable options, each purchased separately\r\n•CA Datacom/AD is a restricted use version that is utilized by many CA products as their internal database today and even more products will use it in the future. 5 CA Datacom options packaged together: DB, DD, DQ, SQL, Server. All the power of the CA Datacom/DB products with only one limitation: Only allows CA product databases to be installed"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "AD / DB",
    "info": "Though the same FMID's are installed when installing these product there is a diffrence in the module. so, the datasets cannot be shared and we will get errors when starting MUF's.\r\nWhen you start a Datacom Multi-User with card DATACOM DB or DATACOM AD a check is done to see if you run with the correct Datacom load library . If it does not match then the startup fails with DB00205E - MULTI-USER ERROR - 1074 .\r\n1074 says: the specified libraries are not compatible with the MUF startup option DATACOM value.\r\nSee DB00205E"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "install",
    "info": "In a non-AD environment where you run a full Datacom MUF, CA IPC is a required product and needs to be installed/upgraded separately.\r\nCA Datacom/DB/DataDictionary/CA Dataquery and SQL are installed/upgraded together and are on the same installation product pax. CA Datacom Server is also a separate product and installation/upgrade.\r\nCA IDEAL is a separate product and installation/upgrade.\r\nCA Datacom CICS Services is a separate product and installation."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "MUF",
    "info": "Identifying the MUFName and MUF stc that your product is working with. Check for the string MUFNAME in your product STC ouptut and we will know the MUF stc name that it is working with. Look for message\r\nCA7 : DB00101I - STARTED JOB-CA7ONL NUMBER-75664 CXX=UST7CXX MUFNAME=USTMUFAD\r\nCAL2D041I CA Datacom r14.0 MUF USTMUFAD STC27024 r14.0 connection LOCAL\r\nCA11 : DB00135I - CONNECT TO AD10STRT MUFAD14 STC27065 SYST M-14.0 I-14.0\r\nDB00101I - STARTED JOB-CAL7 NUMBER-80789 CXX=AD14CXX MUFNAME=MUFAD14"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "MUF",
    "info": "1.How to identify if we are running the DATACOM/AD or DATACOM/DB I see both the messages in MUF stc. When starting , each Multi-User writes out message DB00201I - MULTI-USER ENABLED,CXXNAME=cxxname MUFNAME=mufname XX with XX being AD or DB . AD means this is a Datacom/AD Multi-user and you find card DATACOM AD in the startup cards . 2.How to identify what is the STC name for the MUF that my product is running. (CA7, CA11, MSM, CICS and so on).\r\nyou can run DBUTLTY REPORT MEMORY=MVS to see all MUFS that run on the LPAR where you run this report . Each application connecting to a MUF uses a module DBSIDPR which has the name of the MUF in TARGET_MUF_LIST . Each application writes out a connection message to connect to the MUF like DB00135I and DB00101I with the name of the MUF it connects to and the Datacom version. 3. How to identify if we have a MUF that runs internal (I think a task starts and ends ) or external(long running STC) to the product. the only MUF that can run internal in the same address space as another product is the IMUF used by CA COMMON SERVICES ENF ."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Datacom",
    "type": "Shadow MUF",
    "info": "I have Cal7 (ca11) STC running on 3 systems in sysplex and sharing datasets. I see the MUF task AD10STRT being started on a system at any given time. If we shutdown the system where AD10STRT is running, then I see another AD10STRT task starting automatically on another system in sysplex.\r\nIs it supposed to be running that way?\r\nThat is because that MUF is running with a Shadow MUF that takes over when the primary MUF abends or gets ended.\r\nThe MUF that is the Shadow MUF displays message DB02325I SHADOW MUF NOW WAITING . With a MUF that has a SHADOW MUF you you have 2 MUFNAMES in the DBSIDPR TARGET_MUF_LIST and CONNECT_ALLOW_PRIORITY=(LOCAL,XCF) if the Shadow MUF runs on another LPAR than the Primary MUF. The MUFs are then configured as primary/shadow MUF and have XCF enabled .\r\nHere in Use Case Videos you find a video that shows how to setup a Shadow MUF: https://techdocs.broadcom.com/us/en/ca-mainframe-software/database-management/ca-datacom/15-1/using/use-case-videos.html#"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "datacom",
    "type": "datasets",
    "info": "The system data set names for CXX,FXX,LXX are known via the DBSIDPR DSN_XXX= when running with SIMPLIFY_MODE=YES. That is the case for all CA Datacom/AD sites.\r\nDBSIDPR DSN_XXX\r\nThen for the user data bases . When you run DBUTLTY INIT AREA= , DBID=nnnnn we attach that data set to the CXX and store the name of the data set in the CXX . When the MUF or DBUTLTY opens a database we fetch the name of the data set in the CXX and do a dynamic allocation for the file. You can see the names of the data sets by running a full CXX report on the DBID or a complete CXX report .\r\nRun DBUTLTY REPORT AREA=CXX to see all data set names."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "datacom",
    "type": "datasets",
    "info": "https://knowledge.broadcom.com/external/article/144564/two-ways-to-rename-ca-datacom-database-f.html"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "datacom",
    "type": "clone",
    "info": "DBUTLTY has a function called CXXCLONE to clone an existing environment.\r\nExample 2 in our documentation is what you need .\r\nSo you are creating a new MUF in your sandbox , meaning that a new CUSLIB is needed and that you need to configure DBSIDPR with a new CXXNAME/MUFNAME and DSN_XXX=new HLQ for the new data sets . Then you run : 1. DBUTLTY BACKUP on the CXX that needs to be cloned in that source MUF environment\r\n2.Using the new CXX data set in the JCL and the new CUSLIB , you run DBUTLTY in your sandbox with SYSIN cards INIT AREA=CXX,DATACOM=DB,CXXNAME=new cxxname 3.Run DBUTLTY in the new sandbox environment using the new CUSLIB with SYSIN cards\r\nSET OPTION1=MUF_NOT_ENABLED\r\nCXXCLONE DDNAME=x,STATUS=NO_CHANGE,OPTION=ALTER,OPTION2=sourceHLQ*newHLQ where DDNAME refers to the cxx backup data set from 1.\r\n4.Run DBUTLTY in the sandbox to init the LXX/FXX . See STEP1I and STEP1J in CABDLOAD(BDNEW01) 5.You use IEBGENER to copy all data sets ( not the CXX itself) from the source HLQ to the new HLQ .\r\nYou also need to copy the VLS/IDEAL BDAM files or you run VLSUTIL to BACKUP in the SOURCE environment and FORMAT/RESTORE in the sandbox . 6.Start the MUF in the sandbox with the new CUSLIB . Databases 006 and 17 should be VIRTUAL. 7.Run DBUTLTTY using the new CUSLIB with sysin card LINK DBID=1-5000\r\n8.Start the new CICS in the sandbox with the newly copied VLS/IDEAL BDAM files and the new CUSLIB/CABDLOAD and of course all CICS tables need to be updated with the CICS definitions for all products"
  },
  {
    "Vendor": "ibm",
    "component/product": "Db2",
    "type": "offload",
    "info": "DFSMShsm has issued a Statement of Direction to support TCT Full volume dump for FRBACKUP and FRRECOV. This will enable Db2 PiT System Level Backups to be offloaded to a TS7700 Object Store with none of the data passing through z/OS!"
  },
  {
    "Vendor": "IBM",
    "component/product": "DB2",
    "type": "error",
    "info": "ou need to find the error messages that show someone putting in the wrong password, if this is put in by a DB2 connection you will see 10:38:42 22JAN D2PBDIST ICH408I USER(P#00252 ) GROUP(D#825660) NAME(NPSA - PSAR\r\n10:38:42 22JAN D2PBDIST LOGON/JOB INITIATION - REVOKED USER ACCESS ATTEMPT Then you can at the log at that time and find where that came from by looking for the following message.\r\nYou can then take the LUWID from that message and put it into the attached spreadsheet and it will give you the IP address that the bad password came from.\r\nD2PBMSTR DSNL030I -D2PB DSNLTSEC.30 DDF PROCESSING FAILURE D2PBMSTR FOR D2PBMSTR LUWID=A90A09F2.G88A.D92901AFB26A D2PBMSTR REASON=00F30088 D2PBMSTR THREAD-INFO=P#00252:*:*:*:*:*:*:<::169.10.9.242.2186."
  },
  {
    "Vendor": "IBM",
    "component/product": "Db2 query monitor",
    "type": "Ver check",
    "info": "STC"
  },
  {
    "Vendor": "ibm",
    "component/product": "dfsmsdss",
    "type": "dump",
    "info": "ADRDSSU sample for dumping datasets:\r\n//STEP1 EXEC PGM=ADRDSSU \r\n//DASDOUT DD DISP=(NEW,CATLG,DELETE),DSN=SMPE.IBM.CDP.DUMP, \r\n// SPACE=(CYL,(500,20),RLSE) \r\n//SYSPRINT DD SYSOUT=* \r\n//SYSIN DD * \r\n  DUMP DATASET(INCLUDE(SMPE.IBM.CDP.V1R1.SHBO* , - \r\n                                  SMPE.IBM.CDP.V1R1.ZFS)) - \r\n                                  TOLERATE(ENQF) - \r\n       OUTDDNAME(DASDOUT) \r\n//*\r\n//SYSIN DD * \r\nDUMP DATASET(INCLUDE(SMPE.CAI.SYSVIEW.V16.D1009.CNM4*) - \r\nEXCLUDE(SMPE.CAI.SYSVIEW.V16.D1009.CNM4ZFS))- \r\nOUTDDNAME(DASDOUT) - \r\nTOLERATE(ENQF) \r\n//*\r\n\r\nALLDATA(*), COMPRESS also while dumping vsam files."
  },
  {
    "Vendor": "ibm",
    "component/product": "dfsmsdss",
    "type": "restore",
    "info": "ADRDSSU sample for restoring datasets\r\n//STEP1 EXEC PGM=ADRDSSU //DASDIN DD DISP=SHR,DSN=SMPE.IBM.CDP.DUMP, // UNIT=SYSDA //DASDOUT DD DISP=SHR,VOL=SER=TCH304,UNIT=SYSDA //SYSPRINT DD SYSOUT=* //SYSIN DD * RESTORE INDD(DASDIN) OUTDD(DASDOUT) - DATASET(INCLUDE(SMPE.IBM.CDP.**)) - TOLERATE(ENQF) - CATALOG - RENAMEU(SMPE.IBM.CDP.**, SYS2.IBM.CDP.**) /*"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Disk backup and restore",
    "type": "Ver check",
    "info": "Panels"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "dispatch",
    "type": "online",
    "info": "we can update the onlin retention period in option 1: REPORT DEFINITION and select the report and update retention days."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "dispatch",
    "type": "commands",
    "info": "dcmt d ar -- to check the file sizes on the login page."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "dispatch",
    "type": "commands",
    "info": "/F SPL0,STAT,X -- commad to list the status of the SPLx -- look in CADZSPL0 task for the SPLx value. This would tell us the MAXDS value and current olv records.\r\nCheck the MAXDS value and the CAPTIVE= value. this has to comedown for the MAXDS usage to comedown.\r\nMAXDS value cannot be increased by a command."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "dispatch",
    "type": "commands",
    "info": "DCUF SHO USERS ALL -- list all the users"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "dispatch",
    "type": "commands",
    "info": "DCMT V LTE VTMLT051 RES DEL -- logoff dispatch"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "dispatch",
    "type": "commands",
    "info": "DCMT DISPLAY STAT SYSTEM"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Dispatch",
    "type": "commands",
    "info": "DSOPTN -- to check if we are using internal or external security"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Dispatch",
    "type": "File size inc 2",
    "info": "2) Migrate the Archive Area.- review documentation for details. Run the job CA.DISP.SAMPJCL(DSEXARX) use the command DCMT D AR in the dispatch to list the current file sizes and update the job with increased size if this job fails do not try to re-run the job we need to delete the current files restore the files from backup and then re-run the job again. 3) Migrate additional areas - only needed IF you want to migrate other areas - which you probably wont. None for now. 4) DSEXDBEX - Rebuild Database load modules CA.DISP.SAMPJCL(DSEXDBEX) 5) Rebuold modules for OLVO only reqions - this step would ONLY run if you are running OLVO regions none for now."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Dispatch",
    "type": "file size inc 3",
    "info": "6) Complete backup of the new files CA.DISP.SAMPJCL(DSEXBR01) 7) Run the status job CA.DISP.SAMPJCL(DSEXSTAT) Check for the increased sizes of the files required. 8) Copy the load modules from CA.**.CADSLOAD.WORK to CA.DISP.CADLOAD and 9) Modify Utility members. AR-AREA -- DSEXARBL, DSEXARCL, DSEXBDEL, DSEXBR04 10) restart the DIPATCH tasks."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "dispatch",
    "type": "fles full",
    "info": "if OLV files are full do not simply migrate them. First check if there is space in archive files. if the archive files are full. then we need allocate bigger archive files. Complete the pending archive files and then automatically olvs files get archived as per the rules."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Dispatch",
    "type": "file size increase",
    "info": "************ Increase the size of archive file*************************\r\n1) Shutdown Dispatch and other dispatch taks. move the task out of automation 1) Complete backup of existing databasets - this must INCLUDE the Dispatch load library (CADSLOAD) BRing down dispatch and run the job OPDSPD01 and dispatch load backedup as CADSLOAD.WORK here we have 2 load libraries. S*.DISP.CADLOAD and CA.DISP.BE07.CAILIB-- copied both to CA.**.CADSLOAD.WORK 1)Backup the librareisusing ADRDSSU S*.DISP.SAMPJCL(ADRDDUMP)"
  },
  {
    "Vendor": "ibm",
    "component/product": "docs",
    "type": "website",
    "info": "https://watsonwalker.com/"
  },
  {
    "Vendor": "ibm",
    "component/product": "DR",
    "type": "technology",
    "info": "we use storage replication, most commonly with Hitachi or SRDF using Vmax or now Powermax from DellEMC"
  },
  {
    "Vendor": "ibm",
    "component/product": "dr",
    "type": "pprc",
    "info": "when pprc is avaialble and we want to do a DR for few lpars in sysplex sharing DASD then it is better to do the stopping nd startng of PPRC at LCU level."
  },
  {
    "Vendor": "ibm",
    "component/product": "dump",
    "type": "command dump",
    "info": "/D DUMP\r\ndisplays the current dump setup for dataset or logstream and the naming convention of dump datasets.\r\n/D D,O\r\ndisplay the options for different dumps that can be captured. sdump, sysabend, sysudump and so on\r\nDd clear,dsn=xx\r\ndd clear,dsn=all\r\n/CD SET,SDUMP,MAXSPACE=5000M -- command to increase the space for a dump to be captured.\r\n/DD DUMP,ADD,VOLUME=xxxxx to add a volume to capture dump datasets."
  },
  {
    "Vendor": "ibm",
    "component/product": "dump",
    "type": "types",
    "info": "SLIP DUMP --- Snapshot of virtual storage a program being used.\r\nTransaction DUMP --- dump virtual storage areas of interest/uses the IEATDUMP macro to obtain a representation of virtual storage.\r\nAbend Dump --- requested via a jcl when a task cannot complete successfully.\r\nSVC (Supervisor call) Dump -- this is the equivalent of users snap dump for a contriol program.\r\nSlip Dump --- trigger a dump based on a specific message.\r\nStandalone Dump --- dump taken for real and part of virtual storage when a system stops working."
  },
  {
    "Vendor": "ibm",
    "component/product": "dump",
    "type": "types",
    "info": "The three ddnames that can be used in JCL as DD stat. to indicate which type of abend dump you want to use are:\r\nSYSUDUMP which is formatted dump of user storage associated with the failing task.\r\nSYSABEND which is a formatted dump that contains the same information as SYSUDUMP, plus LSQA and the IOS control blocks.\r\nSYSMDUMP which is an unformatted dump of the address space, including the system areas."
  },
  {
    "Vendor": "ibm",
    "component/product": "dump",
    "type": "slip",
    "info": "slip set,enable,lpamod=mod0x,comp=0c4,errtyp=prog,jobname=axxxxx,action=svc,end"
  },
  {
    "Vendor": "ibm",
    "component/product": "dump",
    "type": "command\r\nDUMP",
    "info": "we can specify the options for svc dump in IEADMCxx.\r\n*07 IEE094D SPECIFY OPERAND(S) FOR DUMP COMMAND -- appears when a SVC dump is requested.\r\nwe can reply with following options:\r\nU --- dumps MASTER SCHEDULER addr space.\r\nSDATA=(area) -- SDATA=(CSA,NUC) -- dumps CSA and NUCLeus storage areas.\r\nSTOR=(xxxxxxxx,yyyyyyyy) -- allows you to specify a range, or multiple ranges of virtual storage that you require to be dumped\r\nSTRLIST=(STRNAME=structurename) -- dump any structure.\r\nASID=(xxxx,yyyy) --"
  },
  {
    "Vendor": "ibm",
    "component/product": "dump",
    "type": "command\r\nDUMP",
    "info": "SVC dump command\r\nDump COMM=(title for the dump) / D TITLE=(title for the dump) -- to start the dump.\r\nDump COMM=(xxxx),PARMLIB=xx -- takes an SVC dump with the options specified in PRAMLIB IEADMCxx if we dont provide any parmlib then we get teh message *07 IEE094D SPECIFY OPERAND(S) FOR DUMP COMMAND\r\nwe cna reply\r\nR 07,JOBNAME=ABC or R 07,JOBNAME=ABC,SDATA=(PSA,NUC,SQA)\r\nR 07,TSONAME=XXXXXX  -- to dump a userid\r\n IEA911E will be issued if the dump data set was preallocated. In this instance, IEA611I is issued, indicating that the dump data set was dynamically allocated.\r\nuse the CHNGDUMP command to change the dump options\r\nCD SET,SDUMP,MAXSPACE=8000M -- to increase the svcdump maxspace by 8000M."
  },
  {
    "Vendor": "compuware",
    "component/product": "ecc",
    "type": "commands",
    "info": "refresh parmlib for CMSC task --- /f cmsc,parmlib refresh LMCLxx/FAVMxx/DDSNxx"
  },
  {
    "Vendor": "IBM",
    "component/product": "Education",
    "type": "website",
    "info": "https://www.ibm.com/support/knowledgecenter/en/SSLTBW_2.3.0/com.ibm.zos.v2r3/en/homepage.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "education",
    "type": "website",
    "info": "https://www.ibm.com/it-infrastructure/z/software-trials"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Endevour",
    "type": "Ver check",
    "info": "Panels"
  },
  {
    "Vendor": "Rocket",
    "component/product": "EOS",
    "type": "License",
    "info": "expiration date of the EOS 360 license at the bottom of the EVT syslog (alternatively, you can view the RSDLOUT dd of the EVT job/STC) so there really is no need for a batch utility to get this information."
  },
  {
    "Vendor": "Rocket",
    "component/product": "EOS",
    "type": "License",
    "info": "in the EVT log check the RSDLOUT DD messages for the expiration date."
  },
  {
    "Vendor": "Rocket",
    "component/product": "EOS",
    "type": "License",
    "info": "issue the command PROFILE and select system profile"
  },
  {
    "Vendor": "bmc",
    "component/product": "fileaid",
    "type": "commands",
    "info": "TSO XVJALLOC in the fileaid panels would provide information on the allocations for fileaid."
  },
  {
    "Vendor": "bmc",
    "component/product": "fileaid",
    "type": "commands",
    "info": "/F CMSC,parmlib refresh famv00"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "commands",
    "info": "mainframeA to mainframeB dumped file.\r\n Connect to MainframeA from MainframeB and get the file.\r\n quote site recfm=u lrecl=0 blksize=27998\r\n Type e\r\n mode b\r\n get 'dump file on mainframeA' 'dump file on mainframeB' (replace -- ensure to create the mainframeB file upfront with the same attribtues as dump file on MainframeA.\r\n\r\nwe can use mget to get the pds. we can off the prompt by using prompt command or mget -i pdaname "
  },
  {
    "Vendor": "IBM",
    "component/product": "FTP",
    "type": "messages",
    "info": "EZYFS56I - A client logged into the server. -- check this message for any problem determination"
  },
  {
    "Vendor": "IBM",
    "component/product": "FTP",
    "type": "messages",
    "info": "EZYFS57I - A client login to the server failed."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "commands",
    "info": "to get a ps dataset from a to b when logged on to B … mput 'a file name' 'b file name'"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "commands",
    "info": "to get a pds dataset from a to b when logged on to B … mput 'a file name(*)' 'b file name' -- when prompted use S to stop prompting for each member. Also we can use TYPE E and MODE B before the put/get commands to transfer the files in non bin format."
  },
  {
    "Vendor": "ibm",
    "component/product": "FTP",
    "type": "commands",
    "info": "quote site lrecl=80 recfm=fb blksize=800 volume=xxxxx -- for any dataset to be created during FTP.\r\nquote site recfm=U lrecl=0 blksize=27998 cylinders pri=50 sec=10 -- to specify space."
  },
  {
    "Vendor": "ibm",
    "component/product": "FTP",
    "type": "commands",
    "info": "mkd -- to create a dataset through ftp. It takes the attributes from the quote site command."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "search order",
    "info": "FTP search order for ftp parms : \r\n $HOME/ftp.data\r\n userid.FTP.DATA\r\n /etc/ftp.data\r\n SYS1.TCPPARMS(FTPDATA) data set\r\n tcpip_hlq.FTP.DATA file"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "filesystem",
    "info": "to find the filesystem mounted for a path issue the command df ."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "setup",
    "info": "jcl to check the connectivity setup of maintframe\r\n //TESTJOB1 JOB CLASS=A,MSGCLASS=X,MSGLEVEL=(1,1),NOTIFY=&SYSUID \r\n //NSLOOKUP EXEC PGM=BPXBATCH, \r\n // PARM='PGM /bin/dig eapi.broadcom.com' \r\n //STDOUT DD PATH='/tmp/&SYSUID..bpxbatch.stdout', \r\n // PATHOPTS=(OWRONLY,OCREAT,OTRUNC), \r\n // PATHMODE=SIRWXU \r\n //OUTSTEP EXEC PGM=IKJEFT01 \r\n //SYSTSPRT DD SYSOUT=* \r\n //INPUT DD PATH='/tmp/&SYSUID..bpxbatch.stdout', \r\n // PATHOPTS=(ORDONLY), \r\n // PATHDISP=DELETE \r\n //OUTPUT DD SYSOUT=*, \r\n // DCB=(RECFM=V,LRECL=256) \r\n //SYSTSIN DD * \r\n OCOPY INDD(INPUT) OUTDD(OUTPUT) \r\n /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "status",
    "info": "quote stat -- we can check for jes interface level."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "jes",
    "info": "submit a job -- \r\n quote site filetype=jes\r\n get 'Dataset(member)' member.txt -- to submit a job in dataset(member) and get the output ftp'ed to PC in name member.txt\r\n put filename.txt -- submit job form pc to mainframe.\r\n job should be userid + 1 character like A or B or anything, if the username used during the ftp session is \"a93lnzz\" to get the output automatically when you use the get command.\r\n If you want to submit the job with different Jobname and still if you want the output of the job then JESINTERFACELEVEL should be set to 2 (which in most environment security people wont allow)\r\n To find the jes interface level you can issue the below command after connect to the ftp server.\r\n quote stat\r\n Then if you see the output it should look something similar to below\r\n 211-JESINTERFACELEVEL is 1\r\nwe can also use the command DELETE jobnumber to delete a job in JES queue."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "jes",
    "info": "30 CS50458 is logged on. Working directory is \"CS50458.\".\r\nftp> quote site jesjobname=*\r\n200 SITE command was accepted\r\nftp> quote site filetype=jes\r\n200 SITE command was accepted\r\nftp> quote site jesowner=cs50458\r\n200 SITE command was accepted\r\nftp> dir\r\n200 Port request OK.\r\n125 List started OK for JESJOBNAME=*, JESSTATUS=ALL and JESOWNER=CS50458\r\nJOBNAME JOBID OWNER STATUS CLASS\r\nCS50458 TSU07605 CS50458 OUTPUT TSU ABEND=622 3 spool files\r\nCS50458 TSU07592 CS50458 OUTPUT TSU ABEND=622 3 spool files\r\nCS50458 TSU07472 CS50458 OUTPUT TSU ABEND=622 3 spool files\r\nCS50458 TSU07955 CS50458 ACTIVE TSU\r\n250 List completed successfully.\r\nftp> get TSU07605 200 Port request OK.\r\n125 Sending all spool files for requested Jobid\r\n250 Transfer completed successfully.\r\nftp: 38573 bytes received in 1.34Seconds 28.72Kbytes/sec."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "commands",
    "info": "Connect to Mainframe from PC for a file.\r\n To download the file from mainframe to PC : Get 'FIIE.ON.MAINFRAME' D:\\MYFILES\\TEST.TXT\r\n To Upload the file to mainframe from PC : PUT D:\\MYFILES\\TEST.TXT 'FILE.ON.MAINFRAM'\r\n to upload a files in a folder : lcd localfolder / mput * and give y to the files we want to upload"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "commands",
    "info": "commad to change the local working directory after connecting to FTP.\r\n LCD C:\\Users\\a93lnzz\\Desktop\\cts\\smf"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "commands",
    "info": "JCL to include date in the FTP ouput file. Not workign.\r\n //STEP1 EXEC PGM=EZACFSM1 \r\n //SYSIN DD *\r\n put 'BELLDS.DS26460A.FTP' AKDIP.ESW.OR.&LYYMMDD.&LHHMMSS\r\n qui \r\n /*\r\n //SYSOUT DD DSN=&&T,DISP=(,PASS),UNIT=VIO, \r\n // RECFM=FB,LRECL=80\r\n //STEP2 EXEC PGM=FTP,PARM='whatever'\r\n //OUTPUT DD SYSOUT=* \r\n //INPUT DD *\r\n ip address\r\n id\r\n pw\r\n ascii\r\n path \r\n /*\r\n // DD DSN=&&T,DISP=(OLD,DELETE)"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "doc",
    "info": "MAXPDSFTP determines the number of PDS members numbers to be considered before converting the inputfile into a PS file."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "secure",
    "info": "the parm \"SECURE_FTP REQUIRED\" in your FTPDATA parmlib used while satrting the FTP DAEMON task ensues that we use some secure FTP tools like Filezilla and not command prompt FTP to connect to the mainframe from PC."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "load module",
    "info": "ftp statements to transfer a load module. logging into the target system from source system.\r\n//STEP1 EXEC PGM=FTP //SYSPRINT DD SYSOUT=* //SYSIN DD * target ip userid password lcd 'xxxx.IBM.CDP.V1R1.SHBOLOAD' --- is the local file you want to ftp quote site LRECL=32760 RECFM=U BLKSIZE=32760 PDSTYPE=PDSE quote site directory=10 volume=eslpl0 mkdir 'ESLIBM.CDP.V1R1.SHBOLOAD' cd 'ESLIBM.CDP.V1R1.SHBOLOAD' mPUT * // //*"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "ftps and sftp",
    "info": "FTPS is FTP with SSL for security. It uses a control channel and opens new connections for the data transfer. ... SFTP (SSH File Transfer Protocol/Secure File Transfer Protocol) was designed as an extension of SSH to provide file transfer capability, so it usually uses only the SSH port for both data and control"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "theory",
    "info": "FTP and FTPS uses the task FTPD* and the SYSFTPD dd points to the FTPDATA member that has the parms. If we have TLS authentication as yes the regular FTP will not work. SFTP uses ssh and it has a tasks sshd* running on the system."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "active/passive",
    "info": "Active mode: server initiates data connection to the client, Passive mode: client initiates data connection to server\r\n If you need a passive ftp connection then check your parms fwfriendly and epsv4 one of them has to be set to TRUE."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "commands",
    "info": "iconv -f ISO8859-1 -t IBM-1047 TESTJCL2 > TESTJCL2.txt -- convert file to ascii in unix."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "ftps and sftp",
    "info": "FTPS (File Transfer Protocol with support for Transport Layer Security (SSL/TLS)), FTP (File Transfer Protocol) and SFTP (SSH File Transfer Protocol) are basically protocols that grants remote file transfer capabilities between a client and a server."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "ftps and sftp",
    "info": "What is FTPS?\r\n Concern about internet security grew during the 1990s. In response, Netscape created the Secure Sockets Layer (SSL, now known as TLS) protocol to protect communications over a network. SSL was applied to FTP to create FTPS. Like FTP, FTPS uses two connections: a command channel and a data channel. You can choose to encrypt both connections or only the data channel.\r\n FTPS authenticates your connection using a user ID and password, a certificate, or both. When connecting to a trading partner's FTPS server, your FTPS client will first check if the server's certificate is trusted. The certificate is considered trusted if either the certificate was signed by a known certificate authority (CA) or if the certificate was self-signed by your partner and you have a copy of their public certificate in your trusted key store. Your partner may also require that you supply a certificate when you connect to them. If your certificate isn’t signed by a third-party CA, your partner may allow you to self-sign your certificate, sending them the public portion beforehand to load into their trusted key store.\r\n User ID authentication can be used with any combination of certificate and/or password authentication."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "ftps and sftp",
    "info": "What is SFTP?\r\n While FTPS adds a layer to the FTP protocol, SFTP is an entirely different protocol based on the network protocol SSH (Secure Shell). Unlike both FTP and FTPS, SFTP uses only one connection and encrypts both authentication information and data files being transferred.\r\n SFTP provides two methods for authenticating connections. Like FTP, you can simply use a user ID and password. However, with SFTP these credentials are encrypted, giving it a major security advantage over FTP. The other authentication method you can use with SFTP is SSH keys. This involves first generating a SSH private key and public key. You then send your SSH public key to your trading partner and they load it onto their server and associate it with your account. When they connect to your SFTP server, their client software will transmit your public key to the server for authentication. If the public key matches your private key, along with any user or password supplied, then the authentication will succeed.\r\n User ID authentication can be used with any combination of key and/or password authentication"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "commands",
    "info": "lcd -- to check the local current working directory."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "logs",
    "info": "When OMVS starts it executes all the commands in /etc/rc from where SYSLOGD is generally started as \"export _BPX_JOBNAME='SYSLOGD1'\r\n /usr/sbin/syslogd -f /etc/syslogd.conf &\" and in SYSLOGD we have the satemetns for log file allocaitons for FTP, SSH, ssylogd and the backup statements.\r\n The -N parameter specifies that the file should be # automatically archived and then re-initialized when an archive event\r\n # occurs. syslog.conf file ahs the archive time parms too.\r\n we can also use *.INETD*.*.* /var/log/%Y/%m/%d/inetd -- this would create new files as per settings."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "stc",
    "info": "sshd starts and ends typically and in general. A forked copy of the daemon will be left running, which is\r\n normal"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "send file",
    "info": "send pax file from a to b -- from a\r\nftp to b\r\ncd to b locaiton\r\nbin\r\nput 'file on a' 'file on b'"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "setup",
    "info": "if we have the parm AUTH set to SECURED in FTPDATA then we can only connect using SECURED FTP tools from open systems. if we hav ethe AUTH parm set to ALLOWED we can use commnad promot (non secured) to connect and send / receive files."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "conv",
    "info": "default convertion that happens during FTP.\r\nGot the below updates from IBM. So, it is EBCDIC IBM-1047 to ASCII IBM-850. Let me know if this change is getting us the results.\r\n“ As you are running an FTP batch job, you are using the z/OS FTP client function and will connect to the remote FTP server in the PC.\r\nThere many ways to specify a character translation to the FTP client but if you did not customize anything to do so, the STANDARD translation table (STANDARD.TCPXLBIN) will be used. In this case, the character translation is between EBCDIC ibm-1047 and ASCII ibm-850.\r\nYou may need to use more appropriate code pages or translation tables, and this can be specified to the FTP client in the following search order:\r\n1. Data set specified in the SBDATACONN configuration statement in FTP.DATA 2. Data set specified in the SBTRANS configuration statement in FTP.DATA 3. user_id.FTP.TCPXLBIN 4. hlq.FTP.TCPXLBIN 5. user_id.STANDARD.TCPXLBIN 6. hlq.STANDARD.TCPXLBIN 7. The same translation tables established for the control connection I would recommend to use the SBDATACONN statement. It can be used for both FTP client and FTP server.\r\nIn the SBDATACONN statement, you can either indicate a translate table that you may customize or precise the desired code pages of the translation.\r\nIf you use the z/OS FTP client you can code this SBDATACONN statement either in the related FTP client FTP.DATA or within a locsite subcommand.\r\nSuch as: locsite SBDATACONN=(IBM-1047,IBM-819)\r\nYou have to determine which code page is used on each side, in particular on PC side.\r\nYou can find many samples of translation tables in both SEZATELX and SEZATCPX for specific national usage."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "batch",
    "info": "uploading multiple files to mainframe from PC using batch ftp.\r\n1. Download all the files to PC.\r\n2. rename the file names to 8 chars without extn (to be saved as members else not required).\r\nwe can use SHIFT+Rightclik to open the windows command prompt in the directory we are in.\r\n3. remove the extensions by issuing teh command ren *.BIN *.\r\n4. issue the command dir > myoutput.txt -- then we will get the output of the dir command in myoutput.txt file in your current working directory.\r\n5. open an excel sheet and open the myouput.txt file and use space as delimiter.\r\n6. use some logic and create the put statements using the concatenate function better get it as Put filename 'mainframe filename(member)'\r\n7. create ftp.txt file and add the following statement and the put statements generated in teh excel file.\r\nopen ipadress\r\nuserid\r\npassword\r\ncd mainframe file hlq (for some reason it is taking userid as HLQ by default attached to your CD location)\r\nlcd localfile loction.\r\nbinary\r\n8. issue the command ftp -s:ftp.txt > ftplog.txt -- in command prompt ensure that you are in the ftp.txt file location. this will run the command and produce the log in ftplog.txt in the location the commnd is run.\r\nor you can also save this command in a file and rename it as ftpstart.bat and double click it to run."
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "debug",
    "info": "If you could recreate the issue please collect following trace. userid is the task that FTPD1 STC is associated with. \r\nF FTPD1,DEBUG=(ALL,USERID(US0551A2))\r\nF FTPD1,DUMP=(21,USERID(US0551A2))\r\nresubmit client script \r\nD GRS,RES=(SYSDSN,mvsdatasetbname)\r\n \r\nWhen trace is done, turn off trace by command\r\nF FTPD1,DEBUG=(NONE)\r\nF FTPD1.NODUMP\r\n\r\nNote that the FTPD server trace will route to syslogd daemon facility"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "change password",
    "info": "command to change password using cmd ftp.\r\nuser userid oldpassword/newpasswrd/newpassord"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "general",
    "type": "website",
    "info": "https://support.broadcom.com/product/product-lifecycle-details.html?segment=MF\r\nlife cycle of CA products.\r\nhttps://support.broadcom.com/group/ecx/productlifecycle?"
  },
  {
    "Vendor": "BMC",
    "component/product": "general",
    "type": "support",
    "info": "https://webapps.bmc.com/support/faces/az/supportlisting.jsp"
  },
  {
    "Vendor": "compuware",
    "component/product": "general",
    "type": "support",
    "info": "https://mainframesupport.force.com/gateway/s/product-support-dates"
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware",
    "type": "MSU",
    "info": "Large Systems Programming Reference -- has the details of the hardware and the MSU capacity of all models available"
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware",
    "type": "chip status",
    "info": "D M=CHP(2A) -- chip status"
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware",
    "type": "processer",
    "info": "CPACF -- CP Assist for crypto graphic function."
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware",
    "type": "CUoD",
    "info": "Capacity upgrade on demand. allows the customer to initiate a permanent increase in processing capacity.\r\nif the capacity is required only for a short term then we can have IBM's On/Off Capacity on demand configured. (On/Off CoD)"
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware",
    "type": "CBU",
    "info": "Capacity Backup Upgrade : can help provide reserverd emergency backup capacity for all processor configurations."
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware",
    "type": "website",
    "info": "website that lists the IBM MF hardware and the types. models\r\nhttps://www-01.ibm.com/servers/resourcelink/lib03060.nsf/pages/lsprITRzOSv2r3?OpenDocument"
  },
  {
    "Vendor": "ibm",
    "component/product": "IMS",
    "type": "version",
    "info": "issue the command /f xxxx,display version -- xxxx IMS connect stc. Display the version of IMS we are running."
  },
  {
    "Vendor": "ibm",
    "component/product": "iodf",
    "type": "commands",
    "info": "D IOS,CONFIG -- display the IODF --- does the hardware and software update."
  },
  {
    "Vendor": "ibm",
    "component/product": "iodf",
    "type": "commands",
    "info": "/ACTIVATE iodf=xx,test --- test a new IODF for any errors"
  },
  {
    "Vendor": "ibm",
    "component/product": "iodf",
    "type": "commands",
    "info": "/ACTIVATE iodf=xx,soft=novalidate, --- activates only the software part of systems IODF updates and will not validate the"
  },
  {
    "Vendor": "ibm",
    "component/product": "ipcs",
    "type": "invocation",
    "info": "issue the command TSO IPCS to check if we get the panels."
  },
  {
    "Vendor": "ibm",
    "component/product": "ipcs",
    "type": "ispf invocation",
    "info": "when invoking IPCS if you run into an error with respect to allocating the DDIR dataset on a volume then try the command TSO %BLSCDDIR VOLUME(VSAM01) -- volume has to be a volume that we can allocate the DDIR dataset. the ddir by defatult uses SYS1.DDIR if noprefix is set in your profile or usierd.ddir if prefix is set to userid."
  },
  {
    "Vendor": "ibm",
    "component/product": "ipl",
    "type": "parmlib",
    "info": "if you want to change the IEASYM/PARMLIB statement midway of IPL due to some issue. Try the below command\r\n setload t1,ieasym,dsn=sys5.iplparm,vol=ziodf7 -- this command will look for LOADT1 in SYS5.IPLPARM and relook into the IEASYM parm.\r\n setload t1,parmlib,dsn=sys5.iplparm,vol=ziodf7 -- this command will look for LOADT1 in SYS5.IPLPARM and relook into the PARMLIB stat.\r\n setload ipl,ieasym -- this command will look for the load at the time of IPL."
  },
  {
    "Vendor": "ibm",
    "component/product": "ipl",
    "type": "notes",
    "info": "Out of habit, LOAD CLEAR (not RESET CLEAR) It' doesn't matter with z/OS\r\n though (or OS/390 before that). Though you can do RESET clear after you shut\r\n down the LPAR and that is the same as doing LOAD CLEAR when you IPL.\r\n z/OS clears the storage regardless. \r\n I'm not sure the last time it matter... probably before MVS/XA.It matters when IPLing stand alone dump not to clear storage.\r\n Whatever you problem was, doing LOAD CLEAR wasn't it.\r\n z/OS manual doesn't even mention clear because it's irrelevant. \r\n https://www.ibm.com/support/knowledgecenter/SSLTBW_2.3.0/com.ibm.zos.v2r3.ieag100/loadss.htm\r\n z/OS basics mentions that z/OS clears all central storage to zeros.\r\n https://www.ibm.com/support/knowledgecenter/zosbasics/com.ibm.zos.zsysprog/zsysprogc_systemIPL.htm"
  },
  {
    "Vendor": "ibm",
    "component/product": "ipl",
    "type": "hardware load",
    "info": "The initialization process takes place in the following order:\r\n1. Power on the computer.\r\n2. IML is automatically initiated.\r\n3. Hardware such as control processors, storage, and devices are powered on and checked.\r\n4. IML completes tasks.\r\n5. HMC screen is displayed on the console.\r\n6. Central processing complex is ready to IPL."
  },
  {
    "Vendor": "ibm",
    "component/product": "iptrace",
    "type": "trace",
    "info": "IP VERBX MTRACE --- last messagest that are issues and not captured... due to sisues."
  },
  {
    "Vendor": "ibm",
    "component/product": "iptrace",
    "type": "trace",
    "info": "IP ST W --- when the wait state is issued."
  },
  {
    "Vendor": "ibm",
    "component/product": "iptrace",
    "type": "trace",
    "info": "IP SYSTRACE ALL PERFDATA TIME(LOCAL) -- summary of the task using srbs"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "commands",
    "info": "to give a command use ZEXPAND and write the command in the POP UP panel. If it has been activated on the system. it works in the member and not outside of a member."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "commands",
    "info": "hide lines -- xx line command hides the lines"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "trace",
    "info": "ISPDPTRC-- this command is issued in 6 and it would start captring the trace of panels that we would use. Once you have used the panels to test re-issue the command to end the tace and display the resuts."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "setup",
    "info": "the ISPSTART command displays the default primary panel specified in the DEFAULT_PRIMARY_PANEL keyword in the ISPF configuration table. This keyword is typically set to ISP@MSTR."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "keys",
    "info": "use a PFKEY setting to ZEXPAND using the KEYS command. We can issues lenghtier tso commands."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "jobcard",
    "info": "ISERDIT MACRO for job card.\r\n ISREDIT MACRO \r\n SET Y=&SYSUID --- not used here but can be used to get better results. \r\n ISREDIT LINE_AFTER 0 = '//\"&SYSUID\"A,JOB TEST,'TEST',REGION=0M,' \r\n ISREDIT LINE_AFTER 1 = '// CLASS=A,MSGCLASS=X,' \r\n ISREDIT LINE_AFTER 2 = '// NOTIFY=&SYSUID' \r\n ISREDIT LINE_AFTER 3 = '/*JOBPARM L=9999' \r\n ISREDIT LINE_AFTER 4 = '//*'"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "alloc",
    "info": "TSO ALLOC FI(ddname) DA('dataset name') SHR REUSE"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "commands",
    "info": "Line commands\r\n BNDS : set boundaries for the text flow \r\n MASK : repeat the chars every time we insert a line.\r\n TABS : Creates tabs for a line and use the same for all line.\r\n TE   : To be able to write paragarphs without any intereption.\r\n TS   : To update a paragraph of sort. "
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "x all",
    "info": "X ALL -- to hide all lines\r\nF abc all -- shows all lines having the string ABC\r\nDEL X ALL -- to delete all hidden line\r\nDEL NX ALL -- to delete all non-exclued lines.\r\nSx -- line command to show hidden line. S1 -- opens up one hidden line. Needs to be given on the Hidden line.\r\nX ALL ' ' 1;DEL X ALL;SAVE --- deletes blank lines.\r\nHIDE X : to hide all the xcluded lines.\r\nFLIP : This command will flip the excluded lines for the non excluded lines. "
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "pfkeys",
    "info": "to see the pfkeys issue the command PFSHOW on command line. to hide the PF keys issue the command PFSHOW OFF"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "find",
    "info": "FIND P'###' -- To find a string of 3 numeric characters\r\nFIND P'.' -- To find any character that cannot be displayed\r\nCHG P'@@##' P'>>==' -- To change an alphabetic, alphabetic, numeric, numeric string so that the alphabetic characters become uppercase characters and the numeric characters are unchanged"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "command table",
    "info": "option 3.9 list the current command tables.\r\nWe can create a new user command tabe and update the commands in the user command table.\r\nIssu the command TSO ISPCCONF\r\nprovide a dataset with VB 255 and PDS with a member. continue from there to use the defaults or update any.\r\nselect option 5.Modify ISPDFLTS and Other DM Settings to create a new table."
  },
  {
    "Vendor": "Orcale",
    "component/product": "java",
    "type": "jsp",
    "info": "Java code can even be directly embedded into an HTML file, and compiled and run when the HTML file is requested. These are known as Java Server Pages (JSP)."
  },
  {
    "Vendor": "Orcale",
    "component/product": "java",
    "type": "servlet",
    "info": "In IBM terms, a servlet is a Java program that uses the Java Servlet Application Programming Interface (API) to access data on the mainframe."
  },
  {
    "Vendor": "Orcale",
    "component/product": "java",
    "type": "applet",
    "info": "A Java program that runs in a web browser that has been java configured."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "syntax",
    "info": "use dsn=&&abc,disp=(new,pass,pass) -- to create a temp dataset and pass it to the next step."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "syntax",
    "info": "use SYSTEM=xxxxx in the job card to specify on which system the job has to run in a JES2 MAS environment."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "idcams",
    "info": "job to delete the members of a PDS if the PDS is held by other running tasks\r\n//A93LNZZ$ JOB TEST,'TEST',REGION=0M,CLASS=A, // MSGCLASS=T,PRTY=15,NOTIFY=&SYSUID //STEP1 EXEC PGM=IDCAMS //DD1 DD DISP=SHR,DSN=SYS1.FILEAID.V17R02.SXVJLOAD //SYSPRINT DD SYSOUT=A //SYSIN DD * DELETE - 'SYS1.FILEAID.V17R02.SXVJLOAD(*)' FILE(DD1)\r\ndelete 'sys2.tet.tet' purge -- delete a nonexpiring dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "idcams",
    "info": "REPRO\r\n//STEP1 EXEC PGM=IDCAMS //DD1 DD DISP=SHR,DSN=SYS1.FILEAID.V17R02.SXVJLOAD //DD2 DD DISP=SHR,DSN=SYS8.COMPWARE.FAMVS.V17R02.SXVJLOAD //SYSPRINT DD SYSOUT=A //SYSIN DD * REPRO INFILE(DD2) OUTFILE(DD1) REPLACE"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "gdg",
    "info": "GDG cretion\r\n//STEP1 EXEC PGM=IDCAMS //SYSPRINT DD SYSOUT=* //SYSIN DD * DEFINE GDG(NAME(SYS3.OPSCCHK.SYSR.COMDOUT) - LIMIT(7) - NOEMPTY - SCRATCH) /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "temp",
    "info": "//SORTOUT DD DSN=&&TEMP,DISP=(NEW,PASS,DELETE), \r\n // UNIT=SYSDA, \r\n //SORTIN DD DISP=(OLD,DELETE,KEEP),DSN=&&TEMP"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "jcl example to use variables in sysin\r\n// EXPORT SYMLIST=(RM1DT,LPAR,VER) Multiple variables separated by ‘,’ \r\n// SET RM1DT=161213,LPAR=abc,VER=V12 \r\n//DELETE1 EXEC PGM=IDCAMS \r\n//SYSPRINT DD SYSOUT=* \r\n//SYSIN DD *, SYMBOLS=JCLONLY\r\nDELETE ALCSS.NONP.DCS.CADF.D&RM1DT.&LPAR..&VER \r\nIF MAXCC LT 12 \r\nTHEN DO SET MAXCC = 0 \r\nEND \r\n//*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "proc / multiple runs",
    "info": "//SMFUS36D JOB SMF,'MFSYSPG',REGION=0M,CLASS=U, \r\n// MSGCLASS=T,PRTY=15,NOTIFY=&SYSUID\r\n//L30W036D PROC HLQ1=HLQ1,LPAR=LPAR \r\n// EXPORT SYMLIST=(HLQ1,LPAR) \r\n//SETA SET HLQ1=&HLQ1,LPAR=&LPAR \r\n//SYSEDEL EXEC PGM=IDCAMS \r\n//SYSPRINT DD SYSOUT=* \r\n//SYSIN DD *,SYMBOLS=JCLONLY \r\nDELETE &HLQ1..&LPAR..L30W036D.SMF70.EXTRACT \r\nDELETE &HLQ1..&LPAR..L30W036D.SMF723.EXTRACT \r\n//STEP2 EXEC pgm\r\n//STEP3 EXEC pgm\r\n// PEND \r\n//SYSE EXEC L30W036D,LPAR=XXXX,HLQ1=SYS8.SMF \r\n//SYSF EXEC L30W036D,LPAR=XXXX,HLQ1=SYS8.SMF \r\n//SYSG EXEC L30W036D,LPAR=XXXX,HLQ1=SYS8.SMF \r\n//BE07SMFR EXEC PGM=IKJEFT01,COND=(5,LT) \r\n//SYSTSPRT DD SYSOUT=* \r\n//SYSTSIN DD * \r\nSUBMIT 'SYS5.CTS.JCL.SMF.CNTL(SMFUS38D)' \r\nSUBMIT 'SYS5.CTS.JCL.SMF.CNTL(SMFUS39D)' \r\nSUBMIT 'SYS5.CTS.JCL.SMF.CNTL(SMFUS40D)' \r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "data and time",
    "info": "use D&LMMDDYY. T&LHHMMSS. -- to get today's time and date."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "//TERSEQ EXEC PGM=TRSMAIN,PARM=PACK \r\n//SYSPRINT DD SYSOUT=* \r\n//INFILE DD DSN=LCL3M.BE07.SYSLOG.DAILY.G6218V00, \r\n// DISP=SHR \r\n//OUTFILE DD DSN=A93LNZZ.SYSLOG.MAR26TH, \r\n// DISP=(NEW,CATLG),DCB=(DSORG=PS,RECFM=FB,LRECL=1024), \r\n// SPACE=(CYL,(100,100),RLSE)"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "//TERSEQ EXEC PGM=AMATERSE,PARM=PACK \r\n //SYSPRINT DD SYSOUT=* \r\n //SYSUT1 DD DSN=LCL3M.BE07.SYSLOG.DAILY.G6218V00, \r\n // DISP=SHR \r\n //SYSUT2 DD DSN=A93LNZZ.SYSLOG.MAR26TH, \r\n // DISP=(NEW,CATLG),DCB=(DSORG=PS,RECFM=FB,LRECL=1024), \r\n // SPACE=(CYL,(100,100),RLSE)"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "Utility to seach for a string in the INPUT DD dataset names.\r\n//SEARCH EXEC PGM=ISRSUPC,\r\n // PARM=(SRCHCMP,ANYC,IDPFX,NOPRTCC)\r\n //NEWDD DD DSN=your.input.dataset,DISP=SHR\r\n //OUTDD DD SYSOUT=A\r\n //SYSIN DD *\r\n SRCHFOR 'string'[,t][,startcol][:stopcol]\r\n SRCHFORC 'string'[,t][,startcol][:stopcol]\r\n /*\r\n It will return maxcc = 1, if it finds the text in the specified PDS, otherwise it return zero"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "IEHMOVE Moves or copies sequential datasets."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "IEHPROGM Deleting and renaming datasets; catalog or uncatalog datasets other than VSAM.<"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "IEHCOMPR Compares data in sequential datasets."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "IEBEDIT Used to copy selected parts of a JCL. For Example, if a JCL has 5 steps and we require to execute step 1 and 3 only, then a IEBEDIT JCL can be coded with a dataset which contains the actual JCL to be executed. In the SYSIN of IEBEDIT, we can specify STEP1 and STEP3 as parameters. When this JCL is executed, it executes the STEP1 and STEP3 of the actual JCL."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "",
    "info": "//MATEKSD JOB MSGLEVEL=(1,1),NOTIFY=&SYSUID\r\n //*\r\n //* EXAMPLE TO SHOW IF CONDITION IN JCL\r\n //*\r\n //STEP01 EXEC PGM=IFCOND1\r\n //IFSTMT1 IF STEP01.RC = 0 THEN\r\n //STEP02 EXEC PGM=IFCOND2\r\n //STEP03 EXEC PGM=IFCOND3\r\n // ENDIF\r\n //STEP04 EXEC PGM=IFCOND4\r\n //STEP05 EXEC PGM=IFCOND5\r\n //IFSTMT2 IF STEP05.RC = 04 THEN\r\n //STEP06 EXEC PGM=IFCOND6\r\n // ELSE\r\n //STEP07 EXEC PGM=IFCOND7\r\n // ENDIF\r\n //STEP08 EXEC PGM=IFCOND8\r\n //*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "This basic example uses IEBUPDTE to add and replace JCL procedures to the data set named MY.PROCLIB:\r\n //ADDPROC1 JOB 1,SMCHUGH,MSGCLASS=X\r\n // EXEC PGM=IEBUPDTE\r\n //SYSPRINT DD SYSOUT=*\r\n //SYSUT1 DD DISP=OLD,DSN=MY.PROCLIB\r\n //SYSUT2 DD DISP=OLD,DSN=MY.PROCLIB\r\n //SYSIN DD DATA\r\n ./ ADD LIST=ALL,NAME=MYJOB1\r\n //STEP1 EXEC=SUZNX1\r\n //PRINT DD SYSOUT=A\r\n // (more JCL for MYJOB1)\r\n //SYSUDUMP DD SYSOUT=* (last JCL for MYJOB1)\r\n ./ REPL LIST=ALL,NAME=LASTJOB\r\n //LIST EXEC PGM=SUZNLIST\r\n // (more JCL for this procedure)\r\n //* LAST JCL STATEMENT FOR LASTJOB\r\n ./ ENDUP\r\n /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "utility",
    "info": "In this example, a block of three logical records is inserted into an existing member, and the updated member is placed in the existing partitioned data set.\r\n//UPDATE JOB ...\r\n//STEP1 EXEC PGM=IEBUPDTE,PARM=MOD\r\n//SYSPRINT DD SYSOUT=A\r\n//SYSUT1 DD DSNAME=PDS,UNIT=disk,DISP=(OLD,KEEP),VOL+SER=\r\n//SYSUT2 DD DSNAME=PDS,UNIT=disk,DISP=(OLD,KEEP), VOLUME=SER=111112\r\n//SYSIN DD *\r\n./ CHANGE NAME=RENUM,LIST=ALL,LEVEL=01,SOURCE=0\r\n./ NUMBER SEQ1=15,NEW1=20,INCR=5,INSERT=YES\r\n(Data statement 1)\r\n(Data statement 2)\r\n/"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "stc",
    "info": "to have a job that can run as an STC.\r\nwe can these jobs added to IEFJOBS DD in the MASTER Jcl. then we can issue the /START ABC. The ABC would have the required job card."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "srch proc",
    "info": "when we issue the /start xxx in the console. the system checks the IEFJOBS and then IEFPDSI and then JES2 proc concatenation to start the job or proc."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "command",
    "info": "jcl to issue MVS and JES2 commands -- just a job card and command statement can be used and run commands.\r\n//jobcard\r\n//MVSCMD COMMAND 'D symbolS'\r\n//MVSCMD COMMAND 'STOP SYSVIEW'\r\n//JESCMD COMMAND '$D JES2'\r\n//*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "command",
    "info": "jes command can also be issued\r\n/*$D SPL //A93LNZZ$ JOB TEST,'TEST',REGION=0M,CLASS=A, // MSGCLASS=T,PRTY=15,NOTIFY=&SYSUID,SYSTEM=SYST //MVSCMD COMMAND 'D SYMBOLS' //STEP1 EXEC PGM=IEFBR14"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "command",
    "info": "jes command can also be issued\r\n/*$D SPL /*$VS 'I SMF' ---- can be used to issue MVS commands.\r\n//A93LNZZ$ JOB TEST,'TEST',REGION=0M,CLASS=A, // MSGCLASS=T,PRTY=15,NOTIFY=&SYSUID,SYSTEM=SYST //MVSCMD COMMAND 'D SYMBOLS' //STEP1 EXEC PGM=IEFBR14"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "IKJEFT01",
    "info": "LISTC ENT('ibmuser.reports') -- listcat all the entries\r\nEX 'vendor.clist(rexxtest)' -- execute rexx \r\nSEND 'REXX pgm has run ' user(abcd) -- send messages to a user\r\n\r\nif one command fails all other after that commands still run. we can use IKJEFT0A to stop exection if one command fails."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "alias",
    "info": "create an alias for load module\r\n//LKED EXEC PGM=HEWL,PARM='LIST,AMODE=31,RMODE=ANY,RENT' //SYSLIN DD * SETCODE AC(1) INCLUDE SYSLIB(TCCENTCB) ALIAS IGYCRCTL(CEESTART) ALIAS TCCENTCB(CEESTART) ENTRY CEESTART NAME TCCENTCB(R) /* //SYSUT1 DD UNIT=SYSDA,SPACE=(1024,(200,20)) //SYSPRINT DD SYSOUT=* //SYSLMOD DD DSN=userid.yourname.LOAD,DISP=OLD //SYSLIB DD DSN=*.SYSLMOD,DISP=OLD"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "keywords",
    "info": "SCHENV=xxxx -- would allow the job to run any jobclass and it would override the default SCHENV for that job class"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "rename",
    "info": "jcl to rename a member of a pds\r\n//A93LNZZ$ JOB TEST,'TEST',REGION=0M,CLASS=T, // MSGCLASS=T,PRTY=15,NOTIFY=&SYSUID,SYSTEM=SYST //STEP1 EXEC PGM=IEHPROGM //DD1 DD VOL=SER=ZSPILL,DISP=OLD,UNIT=3390 //SYSPRINT DD SYSOUT=* //SYSIN DD * RENAME VOL=3390=ZSPILL,DSNAME=A93LNZZ.JCL.PROD, X\r\nNEWNAME=IEHCHK, X\r\nMEMBER=IEHCHK1 /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "region",
    "info": "to make the pgm run in a specific region space\r\n//ABC job 123,'yugi test',REGIONX=(512K,1G) -- This allows you to specifically define memory amounts below the line storage (16MB) and below the bar (above 16MB and below 2GB). In the example below, the first sub-parameter (512K) indicates the amount of memory to be assigned below the 16 MB line. The second sub-parameter indicates the amount of memory to be assigned above the 16 MB line, but below 2 GB (the bar)."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "notify",
    "info": "generally we use notify to send the end of job message to a user.\r\n//ABC job .....\r\nif you want to send that as an email\r\n//NOT1 NOTIFY email='ypothuru.cw@mmm.com',type=email\r\nif you want to send the job end message to multiple users then code\r\n//NOT1 NOTIFY user=xyz1,type=msg\r\n//NOT2 NOTIFY user=xyz2,type=msg\r\nusing when conditions\r\n//NOT1 NOTIFY user=xyz1,type=msg\r\n// when='(RC=4 | RC=8)'"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "dynamic dsn",
    "info": "//jobname proc\r\n//iefproc exec pgm=iebgener\r\n//sysut1 dd ddname=iefrder\r\n//sysut2 dd sysout=*\r\n//sysin dd *\r\nnow you can supply teh iefrder as follows /S jobname,DSN=filename,disp=shr and it get replaced when the proc is started."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "xmit",
    "info": "Xmit is used to send files form one node to another connected node.\r\n//STEP1 EXEC PGM=IKJEFT01 //SYSTSPRT DD SYSOUT=* //SYSTSIN DD * XMIT xxxxx.yyyyyyy PDS DSNAME('xxxxxxx.JCL.PROD') /* xxxxx -- node name of the system that we are planning to send the data.\r\nyyyyyy -- username."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "receive",
    "info": "RECEIVE is used to receive any files that got transmitted to that system by another nodes in the system complex.\r\n//* Job to receive the transmitted files. //* syn: RECEIVE INDSN('dataset name transmitted') //* : DA('name of the dataset to used used for receving') //* //STEP1 EXEC PGM=IKJEFT01 //SYSTSPRT DD SYSOUT=* //SYSTSIN DD * RECEIVE USERID(A93LNZZ) DA('xxxxxxx.JCL.PROD.RECV') /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "rename",
    "info": "//step1 exec pgm=ikjeft01\r\n//systsprt dd sysout=*\r\n//systsin dd *\r\nrename 'abc.xyz' 'abc.def' --- to rename a pds\r\nrename 'abc.**' 'abc.def.**' -- to rename mutiple datasets with the same hlq\r\nrename 'abc.xyx(123)' (456) -- to rename mebmer of a pds\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "region",
    "info": "REGION : REGION parameter to specify the amount of central or virtual storage that the step requires\r\n0M : can get us a maximum of 2G if that much of space is available below the bar. Which is not available at any time. If no REGION parameter is specified, the system uses an installation default specified at JES initialization. It can also check the IEFUSI and IEALIMIT exits.\r\n\r\nRegion parm by default is specified for a user when creating an ID in racf(picked when logging in by default). It can also be defined with JOBCLASS(TSU)."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "cond",
    "info": "Job Card--COND=(value,parm) --- Value -- is the one that is looked to stop the job. Parm specifies the condition for the value.\r\nStep -- COND=(value,parm,stepxx,even/only)\r\nValue : 4,8,16...\r\nPrameter : Greater than(GT), Less than (LT), Greaterthan or equal (GE), Lessthan or equal(LE), Equal(EQ), Noteqal(NE)"
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "cond",
    "info": "cond on JOB statement if the RC of any step satifies the condition then all the remaining steps will not be executed.\r\nOn a step we can use only or even for each step and verify it with previous step RC."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "if..then..else",
    "info": "//job\r\n//step1 exec pgm=\r\n// IF RC>=08 THEN\r\n// ....\r\n// ELSE\r\n//STEP04 exec pgm=\r\n//....\r\n// ENDIF"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "jclcheck",
    "type": "invocation",
    "info": "can be done by !JCK or EJCK -- generally but different sites might have different ones."
  },
  {
    "Vendor": "ASG",
    "component/product": "Jclprep",
    "type": "Ver check",
    "info": "Mostly Panels"
  },
  {
    "Vendor": "IBM",
    "component/product": "JES2",
    "type": "proclib",
    "info": "$D jobclass(stc),proclib -- you can issue this command to identify the proclib concatention that JES2 uses to search for a stc while starting."
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "setup",
    "info": "to identify the systems particiapting in JES2 MAS -- /$D MEMBER"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "commands",
    "info": "find the name of the running (job/stc/tsu) with the task number /$d stcxxxx, /$d tsuxxxx, /$D jobxxxx"
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "dd",
    "info": "if we have an include statement in jes2 proc then the system looks for the member in IEFPDSI DD concatenation in MSTJCLxx proc."
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "dd",
    "info": "if we have an include statement in proc then the system looks for the member in JES2 proc DD concatenation."
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "commands",
    "info": "if a job is in input and not getting into execution queue try $S jxxxx -- xxxx is the job number."
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "commands",
    "info": "$P XEQ -- To prevent JES2 and WLM-controlled initiators from selecting work."
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "commands",
    "info": "$S XEQ -- To allow JES2 and WLM-controlled initiators to select work"
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "jcl, submit job",
    "info": "Jcl to submit a job in a step.\r\n //STEPXXXX EXEC PGM=IKJEFT01\r\n //SYSTSPRT DD SYSOUT=*\r\n //SYSTSIN DD *\r\n SUBMIT 'MY.JCL(MEMBER)'\r\n /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "jcl",
    "info": "COND parm in JCL step.\r\n COND=(4,LT) read it as follows: \r\n If 4 is less than any condition code issued so far, DON'T execute this step."
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "commands",
    "info": "$POJOBQ,ALL,PROTECTED,DAYS>7 -- deletes all the jobs from sdsf that are greater than 7 days."
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "init",
    "info": "$Si1-3,c=F -- to start init 1,2,3 in class F"
  },
  {
    "Vendor": "ibm",
    "component/product": "JES2",
    "type": "init",
    "info": "$si1-3 -- to start init 1,2,3"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "jobclass",
    "info": "to modify jobs class SWA to below or above. /$t jobclass(x),swa=above/below."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "commands",
    "info": "check jes2 mas -- $D MEMBER"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "ZJC -- Zone Job Container -- The JOBGROUP statement defines a job group. This identifies the name and attributes of the group. JOBGROUP definition starts with a JOBGROUP statement and ends with an ENDGROUP statement. Data for job groups is stored in a data area called a ZJC.\r\n$D GRPDEF -- display the group defitnition like no. of ZJC, Free, warn.\r\n$T GRPDEF,xxxx=yyyy -- to update the ZJC..."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "VTMB -- VTAM buffers : SNABUF on TPDEF"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "TTAB -- Trace Tables : TABLES on the TRACEDEF statement"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "TGS -- SPOOL space/track groups : TGSPACE=(MAX=) on the SPOOLDEF statement"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "TBUF"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "SMFB -- System management facility buffers : BUFNUM on the SMFDEF statement"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "NHBS -- NJE header/trailer buffers : HDRBUF on the NJEDEF statement"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "LBUF -- Logical buffers : BELOWBUF on the BUFDEF"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "JQES --- Job queue elements -- this would be the no. of jobs in the jes2 queue. jobs that can be in the JES2 job queue at any given time. This value includes all TSU, STC jobs, and batch jobs\r\n$D jobdef --- look for JOBFREE, JOBNUM and JOBWARN values these are releated to the JOB Queue\r\n$T jobdef we can update these values.\r\nwe can also delete any old jobs in output queue. /$P OJOBQ,ALL,PROTECTED,DAYS>7"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "JOES -- Job output elements : JOENUM on the OUTDEF statement\r\n$D OUTDEF -- dispay the definition of the JOES.\r\n$T OUTDEF -- to update any values.\r\nwe can use the command /$P OJOBQ,ALL,PROTECTED,DAYS>7. Which would also release JOES."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "JNUM ---of assignable job numbers (speci®ed through the RANGE= parameter) that have been used for jobs submitted at the local node . check the value with $d jobdef. JES2 assigns as JOBIDs to jobs which originated on the local node. these are the starting and ending number that JES2 / Master assings for any tasks starting in local node. like STC12345, JOB99999 --- the number depends on the RANGE parm values.\r\nwe can delete unwanted jobs in the queue if you are reaching your highest range number and no JOBNUMARN is above 80 or 90%.\r\nwe can delete any old jobs in output queue. /$P OJOBQ,ALL,PROTECTED,DAYS>7"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "ICES -- VTAM® sessions $D U,TP -- displays the displays the status of all lines and the JES2/VTAM interface.\r\n$D TPDEF -- to display the JES2 teleprocessing characteristics. Look for the SESSIONS parameters for the available VTAM sessions.\r\n$T TPDEF -- to update the numbers."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "CMDS -- : CMDNUM on the CONDEF statement --- no. of JES2 commands that can be queued. $D CONDEF\r\n$T CONDEF"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "CMBS -- Console message buffers : BUFNUM on the CONDEF statement"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "CKVR -- Checkpoint versions : NUMBER on the CKPTDEF statement"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "BUFX -- Extended logical buffers : EXTBUF on BUFDEF"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "BSCB -- Bisynchronous buffers : BSCBUF on TPDEF"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "resource",
    "info": "BERT -- Block Extension reuse tables defined in the checkpoint : BERTNUM on CKPTSPACE\r\n$D CKPTSPACE\r\nST CKPTSPACE"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "status",
    "info": "$jD DETAILS -- lists all resource status (TBUF, CMBS, BERT, BUFX)"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "command",
    "info": "$JDHISTORY -- history of jes2 resources in hourly interval.\r\n$JD HISTORY(BERT) or any other resource gives the details of that resource alone."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "commands",
    "info": "to purge multiple jobs with name\r\n/$po jq,jm="
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "stages",
    "info": "Input -> Conversion -> Processing -> Output -> Hardcopy -> Purge."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "checkponint",
    "info": "$D PERFDATA(CKPTSTAT) -- checkpoint statistics"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "command",
    "info": "to issue command at specfic intervals\r\n/$ta(id number)"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "keywords",
    "info": "SCHENV=xxxx -- would allow the job to run any jobclass and it would override the default SCHENV for that job class"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "job",
    "info": "$t jxxxx,schenv=yyyy --- to change a running jobs scheduling env."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "line",
    "info": "line(nnnn).jt(n) -- job transmitter\r\nline(nnnn).st(n) -- sysout job transmitter\r\nline(nnnn) -- NJE/RJE SNA, BSC, TCP/Ip lines."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "SAPI",
    "info": "The SYSOUT Application Program Interface (SSI function code 79) allows JES to function as a server for applications needing to process SYSOUT data sets residing on JES spool. Use of the SAPI SSI call allows a user-supplied program to access JES SYSOUT data sets independently from the normal JES-provided functions (such as print or network). Users of this function are application programs operating in address spaces external to JES. SAPI supports multiple, concurrent requests from the applications' address spaces. Each issuer of the IEFSSREQ macro is referred to as an \"application thread.\""
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "scheduling",
    "info": "//sched1 jobgroup //job1 gjob\r\n//job2 gjob // after name=job1,when=(rc=0)\r\n//job3 gjob // after name=job1,when=(rc=8)\r\n//job4 gjob // after name=job1 --- we can use after, before, concurrent\r\n// after name=job3\r\n//sched1 endgroup //job1 job .....\r\n// schedule jobgroup=sched1,\r\n// holduntil='+3:00'\r\n//step1 exec pgm=iefbr14\r\n//*\r\ndefines a group of jobs and they can scheduled based on few simple conditions."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "command",
    "info": "JES2 EDS -- electronic email distribution services. uses zOSMF to send the emails. Start and addr space $EDSQnnnn job when ever a email request is done in the NOTIFY parm of JCL.\r\n$DS($EDSQ*) -- command to display any jobs and their status related to the emails.\r\nEDS message queue entries in the JES2 checkpoint (ESQs).\r\n• $EDSQnnnn system jobs. Each email message queue has an associated $EDSQnnnn job.\r\n. a customized subject line can be con®gured by using the NFY_SUBJECT keyword of the JOBDEF JES2 command or initialization statement"
  },
  {
    "Vendor": "Ibm",
    "component/product": "Jes2",
    "type": "Command",
    "info": "To start a job that is in input status for some reason try the command $sjjobnumber"
  },
  {
    "Vendor": "ibm",
    "component/product": "Jes2",
    "type": "stages",
    "info": "input -- reads the input data, assigns a job identifier, places the job jcl onto DASD datasets called spool.\r\nconversion -- reads the jcl, analyzes for any erros and if no erros converts to machine language. if any errors stop procssing and send the job for output processig.\r\nprocessing -- send jobs for execution on zos.\r\nouput\r\nhardcopy -- printing.\r\npurge"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "dup jobs",
    "info": "you can configure JES2 to allow jobs of the same name to execute at the same time, the DUPL_JOB parameter in the JES2 initialization deck controls this.\r\nyou could enter the $D DUPJOB command"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "start",
    "info": "If you need more control during a JES2 startup, then consider using the S JES2,PARM=CONSOLE command. This will read and process existing JES2 initialization statements and then prompt the operator for any additional statements before initialization takes place.\r\n\r\nThis allows you to include a new statement to be used as part of this initialization or override a previous statement that has been entered."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "alternate",
    "info": "we can have 2 jes2 running at the same time\r\n1) Create JES2A proc wth just one or 2 proclibs.\r\n2) remove teh RJE and NJE and any start command in the parm file\r\n3) Create a small checkpoint and spool datasets and update jes2 parm.\r\n4) Update the CONCHAR character to a new PREFIX for new JES2\r\n5) Define the alterate JES in subsystem table. SETSSI ADD,SUB=JES2A\r\n6) Ensure XCFGRPNM is set to unique value for JESXCF, as a MASDEF member.\r\n7)"
  },
  {
    "Vendor": "Open systems",
    "component/product": "kubernetes",
    "type": "Kubernetes",
    "info": "Kubernetes is a kind of orchestration tool for container manipulaiton/confiugraiton/implementation.\r\nHow it runs : MASTER(Hardware + OS -- funcitons controls Worker nodes) + (Worker nodes(Hardware --> OS (windows/linux) --> docker Engine --> Kube-Proxy --> Kubelet-->(container) --> service(exposes the container application to network))\r\nMaster has a functionality (Kubernetes API server + scheduler + controller manager _ etcd)\r\nMultiple of worker nodes are controlled by the Master.\r\nKUBECTL tool is used to communicate with the Kubernetes API server running in the MASTER.\r\n\r\nKubernetes is from google.\r\nother tools for container orchestration are Docker Swarm (docker), MESOS (apache)"
  },
  {
    "Vendor": "IBM",
    "component/product": "learning",
    "type": "website",
    "info": "https://www.slideshare.net"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "learning",
    "type": "website",
    "info": "https://community.broadcom.com/education/communities/community-home/librarydocuments?communitykey=bd92ecf3-d291-44ae-87ef-f17f7697397e&tab=librarydocuments&LibraryFolderKey=&DefaultView="
  },
  {
    "Vendor": "Broadcom",
    "component/product": "License",
    "type": "License",
    "info": "For all CA products Identify the CA common services initialization proc and look for KEYS DD. You can also check the IPL SYSLOG and the statements in KEYS DD are written to SYSLOG if the task is started under MSTR."
  },
  {
    "Vendor": "macro4",
    "component/product": "License",
    "type": "view",
    "info": "issue the command LMVIEW as line command against a Macro4 license key member to check the license information. Generally the license is in unreadable format."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "License",
    "type": "website",
    "info": "https://techdocs.broadcom.com/content/support/en_us/product-content/recommended-reading/technical-document-index/ca-licensing---lmp-listing.html --- product corresponing to lmp key."
  },
  {
    "Vendor": "ibm",
    "component/product": "linklist",
    "type": "dynamic",
    "info": "LNKLST UNDEFINE NAME(LNKLSTAA) --- to ensure the new linklist name is not available \r\nLNKLST DEFINE NAME(LNKLSTAA) COPYFROM(CURRENT) \r\nLNKLST ADD NAME(LNKLSTAA) DSN(SYS1.TS55.SDFHLINK.CHCK) VOLUME(TCH301) --- make any changes.\r\nLNKLST ACTIVATE NAME(LNKLSTAA) -- actiating the new linklst \r\nLNKLST UPDATE,JOB=* -- updating all active tasks to use the ative linklst \r\nLNKLST UNALLOCATE -- you cna use unallocate to free lnklst dataset from XCF enqueue \r\nLNKLST ADD NAME(LS01) DSN(SYS1.TS55.SDFHLINK.CHCK) VOLUME(TCH301) \r\nLNKLST ACTIVATE NAME(LS01) \r\nLNKLST UPDATE,JOB=* yOu can issue these commands one after the other in the log or you can create a member PROGxx in your PARMLIB concatenation and issue the command \r\n/SET PROG=xx to update."
  },
  {
    "Vendor": "ibm",
    "component/product": "linklist",
    "type": "dynamic",
    "info": "/setprog LNKLST,DEFINE,NAME(LNKLSTAB),COPYFROM(CURRENT) \r\n/setprog LNKLST,DELETE,NAME(LNKLSTAB),DSN(SYS2.SYSVIEW.&CASYSV..CNM4BLOD)\r\n/setprog LNKLST,DELETE,NAME(LNKLSTAB),DSN(SYS2.SYSVIEW.R142.CNM4BLOD)\r\n/setprog lnklst,add,name(lnklstab),dsn(SYS2.SYSVIEW.&CASYSV..CNM4BLOD),volume(tch303)\r\n/setprog LNKLST,ACTIVATE,NAME(LNKLSTAB) \r\n/setprog LNKLST,UPDATE,JOB=* \r\n \r\n /setprog LNKLST,UNDEFINE,NAME(LNKLSTAB)"
  },
  {
    "Vendor": "ibm",
    "component/product": "logr",
    "type": "logstream structure",
    "info": "Once the data in the structure reaches the defined highoffload threshold, this data will be offloaded to offload datasets (LOGR.ATR.PLEX1.xxxxx.A00000nn). The logstream data on the structure will also be written to offload datasets on disconnect (when RRS is shutdown for example)."
  },
  {
    "Vendor": "ibm",
    "component/product": "mainframe",
    "type": "jcl",
    "info": "https://github.com/billrain/MainframeJCL"
  },
  {
    "Vendor": "ibm",
    "component/product": "manuals",
    "type": "website",
    "info": "https://www.ibm.com/docs/en/zos/2.5.0?topic=zos-mvs"
  },
  {
    "Vendor": "Mackenney",
    "component/product": "MAPR-II",
    "type": "License",
    "info": ""
  },
  {
    "Vendor": "ibm",
    "component/product": "mvs",
    "type": "commands",
    "info": "/RO *all,D A,l -- issue the D A,L command to all the systems in the sysplex"
  },
  {
    "Vendor": "ibm",
    "component/product": "mvs",
    "type": "commands",
    "info": "/RO T=10,*all,D A,l -- issue the D A,L command to all the systems in the sysplex -- waits for 10 seconds for the response"
  },
  {
    "Vendor": "ibm",
    "component/product": "GRS",
    "type": "commands",
    "info": "check if a dataset is shared across systems : d grs,res=(*,datasetname)"
  },
  {
    "Vendor": "ibm",
    "component/product": "mvs",
    "type": "utility",
    "info": "ADRDSSU restore utility:\r\n//STEP1 EXEC PGM=ADRDSSU //DASDIN DD DISP=SHR,DSN=SYS5.CTS.IBMCDP.DUMP, // UNIT=SYSDA //DASDOUT DD DISP=SHR,VOL=SER=TCH304,UNIT=SYSDA //SYSPRINT DD SYSOUT=* //SYSIN DD * RESTORE INDD(DASDIN) OUTDD(DASDOUT) - DATASET(INCLUDE(IBM.CDP.**)) - CATALOG - RENAMEU(IBM.**, SYS2.**) /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "page dataset",
    "info": "jcl to add page dataset.\r\n//DEFPGSPC EXEC PGM=IDCAMS\r\n//SYSPRINT DD SYSOUT=* \r\n//SYSIN DD * \r\nDEFINE PAGESPACE ( - \r\nNAME(SYS1.SYST.PAGE5L) - \r\nCYLINDERS(800) - \r\nVOLUME(PAGET1)) \r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "page dataset",
    "info": "command to add a page dataset /PA page=defined page dataset name."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "page dataset",
    "info": "PD DRAIN,PAGE=SYS1.SYST.PAGE5L -- Drain a page"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "page dataset",
    "info": "PD REPLACE,PAGE=(SYS1.SYST.PAGE5L,SYS1.SYST.PAGE7L) -- Repalce a page dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "mvs",
    "type": "commands",
    "info": "cancel a task in starting status : /C STARTING,A=asid"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Netmaster",
    "type": "commands",
    "info": "To see all the attributes which are available to Netmaster (but you might not be collecting on them)\r\n \r\n logon to NM\r\n issue /monattr\r\n then issue showall from command line"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "netmaster",
    "type": "level",
    "info": "/level -- to know the current running version"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "netmaster",
    "type": "$$SYSPRO NMDIAG",
    "info": "to check the system profile and the diagnostics of our task."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "netmaster",
    "type": "bestpractie",
    "info": "One STC as FOCAL and other systms tasks as SUBORDINATE so all the tasks can be see under FOCAL"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "netmaster",
    "type": "",
    "info": "== to goback to primary menu"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "netmaster",
    "type": "",
    "info": "/encsum -- encryptions summary data"
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "D NET,MAJNODES -- list all the majnodes"
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "d net,appls -- status of application major nodes."
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "D NET,ID=xxxx -- lists information for a specific node."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "D net,topo -- display topology database."
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "V NET,ACT,ID=…"
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "V NET,INACT,ID=…"
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "S NET,,,(LIST=E1) -- this will start the net stc and it will look for ATCSTRE1 in the VTAMLST DD concatenated datasets."
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "S NET,,,(01) -- this will start the net stc and it will look for ATCSTR00 in the VTAMLST DD concatenated datasets."
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "D NET,VTAMOPTS -- lists all the options."
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "/D NET,ID=applid -- displays the connectivity sataus."
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "v net,act,id=applid,status=u -- activate the node and all the sub-ordinate nodes of the mentioned ID."
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "startup",
    "info": "start vtam --> looks for ATCSTRxx in the VTAMLST DD datasets and looks for ATCCONxx in ATCSTRxx and starts major nodes"
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "commands",
    "info": "d net,rsclist,id=* -- list all the minor nodes and the corresponding major nodes."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "d net,directry,id=xxxx,scope=nsearch -- searches the network for the resoruce mentioned in ID."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "f net,directry,function=delete,id=xxxx -- deletes the xxxx resoruce from central directory -- directory again conducts a update function whenever it detects a change. Topology Database Update (TDU)."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "to get the acb of a tso session issue the command D NET,TSOUSER,ID=xxxxxxx"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "port",
    "info": "TSO NETSTAT PORTLIST -- list all the connections."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "",
    "info": "/MODIFY RESOLVER,DISPLAY -- to get the active TCPPARMS dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "profile",
    "info": "to update the entries in PROFILE member of TCPPARMS dataset.\r\n VARY TCPIP,,O,USER99.TCPIP(OBEYFIL2)"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "search order",
    "info": "list summarizes the resolver search order\r\n 1. GLOBALTCPIPDATA statement\r\n 2. /etc/resolv.conf file\r\n 3. userid.TCPIP.DATA\r\n 4. SYS1.TCPPARMS(TCPDATA)"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "port",
    "info": "tso netstat (port xxxx -- to check if a port is active or not. / tso netstat conn (port xxxx"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "nameserver",
    "info": "//TESTJOB1 JOB CLASS=A,MSGCLASS=X,MSGLEVEL=(1,1),NOTIFY=&SYSUID //STEP1 EXEC PGM=PING,PARM='PROXY.COGNIZANT.COM' //SYSTCPT DD SYSOUT=* lists a lot of information : res_init Resolver values: Setup file warning messages = No CTRACE TRACERES option = No Global Tcp/Ip Dataset = USER.TCPPARMS(TCPDATA), Default Tcp/Ip Dataset = None , Local Tcp/Ip Dataset = TCPIP.TCPIP.DATA Translation Table = TCPIP.STANDARD.TCPXLBIN, UserId/JobName = IBMUSER Caller API = TCP/IP Sockets Extended, Caller Mode = EBCDIC System Name = S0W1 (from VMCF) , UnresponsiveThreshold = 25 (G) DataSetPrefix = TCPIP , Hostname = RDZUT0 (G) TcpIpJobName = TCPIP (G) DomainOrigin = RTP.IBM.COM (*) NameServer(s) = None (*) NsPortAddr = 53 (G) ResolverTimeout = 30 (G) ResolveVia = UDP (G) ResolverUdpRetries = 1 (*) Options NDots = 1 (*) SockNoTestStor (G) AlwaysWto = NO (G) MessageCase = MIXED (*) LookUp = DNS LOCAL"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "nameserver",
    "info": "TSO NSLOOKUP to get the details of lookup server."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "resolver",
    "info": "F RESOLVER,REFRESH -- if any updates to TCPDATA parms, IPNODES in SYSX.TCPPARMS dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "resolver",
    "info": "f resolver,refresh,setup=yugi001.jcl.cntl(resolver) -- you need create members RESOLVER with links to TCPDATA and IPNODES if changes are being made. example : DEFAULTTCPIPDATA('TCPIP.TCPPARMS(RESLVCF)') -- this activates all the data in TCPIP.TCPPARMS(RESLVCF)."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "D TCPIP,TN3270,TELNET,CONN"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "D TCPIP,,NETSTAT,DEV -- list the osa activity. We can check the packets transfer status."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "telnet",
    "info": "tso telnet ip port to check the connectivity."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "theory",
    "info": "Non-Repudiation : a situation in which we need to confirm that a transaction has happened by both the parties at each end of the transaction. A sender to not deny that he has sent the packet and a receiver not to eny that he has received the packet."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "theory",
    "info": "tcp/ip includes firewall filtering, virtual private network(vpn), and transport layer security(tls) capabilities as part of the protocol stack itself and to encrypt network traffic."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "theory",
    "info": "different layers in a Network between the end pointss : Application(telnet, ftp, SMTP), transportation((TCPIP/UDP) (uses SSL/TLS secuirty contorls)), network(IP/ICMP), datalink and physical(end point port connection (lanport or wifi for PC and OSA card for mainframe))."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "theory",
    "info": "link layer protocols : Ethernet (standard define by IEEE 802.3), Token Ring, Fibre Distributed Data interface (FDDI), Asynchronous Transfer Mode(ATM) and other protocols. OSA Card can support the 802.3 suite of standards (802.3ae) in the form of 10 Gbps."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "theory",
    "info": "MAC address -- every host has to be identified to the network so they can locate each other. This is done by MAC (Media access control) address."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "theory",
    "info": "IP -- is the standard for routing packets across interconnected networks."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "startup",
    "info": "D NET,VTAMOPTS,FUNCTION=VTAMINIT -- we will get all the startup options used."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "tls",
    "info": "trls display -- D NET,TRL -- The DISPLAY TRL (transport resource list) command provides information about the active TRL major nodes or about a single TRLE (transport resource list entry)."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "types",
    "info": "FTPS (File Transfer Protocol with support for Transport Layer Security (SSL/TLS)), FTP (File Transfer Protocol) and SFTP (SSH File Transfer Protocol) are basically protocols that grants remote file transfer capabilities between a client and a server."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "notes",
    "info": "UDP (User Datagram Protocol) is an alternative communications protocol to Transmission Control Protocol (TCP) used primarily for establishing low-latency and loss-tolerating connections between applications on the internet"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "notes",
    "info": "Port forwarding is a type of interaction between two applications, usually TCP/IP applications, that talk to each other using an SSH connection. SSH intercepts a service request from a client application on a host, creates an SSH session carrying the request to the other side of the SSH connection"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "connectivity",
    "info": "from our local system -- using internet -- tcpip on mainframe -- telnet server (tn3270) -- vtam (sna application)-- appl (tso,cics)"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "nodes",
    "info": "adjacent nodes : D NET,ADJSSCPS"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "connectivity",
    "info": "TSO -- Telnet client(pc tn3270 software) --> TCPiP (stc) -- > Telnet server (tn3270 stc) --> VTAM(stc) --> TSO node definition."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "npf - (network print facility)",
    "info": "Route the JES or VTAM print data from your system to printers in the tcp/ip network. Lets you decide where and how output will be printed through the use of routing and options file. We can use options to check on the routing and otpions definitions if we dont know the fields values to be used to list then run an simple IDCAMS job to copy the ROUTING, OPTIONS VSAM files to a dataset and we can check for these values."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "tls applications",
    "info": "-D TCPIP,,N,TTLS -- to check what applicaitons are using at-tls"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "port check",
    "info": "-D TCPIP,,N,CON,PORT=990 -- to check the port activity\r\n-d TCPIP,tcpip stc,N,CON,MAX=all ---- to check all the current acitve port connectivity on the system."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "to check the restricted applications\r\nd tcpip,tn3270x,obj,type=arappl -- restricted application as in tn3270 profile.\r\nd tcpip,tn3270x,obj,type=uss -- Unformatted system serverices table name provided from the tn3270 profile"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "to check the userid lu and other details - d net,id=userid,u"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "architectur",
    "info": "TCPIP -- (telnet,ftp,smtp,socket protocol) --> TCP UDP --> (IP ARP RARP ICMP) --> Datalink --> Physical\r\nOSI (Open systems interconnect) -- Applicaiton --> presentation --> session --> Transport --> Network --> Datalink --> physical\r\nSNA (Systems network architecture) -- (Transaction services --> NAU services management --> Data flow control )--> Tansmission control --> path control --> Datalink control --> physical ."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "communication server",
    "info": "Communication Server -- comprises of VTAM, TCPIP and CSM (Common storage manager managed by VTAM) is used by TCPIP for I/O buffering"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "tcpip",
    "info": "TCP/IP can work with other protocols, such as FTP, Telnet, TN3270, and HTTP servers, enabling communication to occur between applications running on basically any operating system."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "d net,csmusr -- provides the % of I/O buffer used by TCPIP and VTAM."
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "TN3270",
    "info": "Tn3270 clinet running on the PC does the conversion of datastreams into ASCII or EDCDIC.\r\nTN3270 server performs ASCII/EBCDIC codepage conversions for line mode connections."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "TN3270",
    "info": "all sessions have to be initiated from the tn3270 client. Even a printer session must be started from the client work station before SNA session can send print data over the printer session."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "tn3270",
    "info": "z/OS Communications Server has implemented the possibility of using a shared ACB for Telnet logical units (LUs) as a way to reduce extended common storage area (ECSA) usage. for each OPEN ACB issued by the TELNET process, VTAM allocates control blocks in ECSA"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "tcpip comds",
    "info": "TCPIP (D TCPIP,,NETSTAT,): HOME (base IP addresses) DEV (list out the devices that TCPIP talks to the rest of the world over) CONFIG (similar to doing a VTAMOPTS in VTAM) CONN (show all of the active connections to the applications)\r\nPORTL (shows the ports that have been pre-defined to TCPIP) SOCKETS (similar to doing a SESSIONS in VTAM)"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "tcpip comds",
    "info": "D TCPIP,,OMPROUTE,OSPF,LIST,ALL (list all of the OSPF connections - this also shows the Neighbors that the OSA defs knows about) D TCPIP,,OSAINF,INTFN=interface-name (List out what connections the interface is directly talking to) D TCPIP,,SYSPLEX,VIPADYN (shows all of the VIPA connections - similar CPCP in VTAM)\r\nd net,cpcp"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "vtam comds",
    "info": "VTAM: (D NET,): VTAMOPTS (Base setup for the start up of VTAM) CPCP (get the other Connection Points that this VTAM talks to) MAJNODES (and, maybe, display a couple of them later) ISTLSXCF,E (XCF connection names. Once you have a list do a D NET,ID each entry) TRL (then display (,ID=) for each entry to find out what portion go to either OSA or directly to IP) CDRSCS (watch the MAX= count) COS (name of the default Class Of Serice table) GROUPS (line groups - will also show XCA names as well as defined lin\r\nRTPS (HPR pipes) TRACES (what traces are in effect at this point in time - typically used for diagnostic use w/ IBM) USERVAR (alternate name for VTAM resources ie - UK01T can be accessed typing UK93TS)"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "vtam comds",
    "info": "Statistics reporting (to be used in either diagnostics or for finding out performance settings): BFRUSE (list out where the internal buffer storage is for VTAM on that Lpar) CSM (Common Storage Mgmt - storage used between VTAM & TCPIP) SESSIONS,LIST=COUNT (total number of active sessions on this Lpar) STATS,TYPE= (complete statistical read-out. TYPE=VTAM or CFS) Added displays for any Network Node Lpar (refer to VTAMOPTS parm=NODET\r\nADJCLUST (this is for Network Nodes only) ADJSSCPS (this is for Network Nodes only) DIRECTRY (used to show APPN dynamic connections to Appl locations - other parms) STATIONS (X-dmn Link stations) SRCHINFO (summary rpt for subarea and APPN searches)"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "ftp trace",
    "info": "//LLV152 EXEC PGM=FTP, FTP APPS CONSOLIDATED FILES\r\n// PARM='ENVAR(\"_CEE_ENVFILE_S=DD:SYSENV\")/(EXIT=0016'\r\n//SYSENV DD *\r\nGSK_TRACE=255\r\nGSK_TRACE_FILE=/full/path/gskssl.trc\r\n//SYSPRINT DD SYSOUT=*\r\nthe gskssl.trc would be in unreadable format.. we need to issue the command gsktrace /full/path/gskssl.trc>gsksll.txt to read the file in normal fomat"
  },
  {
    "Vendor": "IBM",
    "component/product": "NETwork",
    "type": "ftp Trace",
    "info": "From z/OS perspective, you can collect SSL trace which will show you the FTP server's certificate chain. Are you using ATTLS or native TLS FTP? Please collect GSKSRVR trace as follows:\r\n(1) Bring up GSKSRVR. A sample is provided in the SGSKSAMP library if it isn't already in the PROCLIB concatenation.. (2) Start GSKSRVR component trace with LEVEL=255 TRACE CT,WTRSTART=GSKWTR TRACE CT,ON,COMP=GSKSRVR when these commands are issues we get a reply message and we need to reply as below. R nn,JOBNAME=(jobname),OPTIONS=(LEVEL=255),WTR=ctrwtr,END where jobname is for your FTP server e.g FTPD1 if running native TLS FTP. If using ATTLS, then specify TCPIP's jobname. (3) Recreate the problem\r\n(4) Stop GSKSRVR component trace and send us the trace dataset. TRACE CT,OFF,COMP=GSKSRVR TRACE CT,WTRSTOP=GSKWTR,FLUSH"
  },
  {
    "Vendor": "ibm",
    "component/product": "NETwork",
    "type": "ftp trace",
    "info": ">>>When you start the GSKSRVR trace, a message will pop on the console with reply no. You reply to it.\r\nExample:\r\nTRACE CT,WTRSTART=GSKWTRA ITT038I ALL OF THE TRANSACTIONS REQUESTED VIA THE TRACE CT COMMAND\r\nWERE SUCCESSFULLY EXECUTED. ...\r\nTRACE CT,ON,COMP=GSKSRVR *3673 ITT006A SPECIFY OPERAND(S) FOR TRACE CT COMMAND.\r\nR 3673,JOBNAME=(TCPIP),OPTIONS=(LEVEL=255),WTR=GSKWTRA,END\r\nTherefore in above example, nn is 3673. Note in your case, JOBNAME would be the FTPD jobname e.g.FTPD1 since you are not running"
  },
  {
    "Vendor": "ibm",
    "component/product": "NETwork",
    "type": "OSA",
    "info": "The Open Systems Adapter (OSA) is actually a network controller that enables the mainframe to communicate with a number of LANs by using network protocols such as SNA and TCP/IP.\r\nThe z/OS Communications Server resides within the mainframe and through OSA Express communicates with local users in LANS and those using the 3270 emulation software. Remote users can also access the mainframe using OSA express, routers, firewalls and general internet capabilities.\r\nThe Communications Storage Manager provides shared I/O data flow involved in the communication process."
  },
  {
    "Vendor": "ibm",
    "component/product": "NETwork",
    "type": "command",
    "info": "d net,cdrms -- display cross domain resource managers"
  },
  {
    "Vendor": "ibm",
    "component/product": "NETwork",
    "type": "command",
    "info": "tso tracerte ipaddr. to check the different server that the network would go through before connecting to the ip addr."
  },
  {
    "Vendor": "ibm",
    "component/product": "NETwork",
    "type": "TLS",
    "info": "There is no \"disabling\" TLS because it is always available to you. Functions can support the TLS protocol directly. While the NETSTAT TLS report shows uses of TLS, it being empty does not mean that TLS is not being used. With TLS, your application will need to code in calls to invoke System SSL services. AT-TLS avoids this and provides encryption and decryption along with policy-based security."
  },
  {
    "Vendor": "ibm",
    "component/product": "NETwork",
    "type": "website",
    "info": "To view records of processes using TLS, you might consider using zERT.\r\nhttps://www.ibm.com/support/knowledgecenter/SSLTBW_2.3.0/com.ibm.zos.v2r3.halz002/security_zert.htm"
  },
  {
    "Vendor": "ibm",
    "component/product": "NETwork",
    "type": "theory",
    "info": "Unless your application is using TLS or AT-TLS to encrypt and decrypt data transmissions, ports will not be secured by default."
  },
  {
    "Vendor": "ibm",
    "component/product": "NETwork",
    "type": "osa",
    "info": "OSPF_interface --- is generally in /etc/omproute.conf"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "mac address",
    "info": "for any mac address of a hardware on mainframe. Go to the SE of the mainframe in HMC and check in advanced facilites."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "tcpip errors",
    "info": "not able to connect to a system.. check in tcpip for any OSA card issues and if the chpids are offline we need to make them online.\r\nd tcpip,,netstat,dev\r\nVARY TCPIP,,START,OSAF5F"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "",
    "info": "d net,cpcp -- adjacent connection"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "directory",
    "info": "d net,directory,id=domaind.applid"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "CSM memory",
    "info": "if any issues with communicaiton in TCP/ip .. we can check the memory using teh command D NET,CSM"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "CSM memory",
    "info": "These commands can be used to increse the CSM.\r\nF NET,CSM,ECSA=240M\r\nF NET,CSM,FIXED=320M\r\nAlso, the perm parm changed in SYS1.PARMLIB(IVTPRM00)"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "logon",
    "info": "first screen when connected to a IP for logon.\r\nCheck TN3270 for Port(as specified inpcom/mocha) spefici definiton in the PROFILE dataset pointed by PROFILE DD\r\nlook for USSTAB between BEGINVTAM and ENDVTAM lines.\r\nlook for the module that USSTAB points to in the NET task libraries. this module brings up the initial screen when connected to an IP.\r\nwe need to check and make note for the source code."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "check",
    "info": "check connectivity between systems\r\nV NET,DIAL,ID=applid of the applicaiton or system that you are trying to check. -- this would also activate any connections."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "tcpip",
    "info": "d tcpip,,n,config -- gives details of the tcp/ip configuration."
  },
  {
    "Vendor": "IBM",
    "component/product": "OMVS",
    "type": "commands",
    "info": "df -v in OMVS lists all the directries and files and their owners.\r\ndf -p pathname  or df -P . (takes current lcoation)  location will list the filesystem that we are mounted.\r\ndf -kP filesystem name -- will list the free space in the file system in Kbytes\r\ndf -PKv .  -- to know the filesystem that the current path is mounted on. check the dot after PKv"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "chmod -R 777 /products/ca -- changes the access permissions to RWXRWXRWX for the directory ca and its sub folders."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "MOUNT FILESYSTEM('SMPE.CAI.VANTAGE.V14.D0814.ZFS') TYPE(ZFS) MOUNTPOINT('/products/Vantage/v14/install') -- to mount a file system through TSO command"
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "echo $PATH -- to know the path from where the commands are getting executed."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "DISPLAY OMVS,FILE -- current mounted file systems."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "find / -name \"*.c\" -- search for file .c in / directory"
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "use unset command to remvoe an environment varaible from omvs."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "batch job",
    "info": "Batchjob to mount a file.\r\n//MOUNT EXEC PGM=IKJEFT01 \r\n//SYSTSPRT DD SYSOUT=* \r\n//SYSPRINT DD SYSOUT=* \r\n//SYSTSIN DD * \r\nMOUNT FILESYSTEM('#zfsdsn') + TYPE(ZFS) MODE(RDWR) PARM('AGGRGROW') + \r\nMOUNTPOINT('-PathPrefix-usr/lpp/IBM/+ cdpz/v1r1m0') \r\n//*"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "permission",
    "info": "There are four kinds of 'permissions' encoded by the file\r\n permission bits:\r\n r Read permission- Are you allowed to read the file/directory?\r\n w Write permission- Are you allowed to write to the file/directo\r\n x Execute permission- Are you allowed to execute the file?\r\n x Lookup permission- Are you allowed to traverse the directory?"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "chmod +x filename -- this is for the 4th permission - traverse the diretory."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "permission",
    "info": "Lookup permission is an alternative. If myuser issues:\r\n chmod a+x /u/myuser\r\n chmod a+r /u/myuser/public\r\n then every user on the system will be able to read myuser's public directory, but will not even be able to list(ls) /u/myuser"
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "unzip",
    "info": "to unzip a file in omvs.\r\njar -xvf /Directory/File.zip\r\nx - means extract/unzip\r\nv - verbose command output\r\nf - file name is included"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "convert",
    "info": "Iconv -f ISO8859-1 -t IBM-1047 file1 > file2 to conver ascii to ebsidic format files.\r\n iconv -f ISO8859-1 -t IBM-1047 directory/* > targdirectory/* to conver ascii to ebsidic format files for a entire directory."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "tagging",
    "info": "chtag -tc IBM-1047 ant -- to change the tagging of a file in omvs."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "copy",
    "info": "cp ZWESIS01 \"//'zwes_loadlib(ZWESIS01)' -- command to copy a file to mainframe dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "command to provide access to a folder or a file for an individual user in unix env.\r\nsetfacl -m user:cdpuser:rw- /products/cdp/datastream/wkdir -- provides read andwrite access to user CDPUSER for folder /products/cdp/datastream/wkdir\r\nsetfacl -m user:a8g45zz:rwx $(find /projects/c21ct/workdir/C21CT55T/JVMSRV01) -- provides access to exsisting files too.\r\nsetfacl -m group:admins:r-x,group:dirgrp:rwx /u/ProjectX -- provide Read and Execute authority for group admins and read, write and execute authority for grousp dirgrp.\r\nNote : we need to have FSSEC to be active for setfacl to work.\r\nsetfacl -m default:group:admins:r-x,default:group:dirgrp:rwx /u/ProjectX -- this sets default and will give these permission for any subsequent files /folders created in this path.\r\nsetfacl will give permission to only that folder or file."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "command to list specific individual access to a folder or a file in unix.\r\ngetfacl /products/cdp/datastream/wkdir -- provides the access list for owner,group,other and alos the if any indiidual user access is provided.\r\ngetfacl -d /products/cdp/datastream/wkdir --to list defulat access provided."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "setfacl -D a /etc/inetd.conf -- to delete the individual premissions as modified by the SETFACL command"
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "to set a varible value \" export PATH=/var/zowe/zowerun/nodejs/bin/:$PATH \" -- adds the path /var/zowe/…./bin to PATH varaible."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "rm -R folder name -- removes all the files and the folder\r\nrm -Rf foldrename -- removes all the files even if they are read only files for the user."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "gzip -d perl-5.24.0_b007.180202.tar.gz in /usr/lpp/perl -- to produc a tar file from .gz file -- gzip is a software and needs to be installed and entry updated in /etc/profile"
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "commands",
    "info": "tar -C /usr/lpp/perl -xovf perl-5.24.0_b007.180202.tar -- it unzipped all the executables into /usr/lpp/perl. bin,lib,share folders are created. Tar is a software and needs to be installed."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "issues",
    "info": "atoe_getcwd error: EDC5134I Function not implemented. --- check if the userid running the scirpt has the OMVS home setup."
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "bash",
    "info": "to read a file in bash script . ${variable}"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "batch job",
    "info": "mount a file system using batch job. Use \r\npgm=ikjeft01\r\n OSHELL /usr/sbin/mount -t ZFS -f PLEX.OLD.AGGR002.LDS0002 /service2 -- mounts the file PLEX.OLD.AGGR002.LDS0002 on /service2 locaiton."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "pax",
    "info": "to pax a folder\r\n(1)go to the folder page /u/a93lnzz or /products/cdp pax -wzvLf /tmp/project.pax.Z ./ pax -wzvLf \"//'PROJECT.ARCHIVE'\" ./ -- dumpt the a93lnzz or cdp folder to PROJEC.ARCHIVE dataset.\r\n(2)If you are migrating a file system that contains additional file systems mounted below it, the default settings on the pax command also copies the files and directories that are contained in those file systems. To avoid this, you can either specify the pax -X option, or unmount the lower file systems before issuing the pax command."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "unpax",
    "info": "to unpax a file we cna use\r\ncd to the locaiton where we want to unpax\r\ncopy the pax file to this location.\r\npax -rvf paxfilename -- to unpax"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "COPY using pax command \r\npax -rw "
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "ID",
    "info": "to know the id and gid when in omvs issue the command \"id\"\r\n uid=32360(A93LNZZ) gid=901826380(D#826380) groups=101(AOPADMIN),0(CHOR@F01),100(C01@OPER)"
  },
  {
    "Vendor": "ibm",
    "component/product": "OMVS",
    "type": "automount",
    "info": "in general the automount is specified to be started in /etc/rc as /usr/sbin/automount. Automount gets the location of the Automount filesystem to be used as specified in /etc/auto.master."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "file conversion",
    "info": "to convert ascii to ebcdic format\r\n iconv -f UTF-8 -t IBM-1047 filename.log > filename.ebcdic"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "environment",
    "info": "to find the current current environment varibale values --- use env\r\n use env HOME=/u/ -- to change the environment variable HOME value."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "chagne user",
    "info": "to can work as a different user in OMVS you can use the command SU - username"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "data",
    "info": "date to check the current date and time"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "permission",
    "info": "chmod -w /file locaiton -- to remove write permissions for a file or folder."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "create and edit.",
    "info": "oedit report.log -- opens the report.log file in ispf mode and we can edit it.\r\n Ex report.log -- opens the report.log file in command mode. Issue I to inset lines and when completed issue '.' to inform end of file and then 'X' to terminate writing."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "copy",
    "info": "•Copy a PDS member into a z/OS UNIX file, shown here in the OMVS Shell\r\n•Copy a sequential data set into a z/OS UNIX file\r\ncp \"//'turbo.gammalib'\" dir1\r\n•Copy a PDS to a z/OS UNIX directory\r\n•Copy a z/OS UNIX file into a sequential data set or PDS member -- cp -F bin cdpconfigv2.d03032021.pax.z \"//'sys5.cts.cdp.configv2.zip'\" -- for zip files\r\ncp filename \"//'mvs file name'\" -- regular files\r\n•Copy executables between MVS and z/OS UNIX"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "sharing file system",
    "info": "if we have SYSPLEX(YES) specified in the BPXPRMxx member then the file systems can be shared in that sysplex environment. We would also need the BPXCMDS couple datasets defined and activated.\r\n "
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "options",
    "info": "D OMVS,O -- display the options specified by the BPXPRMxx members."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "mount",
    "info": "/usr/sbin/mount -f SYS5.CTS.OMVS.SHARE.ZFS /products/share -t ZFS -o ’AGGRFULL(90,5)’  -- mounts the file system and at the same time tries to expand when it is almost full. In OMVS"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "mount",
    "info": "TSO command -- MOUNT FILESYSTEM(’OMVS.PRV.AGGR004.LDS0004’) MOUNTPOINT(’/etc/zfscompat1’) TYPE(ZFS) MODE(RDWR) PARM('AGGRFULL(90,5)') \r\n /bin/tso \"mount filesystem(OMVS.ZFS.F96) mountpoint(’/u/d96’) type(zfs) mode(read)\""
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "mount",
    "info": "in a shared environment we can find the omvs file system using system by listing all the file systems.\r\n D OMVS,F"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "owner",
    "info": "we can find the owner of a file by issuing the command df -v when in the folder."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "unmount",
    "info": "omvs command to unmount a file system - /usr/sbin/unmount -f SYS5.CTS.OMVS.SHARE.ZFS"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "copy",
    "info": "cp RLp /products/chorus/cetjr3m0/dply/cetjr3m0 /products/share/ -- R-copies all the files and p uses the same format and owner and group. L to copy over the symbolics in the files."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "list",
    "info": "ls -al -- to list hidden files also."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "user log",
    "info": "userlog would be in .sh_history file of /u/userid -- you need to use the command ls -al to list the hidden files."
  },
  {
    "Vendor": "Ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "ls -ld -- list directory entries."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "ls -EL -- extended attrubutes for apf authrized and, program controlled and shared address space."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "extattr +a /usr/sbin/sshd -- to set extended attribute for apf authroization."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "concept",
    "info": "Program control is the concept of having \"trusted\" applications -- we can a file program control attribute by issuing the command extattr +p /usr/sbin/sshd"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "OMVS command to check the resolver: HOST google.com"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "startup",
    "info": "/SYSTEM/etc/rc -- has all the statemetns for starting different tasks under OMVS. Executed with the start of OMVS.\r\nit would have statements to start SYSLOGD, CRON and others like\r\n# Start the cron daemon              \r\n_BPX_JOBNAME='CRON' /usr/sbin/cron & \r\n# next two lines                                                 \r\n_BPX_JOBNAME='SYSLOGD' /usr/sbin/syslogd -c -i -D 0755 -F 0664 & \r\nAs explained in Using & at the end of a command, using the & at the end of a command starts the command in the background and the _BPX_JOBNAME environment variable assigns a job name"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "syslogd",
    "info": "syslogd has all the log file locations defined."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "mount",
    "info": "The next thing to do is mount this new intermediate file system at /u. The mount\r\n can be performed from an ID that has superuser authority by:\r\n v Using the usr/sbin/mount REXX exec from the shell\r\n v Using the TSO MOUNT command\r\n v Using the mount shell command\r\n v Using the ISHELL File_Systems pull-down\r\n v Adding an entry to the BPXPRMxx member in SYS1.PARMLIB so that it will be\r\n mounted when the system reIPLs."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "Startup1",
    "info": "USS has two hats it needs to wear. An MVS hat to interact with the MVS system and the second hat to interact with Unix side USS.\r\nTogether the OMVS and BPXOINIT each manage a different aspect of USS. OMVS interfaces with MVS and BPXOINIT starts and helps manage processes running in USS.\r\nOMVS starts the UNIX file system services on the mainframe. The OMVS address space is the 'MVS' hat. It is started first and establishes the layer USS layer that communicates and co-ordinates resources with the MVS side of the zOS system.\r\nAt IPL time, the OMVS address space processes the BPXPRMxx member and performs all tasks it contains (setup filesystems, limits, networking, mounts.. etc).\r\nAfter IPL, it helps to manage interprocess communication, inter-system filesystem sharing, resource/storage management\r\nOMVS starts and invokes BPXOINIT during the IPL. BPXOINIT address space (started by the OMVS STC) initializes the UNIX environment. BPXOINIT is the first 'unix' process to run in the system (it is PID 1).\r\namong other things also invokes 2 tasks ETCINIT and ETCRC."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "Startup2",
    "info": "ETCINIT is started by the BPXOINIT address space. What ETCINIT does is invoke the USS shell command '/usr/sbin/init'.\r\nThe init command reads the file /etc/init.options and will perform some environment setup before it fires off the initialization script /etc/rc. ETCRC executes the commands in /etc/rc which has the statements to initialize the daemons like SYSLOGD, inetd and so on.\r\nSYSLOGD has the statements that help us to find the logs for ftp, sshd, fdrupstream and so on.\r\nThe inetd daemon provides service management for a network. For example, it starts the rlogind program whenever there is a remote login request from a workstation.\r\nsshd starts and ends typically and in general. A forked copy of the daemon will be left running, which is normal. Sshd is for SFTP environment.\r\nftp* tasks setups the environment for the ftp protocol it can be normal ftp or secure ftp using TLS. FTPS is for secured ftp over tcpip using TLS.\r\nInetd -- INETD is a daemon that listens for incoming TCPIP requests (on specific ports) and then launches applications to handle those incoming requests.\r\nNewer servers do not tend to use INETD anymore. FTP, SFTP and SSHD can all run as standalone servers, we may not be running these daemon.\r\nBPXAS fork task starts every time there is an OMVS activity by users or app.\r\n\r\nthe banner page that we see at the start of the omvs is all in /etc/profile"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "resolver",
    "info": "in BPXPRMxx RESOLVER_PROC(procname|DEFAULT|NONE)\r\nSpecifies how the resolver address space is processed during z/OS UNIX initialization. The resolver is used by TCP/IP applications for name-to-address or address-to-name resolution. In order to create a resolver address space, a system must be configured with an AF_INET or AF_INET6 domain.\r\nDEFAULT\r\nCauses an address space named RESOLVER to start, using the system default procedure of IEESYSAS. The address space is started with SUB=MSTR so that it runs under the MASTER address space instead of the JES address space.\r\nNONE\r\nSpecifies that no address space is to be started. If you are using z/OS Communications Server IP, the resolver must be started before TCP/IP can be started. TCP/IP does not initialize until the resolver address space is started.\r\nprocname\r\nThe name of the address space for the resolver and the procedure member name in the appropriate proclib. procname is one to eight characters long. The procedure must reside in a data set that is specified by the MSTJCLxx parmlib member's IEFPDSI DD card specification."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "stc",
    "info": "The inetd daemon provides service management for a network. For example, it starts the rlogind program whenever there is a remote login request from a workstation."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "daemons",
    "info": "z/OS UNIX supplies these daemons:\r\n - inetd—the network daemon\r\n - rlogind—the remote login daemon\r\n - cron—the clock daemon\r\n - uucpd—the UUCP daemon\r\n The syslogd daemon, which is used to route messages, is shipped with TCP/IP and is documented in their library."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "daemons",
    "info": "INETD is a daemon that listens for incoming TCPIP requests (on specific ports) and then launches applications to handle those incoming requests. Some older style daemons like rlogind and otelnetd use INETD to front end the TCPIP port listening, but if you do not need these services running you likely do not have a need to run INETD. However, newer servers do not tend to use INETD anymore. FTP, SFTP and SSHD can all run as stand alone servers.\r\nIt is possible that you are not running the INETD daemon because you do not need to use services like rlogind or otelnetd. You can check to see if it is running with the mvs console command 'D OMVS,A=ALL'. or from the OMVS shell with the command 'ps -ef | grep inetd' Note: this requires UID 0 authority for complete results"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "sshd",
    "info": "/usr/sbin/sshd -v localhost --to identify the protocol thet sshd is running."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "debugging",
    "info": "Steps for setting up syslogd to debug sshd:\r\nBefore you begin: You need to have superuser authority in order to start the syslogd daemon. Perform the following steps to set up syslogd to debug sshd. 1. Create the syslogd configuration file /etc/syslog.conf. a. Create directory /tmp/syslogd. mkdir /tmp/syslogd b. Add a configuration statement in /etc/syslog.conf. Example: daemon.debug /tmp/syslogd/server.logfile\r\nResult: Writes debug messages with facility daemon to /tmp/syslogd/server.logfile. c. Set the permission bits. chmod 644 /etc/syslog.conf d. Create the log file. touch /tmp/syslogd/server.logfile 2. Start syslogd /usr/sbin/syslogd -f /etc/syslog.conf & 3. In the sshd configuration file, /etc/ssh/sshd_config , add keywords \"SyslogFacility\" and \"LogLevel\". The default SyslogFacility is AUTH. The default LogLevel is INFO : Example: SyslogFacility DAEMON\r\nLogLevel DEBUG3 4. In the sshd configuration file, /etc/ssh/sshd_config update the sftp subsystem entry to enable sftp debugging:\r\nSubsystem sftp /usr/lib/ssh/sftp-server -f DAEMON -l DEBUG3 5. To force syslogd or sshd to reread its configuration file and activate any modified parameters without stopping, issue:\r\nkill -s SIGHUP PID\r\nwhere PID is the process ID of syslogd or sshd. When you are done, you have set up syslogd and sshd for debugging"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "batch",
    "info": "//STEP1 EXEC PGM=BPXBATCH \r\n//STEPLIB DD DSN=SYS1.SCEERUN,DISP=SHR \r\n//STDERR DD PATH='/u/userid/std.err', \r\n// PATHOPTS=(OWRONLY,OCREAT,OTRUNC),PATHMODE=SIRWXU \r\n//STDOUT DD PATH='/u/userid/std.out', \r\n// PATHOPTS=(OWRONLY,OCREAT,OTRUNC),PATHMODE=SIRWXU \r\n//STDPARM DD * \r\nsh  \r\necho ls -l; \r\ncd /u/usreid/; \r\nrm -rf *; \r\ncp /u/userid/cdpconfig.pax.z /u/useridcdpconfig/; \r\nchmod -R 777 /u/userid/cdpconfig/; | su \r\npwd;\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "submit job",
    "info": "/bin/submit. This is a standard z/OS UNIX command in at least z/OS 1.12 and above. This can submit from a z/OS UNIX resident UNIX file or \r\nfrom \"stdin\", if no file is specified in the UNIX command line."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "w --- tells you who's logged in, and what they're doing. Especially use the 'idle' part. This allows you to see whether they're actually there typing away at their keyboards right at the moment."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "finger username -- provides lot of info on user"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "Kill/Stop",
    "info": "kill /stop a process. Issue the command /D OMVS,A=ALL. Find the PID od the process that you want to kill. issue the command kill pid to stop teh task."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "if condition in omvs\r\nif ----stat ---- then -- stat --else --- fi"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "keywords",
    "info": "test"
  },
  {
    "Vendor": "IBM",
    "component/product": "omvs",
    "type": "time",
    "info": "TZ varibale has current time zone being used by the system. we can find its value by issuing env command. this can be used to list all of hte environment varibale values for your logon."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "process",
    "info": "to start a process in omvs but dont want to wait for it to complete. we cna start it using the command\r\nnohup \"command\"\r\nas the command runs we can do f2->subcommand and quit to go out of OMVS but the process would be running.\r\nthe nohup creates a log as nohup.out in the folder where we issued the nohup \"command\""
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "process",
    "info": "to terminate a process. pppp is the PID of the process. get it form /D OMVS,A=ALL\r\nkill -s term pppp F BPXOINIT,TERM=ppp\r\nto restart a process\r\nkill -s SIGHUP pppp\r\nto kill a process\r\nkill -s kill pppp\r\nkill -HUP `cat /etc/syslog.pid` -- to recycle syslogd"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "website",
    "info": "ssh and jcl\r\nhttps://www.ssh.com/manuals/server-zos-user/60/ch06s01s02.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "to create a unix file symbolic link use the command\r\nln -s exsistingfilename symbolicname -- to create a new file. see to that the sybmolicname file is not present.\r\n\r\nuse \"unlink 'symbolic name' \" to remove the link."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "change owner",
    "info": "chown -R john:build /tmp/src -- (R all files and directories, john (owner) build(group) /tmp/src (path)"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "user change",
    "info": "to run the commands and another user issue the command : We need to have access to SURROGAT CLASS BPX\r\nsu -s xxxxxx -- (xxxxx is the username you want to run the command with) \r\nFSUM5027 su: User is not a surrogate of \"BPXROOT\". -- check if the users are surrogate of each other."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "mkdir",
    "info": "mkdir -p /install/bin --- it creates \"install\" directory if not already created. and then created the bin directory."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "super user batch -- ensure that your line numbers are not present in the JCL from 72 to 80 column.",
    "info": "//UNPAXDIR EXEC PGM=BPXBATCH \r\n//STDOUT DD SYSOUT=* \r\n//STDERR DD SYSOUT=* \r\n//STDIN DD PATH='/xxxx/Vantage/unzip.sh',PATHOPTS=(ORDONLY) \r\n/* \r\necho chmod -R 775 /xxxx/Vantage/v14/download | su; \r\necho cd /xxxx/Vantage/v14/download | su; \r\necho ls -l; \r\necho pax -rvf /xxxxVantage/v14/download/DVD0000000001761.pax.z | su"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "theory",
    "info": "The z/OS UNIX kernel is linked to WLM so that when a z/OS UNIX program runs, and requests that another program is to be executed - through a fork or spawn function, WLM uses an IBM-supplied procedure, BPXAS, to start a new address space so that the program can run."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "zos and unix compare",
    "info": "Programming --- zOS (REXX and CLIST) -- UNIX (Shell Scripts and REXX)\r\nData Management --- zOS (DFSMShsm, ISPF) -- UNIX (tar cpio, pax)\r\njob management -- zOS (SDSF, SYSVIEW ) -- UNIX (ps, jobs, kill)\r\nSubmit a job --- zOS (submit command in TSO) -- UNIX (submit, corntab)\r\nCompile --- zOS (Compiler, LINK) -- UNIX (c89, c99, cc, c++, cxx, make)\r\ndebugging -- zOS (zOS debugger) -- UNIX (dbx)\r\nEditing Data --- zOS (ISPF) -- UNIX(ed and vi)"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "cmp file1 file2 -- compare 2 files in a directory"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "format",
    "info": "1023 char for path name length\r\n255 char for a file or directory name"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "_BPX_JOBNAME='SYSLOGD' /usr/sbin/syslogd -f /etc/syslog.conf -c -u & -- assigns a job name of SYSLOGD to the task that starts. if we issue the command \"/usr/sbin/syslogd -f /etc/syslog.conf -c -u &\" alone then our \"useridxx\" gets assinged as the job name.\r\nissue the command /D OMVS,U=userid to check for all the tasks started by the user and are running in OMVS."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "sleep",
    "info": "JOb to run for a long time using sleep command.\r\n//STEP1 EXEC PGM=BPXBATCH //STEPLIB DD DSN=SYS1.SCEERUN,DISP=SHR //STDERR DD SYSOUT=* //STDOUT DD SYSOUT=* //STDPARM DD * sh su; sleep 10 /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "file system",
    "info": "D OMVS,FILE,O --- list the default system owned file systems\r\nD OMVS,FILE,O=sysname --- specific system file systems.\r\nD OMVS,FILE,N=OMVSSPA.* --- file systems with matching names."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "create",
    "info": "Create a zfs file in omvs\r\nzfsadm define -aggregate a93lnzz.zfscre.test.zfs -cylinders 10 5"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "zfsadm fileinfo path (file or directory). command to list a file info.\r\nzfsadm fsinfo path (file or directory). -- Displays detailed information about a zFS file system, which is also known as a zFS aggregate."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "permission bits",
    "info": "default permission bits for direcotries and files.\r\nBy default, we are having 777 permission bit for directories and 666 for files. So, the files will be 666.\r\nAlso, there is another catch here the umask value set in our profile. Here we have usmak 0022(there are only certain octal value that we can spcify, check chmod commnd for the octal values), so every time a directory or file is created the umask is subtracted from default permission bits and the directory or file is created."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "GID",
    "info": "if we have 2 RACF groups and we want to provide different access to users in the groups for a OMVS folder then follow the steps\r\n1) In omvs create a folder and assign the owner(ID) as first group with required access.\r\nCHOWN owner(uid):group(gid) path\r\n2) Issue the command in OMVS\r\nsetfacl -m default:group:”gid of 2nd Group” :rwx /foldername. - this will provide rwx access to the 2nd group."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "userid with $",
    "info": "When the OMVS shell sees a string that begins with a $ in the command stream, it will be interpreted as an environment variable.\r\nWhat you can do is escape or insulate the $294237 from the command interpreter. Two ways to do that are:\r\nchown -R \\$294237:2308 c21ct #uses the escape character to insulate $294237 from being interpreted chown -R '$294237:2308' c21ct #uses quotes to insulate $294237:2308 from being interpreted"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "user name issue",
    "info": "When the OMVS shell sees a string that begins with a $ in the command stream, it will be interpreted as an environment variable.\r\nWhat you can do is escape or insulate the $294237 from the command interpreter. Two ways to do that are:\r\nchown -R \\$294237:2308 c21ct #uses the escape character to insulate $294237 from being interpreted chown -R '$294237:2308' c21ct #uses quotes to insulate $294237:2308 from being interpreted"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "unique setup",
    "info": "setup for a group to work with folders.\r\n1.        Create a Unique Group or Use one of the Nazih Groups: C21C@ALT or C21S@ALT\r\n2.        Connect all those userids to one of the selective groups:\r\na.        TSO CONNECT xxxx GROUP(xxxx)\r\n3.        Create separate Unix Home Directories for those 5 Userids\r\na.        zFS Create Directories ( New or Add Subdirectories to Existing zFS Directory)\r\n4.        Assign userids to New unique UID’s : Perform the following Commands:\r\na.        TSO ALU xxxx OMVS(HOME(‘/u/xxxxx’) Unique\r\nb.        TSO ALU xxxx OMVS(UID(xxxx))  Unique\r\n5.        Perform the following commands:\r\n6.        CHMOD 770 /u/xxxxx  For Each userid change permissions that only Owner+Group a.        can access directory\r\n7.        CHOWN -Rf userid:Group /u/xxxx  Will depend on the Group you decide above"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "vairables",
    "info": "typeset -x --- lists all the default varibales and their values for your logon."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "ftpd1",
    "info": "START FTPD, which runs for a few seconds, fires up FTPD1 as a \"UNIX job\", then ends. FTPD1 stays up (visible in SDSF) until explicitly stopped. \r\nThis is how z/OS emulates UNIX processes. Some are invoked by fork() which leaves the 'parent' task running. All invoked this way will terminate when the invoking task ends.Others (like FTPD) are invoked by spawn() which leaves the process running even when the 'parent' goes away. These are better managed by modifying USS address spaces (OMVS) to terminate, or through the shell.\r\nork()'ed address spaces should not terminate when the parent terminates. If z/OS UNIX does this, it is not standard UNIX functioning. spawn() is simply a simplier way to fork() and exec() in a single call."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "filesystem",
    "info": "file system expansion command : expand\r\nsu\r\nzfsadm grow -a 'omvs.syse.tmp' -size 0\r\n /usr/lpp/dfsms/bin/confighfs -x n filepath  (n=spce in M / T / C)"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "skulker",
    "info": "copy the /sample/skulker to the /bin or /usr/bin ... we cna use the command skulker -r /directory -days old. this would go and delete all the files that are older than 10days in /directory and sub directories."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "Command to backup hfs files using dfdss -- HBACK ‘/u/xxxxxxx/*’ \r\nBackup my home directory -- HRECOVER /u/xxxxxx/ims15.pax’ \r\nRecover a file -- HLIST filename ‘/u/xxxxxxxx/ims15.pax’ BCDS \r\nQuery the Backup Listing of the file -- HLIST fIlelevel ‘/u/xxxxxxx/’ BCDS \r\nQuery on File Level versus Filenames"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "conversion",
    "info": "Converting a file system from hfs to zfs\r\n Allocate a New zFS Filesystem: OMVS.PLEX2.ROOT.Y05D158.ZFS\r\n• Access USS Environment and make sure that there is a directory exists as : /newroot\r\n• Mount the New Filesystem under /newroot"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "conversion",
    "info": "Steps to convert a file system.\r\nAccess the USS environment:\r\n1. su\r\n2. cd /\r\n3. pax -wr -pe -XCM ./ /newroot\r\nUnmount the new filesystem:\r\n• Unmount filesystem(‘OMVS.PLEX2.ROOT.Y05D158.ZFS’) immed\r\nFrom Sysview – Issue the following command:\r\n• /f omvs,newroot=omvs.plex2.root.y05d158.zfs,cond=yes\r\nIf everything completed successfully then update the PARMLIB Member: BPXPRMF0\r\nFROM:\r\nROOT FILESYSTEM('OMVS.PLEX2.ROOT.Y05D158')\r\nTYPE(HFS)\r\nMODE(RDWR)\r\nAUTOMOVE\r\nTO:\r\nROOT FILESYSTEM('OMVS.PLEX2.ROOT.Y05D158.ZFS')\r\nTYPE(ZFS)\r\nMODE(RDWR)\r\nAUTOMOVE"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "if someone reports you that they are experiencing zFS Hangs or there are Quiesce messages then you can do the following:\r\nThrough the USS environment, issue the following command and this would display the quiesce filesystems if there are any: zfsadm aggrinfo -- https://www.ibm.com/docs/en/zos/2.1.0?topic=detector-steps-diagnosing-resolving-zfs-hang"
  },
  {
    "Vendor": "IBM",
    "component/product": "OMVS",
    "type": "command",
    "info": "to define a symbolic for a file\r\ncd /usr/lpp/dp1g; ln -s /products/db2v11/base db2_base; ln -s /products/db2v11/jdbc db2_jdbc; ln -s /products/db2v11/mql db2_mql;"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "dynamic",
    "info": "to dynamically unmount and mount a file system.\r\nunmount filesystem('file system name') remount(read)"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "conversion",
    "info": "converting a file system from hfs to zfs\r\nSYS1.SAMPLIB(ISPBTCH) -- has a JCL that can be used for conversion."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "unmount and mount dynamically",
    "info": ". Mount the current filesystem: OMVS.ZZZZ.ROOT as READ only:\r\n• Issue the following command from ISPF Option 6 on xxxx and YYYY System:\r\n• Unmount filesystem('OMVS.ZZZZ.ROOT') REMOUNT(READ)\r\n• The above should not impact any users since this filesystem has been utilized at 97% and there are no Users that does RW to this filesystem directory level"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "directories",
    "info": "var -- Contains dynamic data that is used internally by products and by elements and features of z/OS.\r\ndev -- Contains files that are used when logging into the shell environment, and during program compilation.\r\netc -- Contains files that are customized for your environment.\r\nbin -- Contains program files for various system commands.\r\nlib -- Contains shared libraries needed by programs in /bin."
  },
  {
    "Vendor": "Ibm",
    "component/product": "omvs",
    "type": "Character Special file",
    "info": "these files are an interface for an I/O device and appears in your file system as if it were and Ordinary file. some examples -- NULL file, terminal file."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "FIFO",
    "info": "used to cpature the output from one process and act as input for another process."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "theory",
    "info": "INODE : each file has a unique identification number that can be used to refer to the file instead of its name."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "theory",
    "info": "A path name can be up to 1023 characters long, including all directory names, file names, and separating slashes"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "CMP -- command to compare 2 directories or files. CMP jan_totals_216 jan_totals_217"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "theory",
    "info": "a file/directory name can be 255 char long."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "syslogd",
    "info": "export _BPX_JOBNAME='SYSLOGD' --- jobs get started with name syslogd\r\n/usr/sbin/syslogd -c -i -D 0755 -F 0664 & --- -c enables SYSLOG task to create any files / flders that are not available. -- it is also specified in the SYSLOGD STC as a parm\r\nSYSLOGD -- we can check how it started by issuing the command D OMVS,ALL -if started under omvs we can see SYSLOGD in the list.\r\nwe can write the statements for backup of the logs like as \" *.err      /var/log/%Y/%m/%d/errors\" -- configuration uses date stamps in the names of directories of log files to organize log files by year (%Y), month (%m), and day (%d) -- Variable substitution occurs using the Language Environment® C function strftime()"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "opsmvs",
    "type": "batch",
    "info": "to run a opsmvs command in batch -- //step1 exec pgm=ox,parm='aoi.ops.rexx3m(tapechek) tape_chek -- tape_chek is the argument passing to the tapechek rexx"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "opsmvs",
    "type": "batch",
    "info": "write the OPSMVS rexx in a dataset and execute it in batch using PGM=IKJEFT01 and SYSIN as OX 'dataset(mem)'"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "opsmvs",
    "type": "rexx",
    "info": "sample OPSMVS rexx to issue a command.\r\nVAR = OPSCLEDQ() ADDRESS 'TSO' \"OPSCMD C(F TERAP02,D CP DETAIL) WAIT(5)\" DO I=1 TO QUEUED() PULL LINE SAY LINE END EXIT"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "opsmvs",
    "type": "panels",
    "info": "to check what are the rule datasets in the OPSMVS panels check the option 4.5.1 it would display the dataset naming convention."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "opsmvs",
    "type": "search",
    "info": "to search for a string in OPSLOG issue the command PRO."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "opsmvs",
    "type": "invocation",
    "info": "Press END to return Syntax error in keyword: WS --- Value of Y is not valid: PARSE OF COMMAND FAILED, RC=18 *** TSO OPSV -> 0 -> 1 -> AOF REXX WorkSpace ===> 1725800"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "opsmvs",
    "type": "add a task to opsmvs control",
    "info": "a) TSO OPSMVS -- o1pen ops view\r\nb) 2: editors\r\nc) 6 Table Edit Relational Table Editor for RDF\r\nd) Enter\r\ne) identify the resource tables that are to be updated. (in general COMMON and LOCAL). Browse the SSM_MANAGED_TABLE\r\nf) take a backup of the table using I line command to rename and then C line command to copy to a new table.\r\ng) use the line command to EDIT the table, we can insert a new line and add all the required fields\r\n10) check the corresponding table_act for the rexx that would be used with these tables based on the conditions."
  },
  {
    "Vendor": "ibm",
    "component/product": "parmlib",
    "type": "MSTJCLxx",
    "info": "The MSTRJCL suffix needs to mentioned in IEASYSxx member using parm MSTR=xx. If the MSTRJCL parameter is not specified, the system uses the MSTJCL00 parmlib member. If the system does not find the MSTJCL00 parmlib member, it uses the default master JCL in the MSTJCL00 module in SYS1.LINKLIB."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "PDSMAN",
    "type": "Ver check",
    "info": "PDSMAN STC - PDSM0PR"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "PDSMAN",
    "type": "check",
    "info": "To check if a dataset is being monitored by PDSMAN.\r\n//PDSM34 EXEC PGM=PDSM34,PARM='SYS1.PARMLIB' \r\n//PDSMRPT DD SYSOUT=* \r\n//SYSIN DD"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "PDSMAN",
    "type": "utility",
    "info": "utility to delete, rename, recover and purge old versions.\r\n//S1 EXEC PGM=PDSM32\r\n//PDSMPDS DD DSN=TEST.LOAD,DISP=SHR\r\n//PDSMRPT DD SYSOUT=A\r\n//SYSIN DD *\r\nPURGE PREVONLY\r\n//"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "PDSMAN",
    "type": "utility",
    "info": "to delete members of a dataset\r\n//* JOB TO DELETE MEMBERS OF DATASET USING PDSMAN\r\n//STEP1 EXEC PGM=PDSEASY \r\n//SYSPRINT DD SYSOUT=* \r\n//SYSIN DD * \r\nMSL A93LNZZ.JCL.PROD D * \r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "performance",
    "type": "cpu _busy",
    "info": "CPU_Busy = SM70PDT/1000000, If calculation CPU_BUSY% =( (CPU_BUSY) /( SMF70INT * no. of CP's) )* 100"
  },
  {
    "Vendor": "ibm",
    "component/product": "performance",
    "type": "cpu _busy",
    "info": "CPU busy time, in seconds. Calculated as SMF70ONT/1000 - SMF70WAT/4 096 000 000, or in LPAR mode, VALUE(SMF70PDT/1 000 000, SMF70EDT/1 000 000) - SMF70WAT/4 096 000 000 if wait completion enabled, else VALUE(SMF70PDT/1 000 000, SMF70EDT/1 000 000). -- we can check any RMFCPU report to see if WAIT COMPLETION is enabled or NOT."
  },
  {
    "Vendor": "ibm",
    "component/product": "performance",
    "type": "rmf",
    "info": "we can get LPAR level usage MSU report as below.\r\nDump SMF70 alone from SMF dump and use it as input for the below job.\r\n//POST EXEC PGM=ERBRMFPP //MFPINPUT DD DISP=SHR,DSN=SYS8.SMF.SYSE.L30W036D.SMF70.JUL17.EXTRACT //MFPMSGDS DD SYSOUT=* //PPOVWREC DD DSN=SYS8.SMF.SYSE.DASHBORD.RMFPOST.CPU.RPT, // DISP=(NEW,CATLG,DELETE), // SPACE=(CYL,(10,10),RLSE) //SYSPRINT DD SYSOUT=* //SYSIN DD * NOSUMMARY DATE(07162019,07162019) OVERVIEW(RECORD) OVW(LDMLP00(LDEFMSU(SYSE))) OVW(LDALP00(LACTMSU(SYSE))) /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "performance",
    "type": "rmf",
    "info": "we can get a complete cpu report along with CEC definitions and Lpar defined capacity : SMF 70 dump is input.\r\n //STEP01 EXEC PGM=ERBRMFPP,REGION=0M\r\n //MFPINPUT DD DISP=(SHR),DSN=GSMVSE.SMF.PLEXPROD.SYST.VTS1SAVE(0)\r\n //PPRPTS DD SYSOUT=*\r\n //SYSIN DD *\r\n NOSUMMARY\r\n DATE(09032007,09032007)\r\n RTOD(0000,2400)\r\n SYSOUT(K)\r\n REPORTS(CPU)\r\n //"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "pmo",
    "type": "commands",
    "info": "issue command MAIN to return to the main menu."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "pmo",
    "type": "commands",
    "info": "f pmo,checklib=datasetname -- it lets us know if the dataset is managed by PMO or not."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "pmo",
    "type": "commands",
    "info": "f pmo,d=datasetname -- it removes the dataset from PMO monitoring and rebuilds the hash tables."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "pmo",
    "type": "commands",
    "info": "f pmo,exclprvt=datasetname -- it removes the dataset from PMO monitoring"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "PMO",
    "type": "setup",
    "info": "in the PMO PARMS member (PMOPARM DD in the STC) -- we can specify the time limit that is automatically refreshes the LLA datasets that are updated. LLAPRMLB=xxxx.&SYSNAME..PMOPARMS.LLA -- if you want to dynamically refresh LLA then we need to update the parm in the ibrary pointed by LLAPRMLIB"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "pmo",
    "type": "usecase",
    "info": "If you have a severe paging problem on your system, you can manually specify the private libraries that CA PMO will manage instead of allowing CA PMO to select them automatically. Methods for handling paging constraints are addressed in the installation and tuning instructions."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "pmo",
    "type": "commands",
    "info": "F PMO,M=member name --- deletes the members entry from PMO management."
  },
  {
    "Vendor": "ibm",
    "component/product": "pprc",
    "type": "commands",
    "info": "command to check the status of PPRC.\r\n CQUERY DEVN(X'0C04') --> this is to query a device and check whether it is mirrored.\r\n CQUERY DEVN(X'0F40') PATHS ---> queries paths established for volume 0F40\r\n CQUERY DEVN(X'0F40') LINKINFO --> to check the PPRC linkage"
  },
  {
    "Vendor": "ibm",
    "component/product": "pprc",
    "type": "message",
    "info": "message is IEA494I, this will come out if a PPRC Suspend occurs"
  },
  {
    "Vendor": "ibm",
    "component/product": "pr/sm",
    "type": "",
    "info": "PR/SM is included with IBM Z mainframes, it does not run under any operating system. PR/SM divides a CEC into LPARs, and can share CPUs, memory, channels, and OSA connections amongst them.\r\nPR/SM and z/VM are similar; both can share channels, OSA connections, and CPU amongst one or more guest systems. z/VM is an operating system that can run under PR/SM. PR/SM is a feature of the IBM Z mainframe."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "qfetch",
    "type": "command",
    "info": "f qfetch,d=dataset --- deletes a dataset from qfetch monitoring"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "qfetch",
    "type": "command",
    "info": "f qfetch,inclprvt=dataset,vol=volume --- add a dataset to qfetch monitoring"
  },
  {
    "Vendor": "Chicago soft",
    "component/product": "Qucikref",
    "type": "License",
    "info": "In the quickref panels issue the command QINFO to identify the expiration date. At present you need to upload the license key in BIN format to mainframe to the license dataset. If already running you can check for it in the QINFO display."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "to list a class RL classname parm || RL DIRSERCH * ALL"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "RLIST classname resourcename AUTHUSER -- lists all the user access for the resource in that class."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "SETROPTS RACLIST(FACILITY) REFRESH\r\n SETROPTS GENERIC(class-name) REFRESH -- refresh the class after changes are made."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "PERMIT resourcename CLASS(classname) ID(userid) ACCESS(READ) -- to permit specific user for a resource in a class."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "keyring",
    "info": "RACDCERT ID(ring-owner) ADDRING(keyringname)\r\n RACDCERT ID(ibmuser) ADDRING(key_ibmuser) -- Create a keying for IBMUSER"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "certificate",
    "info": "RACDCERT CERTAUTH LIST(SERIALNUMBER(023456))\r\n RACDCERT CERTAUTH ALTER(LABEL('GeoTrust Global CA')) TRUST --- Enabling the trust"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "certificate",
    "info": "RACDCERT ID(ibmuser) CONNECT( CERTAUTH LABEL('GeoTrust Global CA') RING(key_ibmuser) USAGE(CERTAUTH) )\r\nRACDCERT ID(GPMSERVE) CONNECT(SITE LABEL(’SYST SITE CERT’) RING(DDSSERVERKEYRING) USAGE(PERSONAL) DEFAULT) -- to mark the certifacate usgae as Default.\r\n\r\nThe irrsitec user ID is defined in USER profiles that are supplied with RACF® and cannot be defined by your installation.\r\n\r\nthe certificate names are case sensitive. please ensure to check and then use the names in the command."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "list",
    "info": "RACDCERT LISTRING (List key ring) -- list key ring.\r\nRACDCERT LISTRING (ringname) ID(ring-owner)"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "PERMIT IRR.DIGTCERT.LIST CLASS(FACILITY) ID(USER2) ACCESS(READ)\r\nPERMIT IRR.DIGTCERT.LISTRING CLASS(FACILITY) ID(USER2) ACCESS(UPDATE) -- to permit users to check all the key ring and not just his own."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "RACDCERT EXPORT(LABEL('zOSMFCA')) DSN(IBMUSER.ZOSMFCA.CERT) certauth format(PKCS12DER) password('123456')"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "setropts classact(rdatalib) -- to activate a class"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "surrogat BPX.SRV.* to imitate another user in OMVS. Once we have access we can issue the command \" su -s newuser \" and act like the new user."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "ralter started zowesvr1.* stdata(user(izusvr))"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "commands",
    "info": "rdefine started zwesis01.* stdata(user(izusvr))"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "permission",
    "info": "MVS.MCSOPER.* and CL(OPERCMDS) -- to permit users with sdsf command display authority"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "permission",
    "info": "CLASS(TSOAUTH) and JCL -- to permit a user to submit a job"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "keyring",
    "info": "a. Create self signed certificate authority (CA) certificate:\r\n RACDCERT CERTAUTH GENCERT SUBJECTSDN(CN('JES2 Subsystem CA') O('JES2 CA Org')\r\n OU('JES2 CA Unit') L('Poughkeepsie') SP('New York') C('US')) WITHLABEL('JES2_CA')\r\n NOTAFTER(DATE(2027-05-31))\r\n b. Create client certificate for JES2 EDS use, signed with CA certificate created previously:\r\n RACDCERT ID(JES2USER) GENCERT SUBJECTSDN(CN(’JES2 Client’) O(’JES2 Client Org’)\r\n OU(’JES2 Client Unit’) L(’Poughkeepsie’) SP(’New York’) C(’US’)) WITHLABEL(’JES2_Client’)\r\n SIGNWITH(CERTAUTH LABEL(’JES2_CA’))\r\n c. Add JES2 client certificate to JES2 key ring:\r\n RACDCERT ID(JES2USER) CONNECT(ID(JES2USER) LABEL(’JES2_Client’) RING(JES2EDS) DEFAULT))"
  },
  {
    "Vendor": "Ibm",
    "component/product": "racf",
    "type": "keyring",
    "info": "Generate a certificate:\r\nRACDCERT SITE GENCERT +\r\nSUBJECTSDN(CN('xxx.xxx.com') +\r\nOU('Company') +\r\nO('Company') +\r\nL('Saint Paul') +\r\nS('Minnesota') +\r\nC('US')) +\r\nSIZE(2048) +\r\nKEYUSAGE(HANDSHAKE DOCSIGN DATAENCRYPT) +\r\nnotbefore(date(2022-01-01))-\r\nnotafter(date(2040-09-11))-\r\nWITHLABEL('SYST TN3270 Site Cert') +\r\nsignwith(certauthlabel('xx Issue 1 Sha2')"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "certficate",
    "info": "to export a certificate from one system to the other when having shared datasets.\r\n1. On owing system issue the command, it should create the copy of the certificate on SYSQ to a file.\r\na. RACDCERT EXPORT(LABEL(‘Cloud Compiling Self Signed’)) DSN('sys5.cts.cc.cert. export')\r\n2. ON rquired system issue the command,\r\na. RACDCERT ID(TCPIP) ADDRING(CloudCompiling)\r\nb. RACDCERT ADD('SYS5.CTS.CC.CERT.EXPORT’) ID(TCPIP) TRUST WITHLABEL(‘Cloud Compiling Self Signed’)\r\nc. RACDCERT ID(TCPIP) CONNECT(SITE LABEL(’ Cloud Compiling Self Signed’) RING(cloudcompiling)\r\nd. SETROPTS RACLIST(DIGTCERT, DIGTRING) REFRESH"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "surrogat",
    "info": "to be able submit jobs on behalf of another user using USER=xxxx on the job card we need to get access to userid.SUBMIT in SURROGAT class."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "smf80 report",
    "info": "we can use smf80 smfdump data to produce a racf violation report. use the below job.\r\n//RACFRW2 EXEC PGM=IKJEFT01 //SORTWK01 DD UNIT=3390,SPACE=(CYL,(100,100)) //SYSPRINT DD DISP=SHR,DSN=report.SMF80 //SYSTSPRT DD SYSOUT=T //RSMFIN DD DISP=SHR,DSN=dump.SMF80 //SYSTSIN DD *,DLM=XX RACFRW SELECT VIOLATIONS PROCESS EV LOGON EV ALLSVC EV ALLCOMMAND SELECT AUTHORITY(SPECIAL OPERATIONS AUDITOR) PROCESS EV ALLSVC EV ALLCOMMAND SELECT REASON(CLASS SPECIAL CMDVIOL) PROCESS EV ALLSVC EV ALLCOMMAND LIST SORT(USER)\r\nEND DLM"
  },
  {
    "Vendor": "IBM",
    "component/product": "RACF",
    "type": "DB2 wrong password",
    "info": "ou need to find the error messages that show someone putting in the wrong password, if this is put in by a DB2 connection you will see 10:38:42 22JAN D2PBDIST ICH408I USER(P#00252 ) GROUP(D#825660) NAME(NPSA - PSAR\r\n10:38:42 22JAN D2PBDIST LOGON/JOB INITIATION - REVOKED USER ACCESS ATTEMPT"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "GID",
    "info": "to assign a OMVS GID to a RACF group. we can use the following commands\r\nALTGROUP SECADMIN OMVS(GID(336)) --- manually assigning the GID if we have the list of GID noted down.\r\nALTGROUP C21S@ALT OMVS(AUTOGID) --- this will assign a GID automatically if the AUTOGID function is enabled."
  },
  {
    "Vendor": "longperl",
    "component/product": "research",
    "type": "Website",
    "info": "http://www.lookupmainframesoftware.com/ --- ISV comparision site."
  },
  {
    "Vendor": "IBM",
    "component/product": "REXX",
    "type": "commands",
    "info": "To display a panel -- ADDRESS ISPEXEC \"DISPLAY PANEL(LICHKP2)\" and display a panel and select the options \"ISPEXEC SELECT PANEL(PARMPAN1)\""
  },
  {
    "Vendor": "IBM",
    "component/product": "REXX",
    "type": "commands",
    "info": "To browse a member -- ADDRESS ISPEXEC \"BROWSE DATASET('\"DS\"(LICEXPDT)')\" \r\n browse a member based on the system name we are running it on.\r\n ST=MVSVAR('SYSNAME') \r\n DS=SYS5.CTS.TOOL.PARMLIB.COLLECT \r\n ADDRESS ISPEXEC \"BROWSE DATASET('\"DS\"(\"ST\"PARM)')\" \r\n exit"
  },
  {
    "Vendor": "IBM",
    "component/product": "REXX",
    "type": "commands",
    "info": "To edit a member -- ADDRESS ISPEXEC \"EDIT DATASET('\"DS\"(LICEXPDT)')\""
  },
  {
    "Vendor": "IBM",
    "component/product": "REXX",
    "type": "commands",
    "info": "Libdef to add a dataset to ISPPLIB -- \"ISPEXEC LIBDEF ISPPLIB DATASET ID('SYS5.CTS.LICHK')\""
  },
  {
    "Vendor": "IBM",
    "component/product": "REXX",
    "type": "commands",
    "info": "To break from a program and execute a funciton use CALL. IF a=0 then CALL ABC\r\n ABC is a funciton here. And we can have a set of statements in ABC"
  },
  {
    "Vendor": "IBM",
    "component/product": "REXX",
    "type": "Loop",
    "info": "Use a END command to END a DO Loop. Do …… END"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "commands",
    "info": "to open a file to read the content : \"ALLOC F(INFILE) DSN('my.seq.dsn') SHR REU\", \"EXECIO * DISKR INFILE ( FINIS STEM MYFILE.\" , y\"FREE F(INFILE)\""
  },
  {
    "Vendor": "ibm",
    "component/product": "REXX",
    "type": "commands",
    "info": "to write to a file: \"ALLOC FI(LNAME) DA('MY.PS.WRITE') SHR\", \"EXECIO * DISKW LNAME(STEM ARRAY. FINIS\", \"FREE FI(LNAME)\""
  },
  {
    "Vendor": "ibm",
    "component/product": "REXX",
    "type": "commands",
    "info": "SUBWORD('I am a hero',2) -- to get the remaining string from a specific word position."
  },
  {
    "Vendor": "ibm",
    "component/product": "REXX",
    "type": "commands",
    "info": "WORD(String,n) -- WORD('(I am a hero)',2) /* returns 'am' */"
  },
  {
    "Vendor": "ibm",
    "component/product": "REXX",
    "type": "commands",
    "info": "WORDPOS('am a','i am a hero') /*returns 2*/"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "commands",
    "info": "a DO / FOR loop can be ended with a LEAVE instruction."
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "commands",
    "info": "call a funciton. CALL ABC arg1 arg2 … write the code for function as ABC: … RETURN"
  },
  {
    "Vendor": "ibm",
    "component/product": "REXX",
    "type": "commands",
    "info": "LASTPOS(needle,string,start pos) -- returns the last position of needle in the string starting at \"start pos\")"
  },
  {
    "Vendor": "ibm",
    "component/product": "REXX",
    "type": "submit a job",
    "info": "submit a job through rexx\r\n /* REXX */ \r\n ADDRESS TSO \r\n \"SUBMIT 'SYS5.CTS.PARMREXX($1CMDCJC)'\" \r\n EXIT"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "clist",
    "info": "giving % infront a clist when executing in ISPF, It causes ISPF to bypass its search through the program libraries and search only the CLIST libraries for the commands"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "scripts",
    "info": "scritp to generate and submit a job through rexx\r\n /***************REXX*****************/ \r\n ADDRESS 'TSO' \r\n \"ALLOC DA('SYS5.A8S59ZZ.TEST(TEST2)') FI(INPUT) SHR REUSE\" \r\n \"EXECIO * DISKR INPUT (STEM VAR. FINIS\" \r\n \"FREE FI(INPUT)\" \r\n DO I=1 TO VAR.0 \r\n PARSE VAR VAR.I GDGBASE \r\n GDGBASE = STRIP(GDGBASE) \r\n GDGBASE = WORD(GDGBASE,1) \r\n QUEUE \"//A8K53ZZ$ JOB TEST,'TEST',REGION=0M,CLASS=T, \"\r\n QUEUE \"// MSGCLASS=T,PRTY=07,NOTIFY=&SYSUID \"\r\n QUEUE \"//GDGSTEP1 EXEC PGM=IDCAMS \"\r\n QUEUE \"//SYSPRINT DD SYSOUT=* \"\r\n QUEUE \"//SYSIN DD * \"\r\n QUEUE \" DEFINE GDG(- \" \r\n QUEUE \" NAME(SYS8.STUPOUT.\"||GDGBASE||\".DAILY) - \" \r\n QUEUE \" LIMIT(7) - \" \r\n QUEUE \" NOEMPTY - \" \r\n QUEUE \" SCRATCH) \" \r\n QUEUE \"/* \" \r\n QUEUE \"// \" \r\n QUEUE \"$$\" \r\n X = OUTTRAP('LOG.') \r\n \"SUBMIT * END($$)\" \r\n X = OUTTRAP('OFF') \r\n PARSE VAR LOG.2 JOB JOBID MESSAGE \r\n SAY JOB JOBID MESSAGE \r\n END \r\n EXIT"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "jobcard",
    "info": "/* REXX fro jobcard*/ \r\n TRACE I \r\n @LINE1 = \"//\"USERID()\"A JOB TEST,'TEST',REGION=0M\" \r\n @LINE2 = \"// CLASS=A,MSGCLASS=X,MSGLEVEL=(1,1)\" \r\n @LINE3 = \"// NOTIFY=\"USERID()\"\" \r\n ADDRESS ISREDIT \r\n 'MACRO' \r\n 'LINE_AFTER 0 = \"&@LINE1\"' \r\n 'LINE_AFTER 1 = \"&@LINE2\"' \r\n 'LINE_AFTER 2 = \"&@LINE3\"' \r\n \"LINE_AFTER 3 = '//*'\" \r\n EXIT"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "system values",
    "info": "we can use the function MVSVAR to collect system name,zos name, version and many other values."
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "pull from user",
    "info": "command to get values from a user.\r\n SAY \"Enter the parmlib member you are lookin for \" \r\n parse pull parm"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "libdef",
    "info": "sample libdef program./* REXX */ to add a dataset for SYSPROC/SYSEXEC concatenation. \r\n TRACE I \r\n DA=SYS5.CTS.TOOL.PARMLIB \r\n ADDRESS ISPEXEC \"LIBDEF ISPPLIB DATASET ID('\"DA\".PANEL')\" \r\n ADDRESS TSO \"ALTLIB DEACTIVATE APPL(EXEC)\" \r\n ADDRESS TSO \"ALTLIB ACTIVATE APPL(EXEC) DA('\"DA\".EXEC')\" \r\n ADDRESS ISPEXEC \"SELECT PANEL(PARMPAN1)\" \r\n ADDRESS ISPEXEC \"LIBDEF ISPPLIB\" \r\n ADDRESS TSO \"ALTLIB DEACTIVATE APPL(EXEC)\""
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "date",
    "info": "X = DATE('N','03112','J'); SAY X -- julian to regular date"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "",
    "info": "insert data into a file using rexx\r\n\"execio * diskr ddname (finis)\" /* stack the dataset contents */\r\nqn=queued()\r\ndo qn /* process stacked data */\r\nparse pull r\r\nqueue r\r\nif pos('whatever you are looking for',r)>0 then queue ' inserted data'\r\nend\r\n\"execio\" queued() \"diskw ddname (finis)\" /* rewrite dataset */"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "pds member",
    "info": "to check if a ps or a pds member is available.\r\nISOK=SYSDSN('LQ.SLQ.TLQ(SAMPLE)') IF ISOK = \"OK\" THEN address ispexec \"Browse Dataset('LQ.SLQ.TLQ(Sample)') \"\r\nRead more: http://ibmmainframes.com/about43384.html#ixzz6OIduCYKv"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "pds member",
    "info": "to check if a dataset is pds\r\nFC = LISTDSI(dsname)\r\nIF SYSDSORG ¬= 'PO' THEN ITERATE\r\nLISTDSI can be used to get the Created, referenced and other values that we see when we give \"I\" next to a dataset\r\n/* REXX */ DINFO = LISTDSI('A93LNZZ.JCL.PROD') CDATE = SYSCREATE --- give the dataset creation date SAY CDATE EXIT"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "select statment",
    "info": "SELECT\r\nWHEN expression THEN instruction\r\nWHEN expression THEN DO instruction END\r\nWHEN expression THEN instruction\r\n⋮\r\nOTHERWISE\r\ninstruction(s)\r\nEND /* -- should be on a seperate line */ else we will get errors /*Incomplete DO/SELECT/IF*/\r\nNo need to use DO if multiple instrucitons"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "time zone varibale",
    "info": "/* REXX Calculate the local timezone from MVS system variables.*/\r\n\r\nday_different = mvsvar('SYMDEF','LYR4') - mvsvar('SYMDEF','YR4')\r\nif day_different = 0 then\r\nday_different = mvsvar('SYMDEF','LJDAY') - mvsvar('SYMDEF','JDAY')\r\nhours_different = mvsvar('SYMDEF','LHR') -,\r\nmvsvar('SYMDEF','HR') + 24 * day_different\r\nmin_different = right(abs(mvsvar('SYMDEF','MIN') -,\r\nmvsvar('SYMDEF','LMIN')),2,'0')\r\nsign = substr('+-',(hours_different < 0)+1,1)\r\nreturn sign || right(abs(hours_different),2,'0')min_different"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "compare",
    "info": "ARG FULLSTNAME FULLNAME1 SAY FULLSTNAME SAY FULLNAME1 TRACE I \"ALLOC FI(NEWDD) DA(\"FULLSTNAME\") REUSE SHR\" \"ALLOC FI(OLDDD) DA(\"FULLNAME1\") REUSE SHR\" \"ALLOC FI(SYSIN) DA('SYS5.CTS.JCL.CNTL(CMPSYSIN)') REUSE SHR\" \"ALLOC FI(OUTDD) DA('A93LNZZ.JCL.TEST(CMPSYOUT)') REUSE SHR\" PARMS = \"LINECMP,DELTAL,SEQ\" ADDRESS LINKMVS 'ISRSUPC PARMS' /* ADDRESS ISPEXEC \"SELECT PGM(ISRSUPC) PARM(\"PARMS\")\" */ SAY RC RETRC = RC \"FREE FI(NEWDD OLDDD SYSIN OUTDD)\" RETURN RETRC"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "call/return",
    "info": "CALL ABC x1 x2. -- call a function ABC, we can pass values x1 and x2 to the function.\r\noutval = C -- the returned value can be saved in a variable.\r\nABC: -- start of fucntion abc\r\nARG x1 x2 -- x1 and x2 are read by the funtion.\r\nc = x1 + x2\r\nReturn C -- return the value C to the call."
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "edit macro through rexx",
    "info": "/* rexx edit macro to change values */\r\n'ISREDIT MACRO'\r\n'ISREDIT C' curval newval 'ALL'\r\n'ISREDIT save'\r\n'isredit end'\r\n\r\nThen, invoke the editor from your exec:\r\n\r\nCALL alloc_tempfile /* allocate tempfile */\r\n\"address ispexec edit dataset(\"tempfile\") imacro(changer)\""
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "tso command",
    "info": "rexx to capture the output of tso command\r\nTRACE 'o' PARSE ARG tsocmd cmdrc=0 IF tsocmd¬='' THEN DO x=OUTTRAP('tsoresp.') ADDRESS 'TSO' tsocmd cmdrc=rc x=OUTTRAP('OFF') DO i=1 BY 1 WHILE i<=tsoresp.0 QUEUE tsoresp.i END END EXIT cmdrc"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "ispf panels",
    "info": "we can invoke panels without going out of the current panel. invoke browse panel when editing some member and comeback to the edit panel.\r\nthis rexx add's new shortcuts to the ISPCMDS command table. so we can use these commands.\r\n* Rexx */ zctverb=”BR” zcttrunc=”0”\r\nzctact=”SELECT PGM(ISRBRO) PARM(ISRBRO01) SCRNAME(VIEW)” zctdesc=”BROWSE SCREEN” Address ISPEXEC “TBADD ISPCMDS” zctverb=”ED” zcttrunc=”0”\r\nzctact=”SELECT PGM(ISREDIT) PARM(P,ISREDM01) SCRNAME(EDIT)” zctdesc=”EDIT SCREEN” Address ISPEXEC “TBADD ISPCMDS” Exit"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "cpu capcity",
    "info": "/* REXX */ rct = c2d(storage(d2x(c2d(storage(d2x(c2d(storage(10, 4))+604), , 4))+228), 4)) say 'CEC MSU capacity='c2d(storage(d2x(rct+32), 4))';' , 'defined LPAR MSU capacity='c2d(storage(d2x(rct+28), 4))"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "capture",
    "info": "capture tso command output.\r\n/* REXX */ /* */ /* AUTHOR: MARK ZELDEN */ /* */ /* TRACE ?I */ arg TSOCMD address ISPEXEC \"CONTROL ERRORS RETURN\" address TSO ddnm = 'DD'||random(1,99999) /* choose random ddname */ junk = msg(off) \"ALLOC FILE(\"||ddnm||\") UNIT(VIO) NEW TRACKS SPACE(5,5) DELETE\", \" REUSE LRECL(140) RECFM(F B) BLKSIZE(8960)\" junk = msg(on) /* */ /* issue tso commnd and trap output */ /* */\r\njunk=outtrap(LINE.) TSOCMD junk=outtrap('off') /* */ \"EXECIO\" line.0 \"DISKW\" ddnm \"(STEM LINE. FINIS\" address ISPEXEC \"LMINIT DATAID(TEMP) DDNAME(\"||ddnm||\")\" address ISPEXEC \"BROWSE DATAID(\"||temp\")\" address ISPEXEC \"LMFREE DATAID(\"||temp\")\" junk = msg(off) \"FREE FI(\"||ddnm||\")\""
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "unix",
    "info": "/* REXX */ --- REXX that uses unix environemtn to stop the execution for 5 sec.\r\naddress syscall sleep 5 EXIT"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "sdsf",
    "info": "mvs commands through rexx \r\nWell, we could always do this via REXX. We can run it in batch under IKJEFT01 or foreground. \r\n\r\nFor instance -\r\nxc = ISFCALLS(\"ON\") \r\nPARSE PULL com\r\nAddress SDSF \r\n\"ISFEXEC /\"com\" \"\r\nxc = ISFCALLS(\"OFf\") \r\n\r\nIf we want to see the output, we cud put a DO loop to list isfulog. stem variable which wud be capturing the data."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "types",
    "info": "RMF 1 -- post processor (produce reports). Periodically writes performance data to SMF records 70-78.\r\nRMF II -- screen shot of a single addr. space and resource use / \r\nRMF III -- called as workload dealy monitor. Sessions are used to check the performance of users or jobs, how fast they are running (workflow) and any delays that have been encountered along the way."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "cpu report",
    "info": "RMF CPU report based on 70:79 smf records\r\n//RMFPP EXEC PGM=ERBRMFPP,REGION=0M //MFPINPUT DD DISP=SHR,DSN=MMM.SMF.SYSR.RMF.G3515V00\r\n//MFPMSGDS DD SYSOUT=* //SYSPRINT DD SYSOUT=* //SYSIN DD * REPORTS(CPU) /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "options",
    "info": "If you do not specify a MEMBER option, RMF uses a particular default parmlib member for each type of gatherer session:\r\n ERBRMF00 for Monitor I -- has the sysnc parm that specifies when to sync the records with SMF.\r\n ERBRMF01 for Monitor II\r\n ERBRMF04 for Monitor III\r\n These members are supplied with RMF, as are two alternative members:\r\n ERBRMF02 for Monitor I\r\n ERBRMF03 for Monitor II"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "commands",
    "info": "/F RMF,D ZZ -- dispalys the options used with Monitor-1 and ERBRMFxx suffix values used."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "ddr",
    "info": "Application programs can retrieve sysplex wide RMF data through the RMF Distributed Data Server (DDS). In this process, the application program sends a HTTP request to the RMF DDS, which in turn gathers the information required from the RMF instances running on the sysplex members. The RMF DDS then returns the response to the application in the form of an XML document."
  },
  {
    "Vendor": "Macro4",
    "component/product": "rmf",
    "type": "ddr collection",
    "info": "https://www.ibm.com/support/pages/apar/OA54982 -- the jcl that comes with apar can be used to collect the DDR. the module GPMCSVM3 is use with the job."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "invocation",
    "info": "ISPF access for RMF\r\nCheck for SYS1.SERB* files and add them to your SYSPROC, IPSMLIB and plib and so on\r\nissue the command TSO RMF to invoke rmf panels.\r\nissue the commadn TOS RMF UTIL to invoke rmf utility panels."
  },
  {
    "Vendor": "ibm",
    "component/product": "RMF",
    "type": "DDR collection",
    "info": "ibm        rmf        GPMSERVE        \"GPMSERVE is a STC that is run on MF -- RMF-DDS-Server\r\nOnce we enable this and we have RMF running on the system we can use weblinks to collect many metrics\r\nhttp://system.xxx.com:8803/gpm/perform.xml?id=8D0420&RESOURCE=SYSTEM,*,PROCESSOR -- this would giveus the value of DDR metric 8D0420(MVS view of CP utilization) for system.\""
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "DDR collection",
    "info": "check the dataset SYS1.SERBPWSV and search for DDR to find out under which metric this DDR gets collected."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "DDR collection",
    "info": "http://xxxx.yyyy.com:8803/gpm/perform.xml?id=8D2540&RESOURCE=,cecmodel,cpc --- cec cpu %"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "DDR collection",
    "info": "http://xxxx.yyyy.com:8803/gpm/perform.xml?id=8D30E0&RESOURCE=lparname,*,PROCESSOR --- no of jobs waiting"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "access",
    "info": "There are several monitoring tools and applications that can be used to monitor RMF data using a workstation:\r\n\r\nz/OSMF is a management console that amongst other things, can access most RMF Monitor III information and save custom views of this data.\r\nRMF Performance Monitoring (RMF PM) obtains RMF data available through the RMF Distributed Data Server (DDS). It allows you to define scenario based templates called PerfDesks that whenever opened, will obtain RMF data according to the performance monitoring requirement.\r\nClient/Server Enabling (RMFCS) allows you to access RMF Monitor II and Monitor III reports using the ISPF Batch GUI feature.\r\nPreviously created Postprocessor reports that have been saved in XML format can be downloaded to your workstation and displayed in a browser, using RMF XSL stylesheets."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "check delay of a job",
    "info": "Steps to check for delay of a job.\r\n1. Invoke RMF monitr ISPF interface 2. Select option 3 RMF Monit III\r\n3. 2 - JOBS\r\n4. provide jobname in JOBNAME field and select 5 JOB \"delay caused by primary reason\"\r\n5. At the bottom of the screen in the \"JOB PERFORMANCE SUMMARY\" look for \"% delayed for \" PRC -- waiting for processor / DEV -- Waiting for I/O / STR -- Waiting for storge / OPR -- operator action such as tapemount / ENQ for ENQ. we can also check \"Primary delay\" field."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "reports",
    "info": "post processor reports\r\nInterval Reports : displays sysplex performance for each interval for which data has been gathered.\r\nDuration reports : contain data,which is summarized over longer periods of time.\r\nSummary, exceptions and overlay reports: allows you to create reports you need to manage the system performance.\r\nOverview records : these can be fed into workstation spread sheets.\r\nweb browser data : reports created in xml format allowing them to be displayed through web browser."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Roscoe",
    "type": "Ver check",
    "info": "ROSCOE STC - ROS001I"
  },
  {
    "Vendor": "ibm",
    "component/product": "rrs",
    "type": "understanding",
    "info": "Let me first give an overview of RRS logstreams and their usage. RRS has 4 mandatory logstreams\r\nATR.gname.RM.DATA Contains list of all RMs registered to RRS and current status with RRS Cannot tolerate dataloss! Recommended to use logstream duplexing\r\nATR.gname.MAIN.UR\r\nContains active local URs Generally minimally used\r\nATR.gname.DELAYED.UR\r\nContains active URs RMs can set option so all (local or sysplex) URs are logged here Majority of all URs will be logged here\r\nATR.gname.RESTART\r\nContains URs associated with RMs that terminated and have not yet restarted Cannot tolerate dataloss! Recommended to use logstream duplexing RRS has 2 optional logstreams\r\nATR.gname.ARCHIVE\r\nContains all completed URs Not recommended to use in a dasd-only environment for performance reasons Must set AUTODELETE(YES) and RETPD(n) on definition to ensure data is only retained for desired n days before it is autodeleted. ATR.gname.METADATA\r\nFor use by RMs to store any desired metadata. Not currently exploited"
  },
  {
    "Vendor": "ibm",
    "component/product": "rrs",
    "type": "check",
    "info": "to check the status of RRS.\r\nTo look at the current status of the RRS logstreams, you can issue: D LOGGER,L,LSN=ATR* (name of the logstream)\r\nThis will tell you whether any of the logstreams are in a dataloss condition.\r\nRRS also has displays that can be issued to check status details.\r\nD RRS,RM shows the current state of Resource managers with RRS -- if the status is RESET no need to worry the task might not be using RRS now. D RRS,UREX shows any RRS URs (representing transactions) that may be hung or delayed and where they are waiting."
  },
  {
    "Vendor": "ibm",
    "component/product": "rrs",
    "type": "check - Dataloss conditon.",
    "info": "IXG251I IKJ56228I DATA SET LOGR.ATR.PLEX1.DELAYED.UR.A0000002 NOT IN CATALOG OR CATALOG CAN NOT BE ACCESSED *039 ATR202D GAP FOUND IN ATR.PLEX1.DELAYED.UR. REPLY RETRY OR ACCEPT TO\r\nACCEPT THE DATA LOSS\r\nWe get these error message when the logstream backup datasets are missing. We either have to restore these datasets and then try a RETRY. if there is no way to have these datasets restored. then check all the systems in the sysplex for any such messages and reply ACCEPT.\r\nif you get the message again reply ACCEPT again it could be because the system had processed some records and was looking for the above dataset by the time we reply to this WTOR. We can try that for a couple of times. We can try stopping any tasks that wuld use RRS services and try the reply commands is possible."
  },
  {
    "Vendor": "ibm",
    "component/product": "rrs",
    "type": "check - Dataloss conditon.",
    "info": "We need to do a COLD start of RRS if the problem persists\r\nhttps://www.ibm.com/support/knowledgecenter/SSLTBW_2.3.0/com.ibm.zos.v2r3.iean100/iea3n1143.htm\r\n\r\n1. issue the command /SETRRS CANCEL to call the members of sysplex. Using the strucutre if you are using DASD only type then we need to do it only on this system.\r\n2. Use the job in ATRCOLD member of SYS1.SAMPLIB to delete and redfine the RRS RM Data logger.\r\n3. Start RRS on one system and then on the other sysplex systems."
  },
  {
    "Vendor": "ibm",
    "component/product": "rrs",
    "type": "check - Dataloss conditon.",
    "info": "If, however, you want to force a cold start and keep the data in the existing logs, specify a different log group name in the JCL that invokes IXCMIAPU, as described for step 3 in the preceding list.\r\n//ATRCOLD JOB MSGLEVEL=(1,1)\r\n//STEP1 EXEC PGM=IXCMIAPU\r\n//SYSPRINT DD SYSOUT=*\r\n//SYSIN DD *\r\nDATA TYPE(LOGR)\r\nDELETE LOGSTREAM NAME(ATR.RRSGROUP.RM.DATA)\r\n/*\r\n// IF (STEP1.RC = 0) THEN\r\n//STEP2 EXEC PGM=IXCMIAPU\r\n//SYSPRINT DD SYSOUT=*\r\n//SYSIN DD *\r\nDATA TYPE(LOGR)\r\nDEFINE LOGSTREAM NAME(ATR.RRSGROUP.RM.DATA) STRUCTNAME(LIST01)\r\nLS_DATACLAS(VSAMLS)\r\n/*\r\n// ENDIF"
  },
  {
    "Vendor": "ibm",
    "component/product": "rrs",
    "type": "reporting",
    "info": "//LISTUTIL JOB MSGLEVEL=(1,1),NOTIFY=xxxxxxx,MSGCLASS=A\r\n//STEP1 EXEC PGM=IXCMIAPU\r\n//SYSPRINT DD SYSOUT=*\r\n//SYSIN DD *\r\nDATA TYPE(LOGR) REPORT(YES)\r\nLIST LOGSTREAM NAME(ATR.PLEX1.*) DETAIL(YES)\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "rrs",
    "type": "checking",
    "info": "After we have a DATALOSS condition and trying to restart WAS tasks.\r\nJust a note going forward regarding the WAS resource managers. If you restart the WAS regions listed in the RRS RM displays, I expect that they might fail because WAS typically does not tolerate missing data in the RRS UR logstreams. There is an ATRQSRV utility option to delete an RM from RRS, DELETERM. You can use this to delete those WAS region RMs and allow them to start cold with RRS if needed:\r\nMVS Programming: Resource Recovery -> ATRQSRV utility https://www.ibm.com/support/knowledgecenter/en/SSLTBW_2.3.0/com.ibm.zos.v2r3.iean100/iea3n1167.htm\r\nNew WAS regions / Resource Manager names will have no problem starting with RRS."
  },
  {
    "Vendor": "ibm",
    "component/product": "sadump",
    "type": "note",
    "info": "The stand-alone dump program and the stand-alone dump together form what is known as the stand-alone dump service aid.\r\n The user generated stand-alone dump program must reside on a storage device that can be used to IPL from.\r\n The dump dataset can span across 32 volumes if defined as a DSNTYPE=LARGE"
  },
  {
    "Vendor": "ibm",
    "component/product": "sadump",
    "type": "multiple dumps",
    "info": "By coding the DDSPROMPT=YES keyword on the AMDSADMP macro, you can generate a stand-alone dump program that allows run-time dump data set prompting.\r\n By coding DDSPROMPT=NO on the AMDSADMP macro, the stand-alone dump program is generated without run-time dump data set prompting. In this case, replying to message AMD001A with a DASD device causes the stand-alone dump program to assume that the output dump data set is named SYS1.SADMP"
  },
  {
    "Vendor": "ibm",
    "component/product": "sadump",
    "type": "program dataset",
    "info": "After the stand-alone dump program is properly created on a DASD residence volume, it resides in the SYS1.PAGEDUMP.Vvolser data set."
  },
  {
    "Vendor": "ibm",
    "component/product": "sadump",
    "type": "data",
    "info": "Each version of zOS has a different SADUMP program so we need to generate the program every time we upgrade zOS."
  },
  {
    "Vendor": "ibm",
    "component/product": "sadump",
    "type": "sad",
    "info": "Step 1: Create a SAD dump program with the zOS version modules that you are running. So, every time we do a zOS upgrade we need to re-do the SADUMP process.\r\nUsing the macro AMDSADMP.\r\nWhen we run this macro an IPL-text is created on the specified volume that would be used to IPL the system to collect an SADUMP. jcl to create the dump program or IPL text on the required volume. it gets created with a naming convention of SYS1.PAGEDUMP.Vvolume -- this is the default.\r\nWe can use the PROMPT keyword so we get the option to specify more address spaces to dump other than the default ones included in the program.\r\nOUTPUT parm to specify the volume where the dataset is residing that needs to be used to collect the dump.\r\nRemember the volume unit addr that you have provided for the ipl text to be written to. This is used to IPL the system to collect the sadmp.use DDPROMPT=YES so we can specify the output dataset name while taking the dump.\r\nAnother parm that differentiates the program from other system is the console that you can use to communicate with the dump program.\r\nStep 2: SYS1.SBLSCLI0(AMDSADDD) – use to allocate, clear, delete the dataset where the dump has to be collected."
  },
  {
    "Vendor": "ibm",
    "component/product": "sadump",
    "type": "sad",
    "info": "taking the dump.\r\nWhen the system is in hung state, in the hmc use the SADUMP profile(has the unit addr where the sadump program is written) and activate that lpar.\r\nIn the console that you have mentioned while generating the program we would get a banner. as we have specified DDPROMT an PROMPT while generating the SADUMP program, the system would ask us for unit addr and dataset name where the dump needs to be captured and also the DUMP options to be specified. we can use the DUMP command to specify any or all address spaces to be dumped. DUMP DATASPACES OF ASID(ALL)\r\nOne thing to remember on the HMC profile would be to remember to have the \"STORE STATUS\" check box ticked (Store status is a processor operation that stores the contents of a processor’s registers, excluding the time-of-day (TOD) clock, in assigned storage locations)."
  },
  {
    "Vendor": "ibm",
    "component/product": "sadump",
    "type": "dump steps",
    "info": "1. Remove system form plex - from another plex member issue: V XCF,sysx,OFF (sysx=system to be dumped). Then XXXsysname=sysx (XXX=prompt #)\r\n2. From (HMC) VIEW screen highlight appropriate CEC and then click on customize/delete activation profile. Select the already set profile for SADUMP. In the LOAD ADDRESS field, put in the appropriate standalone dump program IPL address 3. From (HMC) VIEW screen, select GROUPS (click twice)\r\n4. From GROUPS WORK AREA select CPC IMAGES (click twice)\r\n5. From CPC IMAGES WORK AREA, select lpar desired for sa dump. (click twice)\r\n6. From LPAR DETAILS window click once on CHANGE OPTIONS\r\n7. From CHANGE OBJECT OPTIONS under the list, click once to select proper standalone dump profile."
  },
  {
    "Vendor": "ibm",
    "component/product": "sadump",
    "type": "dump steps",
    "info": "8. Select SAVE. On details window under activation profile category, insure the standalone dump you selected is now listed.\r\n9. Select SAVE again.\r\n10. Click once on desired lpar to highlight it from CPC IMAGES WORK AREA.\r\n11. Select ACTIVATE.\r\n12. Wait 30 seconds and press “ENTER” on master console to get first message. Note: If you don’t get a message on the master console go to the Operator Messages screen on the HMC and press the Enter key. You should get the message there. 13. Rspond to dump title information prompt, followed by output device address prompt.\r\nNote: If more than 1 output volume is needed use the other SADPL addresses. Dump is complete when you get the messages stating “dumping of real storage completed”.\r\n14. Ater dump is completed, repeat steps 3 – 9 to select the proper profile to begin the Normal ipl of the system."
  },
  {
    "Vendor": "ibm",
    "component/product": "scrt",
    "type": "website",
    "info": "https://login.ibm.com/authsvc/mtfim/sps/authsvc?PolicyId=urn:ibm:security:authentication:asf:basicldapuser"
  },
  {
    "Vendor": "IBM",
    "component/product": "SDSF",
    "type": "commands",
    "info": "if we get NO DISPLAYABLE DATA -- issue the INPUT ON cmd."
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "search",
    "info": "findlim xxxxx -- updates the no. of line mvs command seraches."
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "sdsfaux",
    "info": "New address space that helps in collecting more information. we have direct options for LNKLIST, LPA, Pagedatasets and parmlib. we can also use SRCH command to search for a program in lnklst and few more functionalities."
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "field arrangement",
    "info": "to arrange fields in the order you want \"ARR ?\""
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "batch command",
    "info": "//jobcard\r\n//step1 exec pgm=sdsf\r\n//isfout dd sysout=*\r\n//dataout dd dsn=xxx.xxx.xxx,DISP=(new,catlg,delete),DCB=(RECFM=FBA,LRECL=133),space\r\n//isfin dd *\r\n/D T\r\n/D J,L\r\nprint file dataout\r\nulog\r\nprint print close\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "print",
    "info": "we can print the output to a dataset.\r\nissue PRINT D -- opens a page to provide the details of the dataset to be used for printing.\r\niseue PRINT * 99999 -- from start of the cursor to no. of lines\r\nissue PRINT CLOSE -- to close the printing."
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "batch jobs",
    "info": "Print the status of job\r\n//SDSF EXEC PGM=SDSF,PARM='++270,132' <== ALSO, CAN USE PGM=ISFAFD\r\n//* ++270 allows you to print 270 lines for each command\r\n//* 132 is the width of the command output.\r\n//ISFOUT DD SYSOUT=*\r\n//ISFIN DD *\r\nOWNER *\r\nPREFIX R2221*\r\nST"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "commands",
    "info": "command to change the SMF dataset before it is full. SWITCH SMF"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "dump",
    "info": "to dump smf records from tape\r\n//STEP1 EXEC PGM=IFASMFDP //DD1 DD DSN=MMM.SMF.SYST.SCRT.G3289V00,UNIT=TAPE,DISP=SHR //DD2 DD DISP=NEW,DSN=A93LNZZ.SMF.DUMP,DCB=LRECL=32760, // SPACE=(CYL,(30,30)) //SYSPRINT DD SYSOUT=* //SYSIN DD * INDD(DD1,OPTIONS(ALL)) OUTDD(DD2,TYPE(70,89)) /*\r\nINDD(DUMPIN,OPTIONS(ALL)) OUTDD(DUMPOUT,TYPE(00:255)) --- to dump all the records in the input dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "data",
    "info": "SMF 70 record is written at every RMF collection interval. It would be in RMF parmlib ERBRMF00"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "smf30",
    "info": "CICS PGm = DFH*\r\nDB2 PGM = DSN*\r\nMQ pgm = CSQ*"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "dump",
    "info": "dump to dasd\r\n//A93LNZZA JOB TEST,'TEST',REGION=0M, // CLASS=A,MSGCLASS=X,MSGLEVEL=(1,1), // NOTIFY=&SYSUID.\r\n//* //IEFPROC EXEC PGM=IFASMFDP //DUMPIN DD DISP=SHR,DSN=SMF.G6268V00 //DUMPOUT DD DSN=&SYSUID..SMF.DUMP,DISP=(NEW,CATLG,DELETE), // SPACE=(CYL,(70,50),RLSE),VOL=SER=ZTSOT3, // DCB=(RECFM=VBS,LRECL=32760) //SYSPRINT DD SYSOUT=* //SYSIN DD * INDD(DUMPIN,OPTIONS(ALL)) OUTDD(DUMPOUT,TYPE(00:255)) //*"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "iefu29",
    "info": "To allow the system to invoke IEFU29, define the exit in the SMF parmlib member (SMFPRMxx). Specify IEFU29 on the EXITS option of the SUBSYS parameter for the STC subsystem. If your installation chooses not to define a SUBSYS parameter for STC, you can specify IEFU29 on the EXITS option of the SYS parameter."
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "T113",
    "info": "Collecting T113 collection.\r\nF HIS,B,TT='runid',PATH='/u/his/',CTRONLY,CTR=(B,E),SI=SYNC"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "commands",
    "info": "while receiving files from internet using SMPNTS and if you want use CLIENTINFO DD you can copy the secured ftp lines to userid.FTP.DATA and then no need to use the <FTPOPTIONS>-f \"//'SYS1.TCPIP(TCPFW)'\" </FTPOPTIONS>"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "website",
    "info": "link to get sample jobs : http://www-01.ibm.com/support/docview.wss?rs=660&context=SSZJDU&uid=swg21066230"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "receive",
    "info": "sample jcl to receive from SMPNTS -- files to have been uploaded to OMVS\r\n//RECNTS EXEC PGM=GIMSMP, // PARM='CSI=MVS.GLOBAL.CSI' //SMPOUT DD SYSOUT=* //*SMPLOG DD DSN=your SMPLOG data set name,DISP=MOD //SMPNTS DD PATH='/var/zowe/builds/zSMP/',PATHDISP=KEEP //*SMPNTS DD PATH='/var/zowe/builds/zSMP/B5625068/',PATHDISP=KEEP //SMPJHOME DD PATH='/usr/lpp/java/J8.0_64/',PATHDISP=KEEP //SYSUT1 DD UNIT=SYSDA,SPACE=(3120,(380,760)) //SYSUT2 DD UNIT=SYSDA,SPACE=(3120,(380,760)) //SYSUT3 DD UNIT=SYSDA,SPACE=(3120,(380,760)) //SYSUT4 DD UNIT=SYSDA,SPACE=(3120,(380,760)) //SYSPRINT DD SYSOUT=* //SMPCNTL DD * SET BDY(GLOBAL). RECEIVE FROMNTS(B5625068). /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "list",
    "info": "//SMPCNTL DD * SET BDY(GLOBAL). LIST HOLDDATA SYSMODS(UI36027, UI42168, UI46658). /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "jobs",
    "info": "SYS1.SAMPLIB(GIMSAMPU) -- sample job to create SMP/e CSI and other base datasets and option definitions."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "list",
    "info": "//SMPCNTL DD * SET BOUNDARY (GLOBAL) . LIST HOLDDATA"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "apply with source",
    "info": "//SMPCNTL DD * SET BOUNDARY (TARGET) . APPLY BYPASS ( HOLDERROR HOLDFIXCAT HOLDSYSTEM HOLDUSER ) CHECK SOURCEID ( SMCCOR ) RETRY(YES) ."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "apply with FMID",
    "info": "FORFMID( HHBO210\r\nHHBO21L\r\n)"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "fixcat",
    "info": "A fix category is an identifier used to group and associate PTFs to a particular category of software fixes. A fix category might be used to identify a group of fixes that are required to support a particular hardware device, or to provide a particular software function, similar to how a preventive service planning bucket (PSP-bucket) identifies a group of PTFs. Fix categories are supplied to you in the form of SMP/E FIXCAT HOLDDATA statements. Each FIXCAT HOLDDATA statement associates an APAR and its related fixing PTF to one or more fix categories."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "fixcat",
    "info": "we can download the HOLDATA from IBM website.http://service.software.ibm.com/holdata/390holddata.html#fb80.\r\nWe can donwlaod the FULL.TXT better to download it directly on mainframe.\r\nand receive the holddata into product specific smpe. the receive holddata. generate the command from smpe panels. \r\n//SMPCNTL DD * \r\nSET BOUNDARY (GLOBAL) . \r\nRECEIVE HOLDDATA . \r\nWe can see the list of available FICAT at https://www.ibm.com/support/pages/ibm-fix-category-values-and-descriptions"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "fixcat",
    "info": "listing the missing sysmods:\r\n//SMPCNTL DD * \r\nSET BOUNDARY (GLOBAL) . \r\nREPORT MISSINGFIX ZONES ( SYSQRAT ---- target zone ) \r\nFIXCAT( IBM.Device.Server.z14-3906.RecommendedService -- FIX CAT categlory. ) ."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "usermod hold",
    "info": "We should not accept a usremod as it would cause issues at a later date when a ptf hits the usermod.\r\nBTW One of the most important things to remember with SMPE is to never ACCEPT a Usermod. The Usermod is created as a unique piece of code and change that affects only the Installation. There are 4 types of Sysmods in SMPE, APAR, Function, PTF and Usermod. The Usermod is the only one that must stay in APPLY status. New Maintenance will arrive that may hit the same module that\r\na Usermod is covering and so the Usermod must be RESTOREd. If not, the APPLY Check will fail with a MODID Error. Subsequently the Usermod must be updated to include the new PTF in the PREREQ and re-Applied. So how to stop the Usermod being ACCEPTED? Use this little technique. Once the Usermod has been Applied, create the following HOLD Data naming the Usermod and the FMID\r\nit is applicable to and RECEIVE this HOLDDATA. Now when you try to perform an ACCEPT Check on this Usermod (maybe in error), this Hold Data will stop the Accept from completing and it will inform that a Usermod is in the list\r\nand needs to be removed before the ACCEPT Check completes successfully.\r\n++HOLD(usermodname) USER FMID(fmidname)\r\nREASON(NOUSERM)\r\nCOMMENT(DO NOT ACCEPT THIS USERMOD)."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "notes",
    "info": "SMP/e can -- Automaticlaly install pre-requeisite products / Run unix scripts / copy data into specific libraries / chekc if a ptf has been aready installed / check if requesisite fixes are installed / MOD -- is a OBJECT Module (translated to machine code)"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "process",
    "info": "CSI -- consolidated software inventory.-- Vsam dataset that smp/e uses to store the details of the products received/installed. Global(receive), target(apply), distribution(accept)."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "receive",
    "info": "RECEIVE command copies RELFILES into SMPPTS (PTF temporary storage) datasets.\r\nuser smppts, relfiles, smptlib, log files."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "apply",
    "info": "set boundary(tgt001)\r\napply select(FMID001)\r\nAPPLY command install the products as per the MCS statements in SMPPTS and SMPTLIB datasets into target libraries.\r\nUpdate the status of the SYSMOD in global zone as applied.\r\nAPPLY command acts against many elements as follows\r\nMOD -- object modules are linkedited/Bind and copied to target libraries.\r\nSRC -- is assembled to form OBJECT MODULE and LINKEDITED/BIND to get PROGRAMS and copied to target libraries.\r\nMAC -- MACROS are copied into Macro libraries.\r\nLibraries used SMPMTS --(temporary store of macro elemetns for assembling source code).\r\nSMPSCDS -- (temporary backup of entries modified during apply processing. this is used during restore processing. SMPSTS -- temporary store of source elements used for assembling of surce elements.\r\nSMPWORK"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "accept",
    "info": "SET BOUNDARY(dist001)\r\nACCEPT REmoves work datasets : SMPPTS members / SMPTLIB datasets / RELFILES\r\nWhen a SYSMOD is accepted its information is remove in GLOBAL zone."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "relfiles / SMPTLIB",
    "info": "Relfiles are the files that a product is supplied by a vendor that can be used for receiving the product in SMP/e.\r\nIf a SYSMOD being received is packaged in relative files(relfiles), those files are loaded into temporary direct access data sets as part of RECEIVE processing, These temporary data sets, called SMPTLIBs.\r\n\r\nSMPTLIB are generally using during FMID processing. For a bundled PTFS we have both the MCS and MCS text copied into the SMPPTS"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "RMID/UMID",
    "info": "RMID -- SYSMOD id that replace an element. UMID -- SYSMOD id that updates an element"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "reject",
    "info": "REJECT SELECT(PTFA). \r\nAll SYSMOD information is removed from the SMPPTS.\r\nAll SMPTLIB libraries for the sysmod are deleted if packaged using RELFILEs."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "restore",
    "info": "RESTORE SELECT(PTFA)\r\na sysmod can be restored if it has been applied and a previous SYSMOD that it modifies has been accepted.\r\nIt backs-out a SYSMOD apply, restoring elements from the distribution libraries.\r\nSYSMOD elements in target libraries are resoted from the most recent elements in the distribution libraries.\r\nThe SYSMOD is removed from the target zone."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "uclin",
    "info": "uclin add mod(xxxx) fmid(yyyy) -- to add a module.\r\nuclin add dddef(cccc.cccc.cccc) -- to add dddef entry in smp/e zones.\r\nuclin del targetzone(tgt001) -- to delte a target zone.\r\nuclin del dlibzone(dis11) -- to delete a distribution zone.\r\nuclin add options compact(yes) -- update global zone options.\r\nuclin rep sysmod -- to replace a sysmod."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "commands",
    "info": "list sysmod(fmidxxx) -- list entries of the csi here it is the fmid sysmod.\r\nreport errsysmods zones(tgt1) -- produces report will all sysmods that are applied with unresolved hold data. may have been installe before teh sysmod is applied."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "regression sysmod",
    "info": "Regression occurs when SMP/E installs an element from a SYSMOD that did not express a proper PRE or SUP relationship with the RMID and UMID values in the element entry. Regression can occur only when BYPASS(ID) is used to ignore such errors"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "shopz reprot",
    "info": "Jcl to generate a report for shopz to downlaod a maintanance for a product.\r\n\r\n//STEP1 EXEC PGM=GIMXSID,PARM='WAIT=10MIN,L=ENU' \r\n//SYSPRINT DD SYSOUT=* \r\n//SMPOUT DD SYSOUT=* \r\n//SMPXTOUT DD DSN=&SYSUID..SHOPZ.REPORT,DISP=(NEW,CATLG), \r\n// DCB=(RECFM=FB,LRECL=12560,BLKSIZE=25120), \r\n// SPACE=(TRK,(10,10)) \r\n//*SMPXTOUT DD PATH='/existing_directory/new_file', \r\n//* PATHOPTS=(OWRONLY,OCREAT,OTRUNC), \r\n//* FILEDATA=BINARY,PATHMODE=(SIRWXU,SIRWXG,SIRWXO) \r\n//SYSIN DD DATA,DLM=$$ \r\nCSI=SMPE.IBM.CDP.V1R1.GLOBAL.CSI \r\nTARGET=TARGET \r\n$$"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "RECeive from network -1",
    "info": "//SMPER1 EXEC PGM=GIMSMP,REGION=0M, // PARM='PROCESS=WAIT' //SMPCSI DD DISP=SHR,DSN=SMPE.IBM.CDP.V2R1.GLOBAL.CSI //SMPNTS DD PATHDISP=KEEP, // PATH='/products/cdpv2r1/install' //SMPWKDIR DD PATHDISP=KEEP, // PATH='/products/cdpv2r1/install' //SMPJHOME DD PATH='/products/java864/' //SMPCPATH DD PATH='/usr/lpp/smp/classes/' //SMPOUT DD SYSOUT=* //SMPRPT DD SYSOUT=* //SMPLIST DD SYSOUT=* //SYSPRINT DD SYSOUT=* //SMPCNTL DD * SET BOUNDARY (GLOBAL) . RECEIVE FROMNETWORK( SERVER(SERVINFO) CLIENT(CLNTINFO) ) . /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "RECeive from network -2",
    "info": "//SERVINFO DD * <SERVER as provided by the vendor\r\n> </PACKAGE> </SERVER> /* //* //CLNTINFO DD * <CLIENT javahome=\"/products/java864/\" downloadmethod=\"https\" downloadkeyring=\"javatruststore\"> </CLIENT> /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "psp",
    "info": "http://www14.software.ibm.com/webapp/set2/psearch/search?domain=psp -- website to check for PSP update"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "reject",
    "info": "When we reject a sysmod we need to specify the HOLDDATA also else the PTF entry will still be there in the GLOBAL zone.\r\n//SMPCNTL DD * SET BOUNDARY (GLOBAL) . REJECT HOLDDATA SELECT ( UJ02468 UJ03533 UJ03850 ) ."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "apply",
    "info": "GIM35501E ** AN ERROR OCCURRED DURING PROCESSING OF THE MCS ENTRY FOR SYSMOD UJ03590 IN THE SMPPTS LIBRARY. if we get this error during a APPLY processing then check for SMPPTS DD for the ptf residing and code the DD in teh apply job pointing to the SMPPTS dataset."
  },
  {
    "Vendor": "IBM",
    "component/product": "smpe",
    "type": "report",
    "info": "report functional sysmod\r\n//SMPCNTL DD * SET BOUNDARY (CAIT0) . LIST FUNCTIONS SYSMOD ."
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "receive",
    "info": "if you are trying to receive multiple ptf's in a PDF then we need to specify SMPPTS pointing to each member once. THe receive command in general looks for a ps. if we provide PDS and no member name then we will have error \"WRNG.LEN.RECORD,0000011C000C05\" -- reason \"You have specified the SMPPTS (a PDS/PDSE) as sequential input. This\r\nmeans the \"directory\" of the PDS/PDSE is being read as a logical record. As we all know, the \"logical record length\" of a PDS directory entry is 256, not 80, hence your problem.\""
  },
  {
    "Vendor": "ibm",
    "component/product": "smt",
    "type": "what",
    "info": "zOS Simultaneous Multi Threading.\r\nzIIP processors can be configured to run up to 2 simultaneous threads that share a physical core’s resources.\r\nReduces instruction processing latency at the core level by allowing one thread to access a core’s resources while another thread is forced to wait on resolution of a processor cache miss."
  },
  {
    "Vendor": "ibm",
    "component/product": "smt",
    "type": "implementation",
    "info": "Implementation :\r\na. Update the LOADxx with the statement PROCVIEW CORE b. Update the IEAOPTxx memeber with parm MT_ZIIP_MODE=2"
  },
  {
    "Vendor": "ibm",
    "component/product": "smt",
    "type": "benefit",
    "info": " how are we going to measure before & after savings\r\na.        zOS converts all the measurements for SMT to an equivalent non SMT. This enables to ensure no changes in CPU time consumption per workload before and after SMT implementation. So, if our zIIP usage is not increased from earlier we may not see much difference. The understanding is that our zIIP cores runs more productively so you can bring in more zIIP related workload.\r\nb.        As per IBM the maximum through put we can achieve by enabling SMT is 140% without SMT is 100%.\r\nc.        The best way is to calculate the throughput of a zIIP core from smf data before and after implementing SMT."
  },
  {
    "Vendor": "ibm",
    "component/product": "smt",
    "type": "workload",
    "info": "1. What workload was running that can be benefitted by SMT?\r\na. SMT is a hardware feature where we are trying to increase the through put of the physical CPU cores. In general we only have one program/instruction (thread) per core of a physical CPU and only after it gets executed another program/instruction is readied for that core. With SMT we can have 2 threads active at the same time so when one instruction is put on wait that other instruction can execute rather than waiting. There by increasing the productive time of each core. So, by logic all the work that generally executes in a CP core is benefitted by SMT. To be more precise, if we have an application that can run many parallel instruction rather than linear execution can benefit more.\r\nThe mainframe does it a bit different by ensuring all the threads to the core are from the same program. It is enabled only for zIIP’s at this point of time.\r\nFor compute-intensive batch workloads, automated processes can switch to SMT Mode 1 (one thread per core) to maximize thread speed. For data-oriented workloads, automated processes can switch to SMT Mode 2 (two threads per core) to maximize core throughput"
  },
  {
    "Vendor": "ibm",
    "component/product": "smt",
    "type": "smt",
    "info": "1. create IEAOPT0x by copying IEAOPT00 and add MT_ZIIP_MODE=2 \r\n 2. update SYS5.IPLPARM(LOADx1) to add PROCVIEW CORE to change processor view from CPU to CORE \r\n 3. update SYS1.PARMLIB(IEASYS0x) to change OPT=00 to OPT=0x \r\n 4. IPL needed to pick up the change \r\n 5. check SYSVIEW for the change verification, option mvs;cpu;\r\n \r\n note: x=last letter of lpar name"
  },
  {
    "Vendor": "IBM",
    "component/product": "sort",
    "type": "syntax",
    "info": "omit COND=(1,80,ch,eq,c' ') -- omits the line that have BLANK chars starting form 1st column to 80th Column. We can concatenate more conditions with AND or OR operators but all have to be in one OMIT condition only."
  },
  {
    "Vendor": "ibm",
    "component/product": "sort",
    "type": "sort",
    "info": "SORT FIELDS=COPY INCLUDE COND=(1,6,CH,EQ,C' ',OR, - 3,3,CH,EQ,C'END') this is will include only the lines that NULL chars in 1-6 cols and\r\nthe line that has END char in 3-5 cols."
  },
  {
    "Vendor": "ibm",
    "component/product": "sort",
    "type": "sort",
    "info": "SORT FIELDS=COPY OUTREC FIELDS=(1:16,17,18:C',',19:34,4,23:C',', 24:72,8,32:C',',33:81,8,41:C',', 42:C' 1',50:C',',52:7,6) the would crate the output as column 1 starting with 17-34 cols of input record and\r\ncolumn 18 is added a , and\r\ncolumn 19 is added with 33-36 cols of input record"
  },
  {
    "Vendor": "ibm",
    "component/product": "sort",
    "type": "sort",
    "info": "SORT FIELDS=(1,80,CH,A) SUM FIELDS=NONE to remove the duplicates from the file. Based on the entire line"
  },
  {
    "Vendor": "ibm",
    "component/product": "sort",
    "type": "sort",
    "info": "OUTREC FIELDS=(1,10,10X,11,10) -- Suppose you want to copy first 10 fields then place 10 blanks and then bytes from 11 to 20 from the input file to output file. Your OUTREC would look like as below."
  },
  {
    "Vendor": "ibm",
    "component/product": "sort",
    "type": "sort",
    "info": "OUTREC FIELDS=(1,10,10Z,11,10) -- Suppose you want to copy first 10 fields then place 10 zeroes and then bytes from 11 to 20 from the input file to output file. Your OUTREC would look like as below. Or\r\n OUTREC FIELDS=(1,10,21:11,10) -- Where 21: would ask the sort to fill the data from 11 to 20 bytes of input into 21 to 30 of the output dataset. SORT will automatically fill in blanks from 11 to 20."
  },
  {
    "Vendor": "ibm",
    "component/product": "sort",
    "type": "sort",
    "info": "OUTREC FIELDS=(1:1,245,246:DATE1(c)) -- we can include today date in the cols 246 as YYYYcMMcDD"
  },
  {
    "Vendor": "ibm",
    "component/product": "sort",
    "type": "sort",
    "info": "SORT FIELDS=COPY JOINKEYS FILES=F1,FIELDS=(1,245,A) JOINKEYS FILES=F2,FIELDS=(1,245,A) REFORMAT FIELDS=(F1:1,245,F2:1,245) JOIN UNPAIRED,F1,ONLY OUTREC FIELDS=(1:1,245) if we have 2 files and need to compare and remove the duplicates and copy only the unmatched lines. here we get only the lines that are not paired in F1 with F2."
  },
  {
    "Vendor": "ibm",
    "component/product": "sort",
    "type": "vb to fb",
    "info": "sort pgm to convert VB PS file to FB PS file.\r\n//S1 EXEC PGM=SORT\r\n//SYSOUT DD SYSOUT=*\r\n//SORTIN DD DSN=A123456.VBIN,DISP=SHR\r\n//FBOUT DD DSN=A123456.FBOUT,DISP=(NEW,CATLG,DELETE),\r\n// UNIT=3390,SPACE=(CYL,(5,5))\r\n//SYSIN DD *\r\nOPTION COPY\r\nOUTFIL FNAMES=FBOUT,VTOF,OUTREC=(5,100)\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "DASD",
    "type": "catalog",
    "info": "CAS -- Catalog address space contians details of the master catalog, user catalogs and the aliase."
  },
  {
    "Vendor": "ibm",
    "component/product": "DASD",
    "type": "catalog",
    "info": "CAS reources --\r\nALLOCLCK -- internal cas resoruce responsible for allocation, deallocaiton, open and lcoses of datasets.\r\nSYSIGGV2 -- provides the ability for cross system sharing of catalogs through serialization.\r\nSYSZTIOT -- controls access to task input/output table resources.\r\nSYSZVVDS -- serialize access to VVDS records."
  },
  {
    "Vendor": "ibm",
    "component/product": "DASD",
    "type": "catalog",
    "info": "F CATALOG,REPORT,PERFORMANCE -- reports that can assist with identifying catalog related problems.shows the accumulative total of occurrences of CAS related events and the average time taken to complete that event.\r\nF CATALOG,CONTENTION -- contention defaults associated with the CAS resources\r\nF CATALOG,CONTENTION(resource,waittime,actions)\r\nF CATALOG,LIST -- display details on active service tasks.\r\nF CATALOG,LIST(taskid) -- taskid can be found in the display from LIST command.\r\nF CATALOG,LISTJ(jobname),DETAIL -- more detailed informaiton on the job."
  },
  {
    "Vendor": "ibm",
    "component/product": "DASD",
    "type": "catalog",
    "info": "You may find that the only way to resolve a resource deadlock is to remove the offending service task. There are several commands that allow you to perform this task, depending on the outcome you require:\r\nD GRS,RES=(SYSZTIOT,*)\r\nF CATALOG,LIST\r\nF CATALOG,LISTJ(jobname)\r\nF CATALOG,END(taskid),REDRIVE -- will run the task again after the initial task is ended.\r\nF CATALOG,END(taskid),NOREDRIVE -- will not run the task again.\r\nF CATALOG,ABEND(taskid) -- used when the END(taskid) does not work.\r\n\r\nwe can also use ,FORCE appended to the command to end a task."
  },
  {
    "Vendor": "ibm",
    "component/product": "DASD",
    "type": "catalog",
    "info": "CAS reources --\r\nALLOCLCK -- internal cas resoruce responsible for allocation, deallocaiton, open and lcoses of datasets.\r\nSYSIGGV2 -- provides the ability for cross system sharing of catalogs through serialization.\r\nSYSZTIOT -- controls access to task input/output table resources.\r\nSYSZVVDS -- serialize access to VVDS records."
  },
  {
    "Vendor": "ibm",
    "component/product": "DASD",
    "type": "catalog",
    "info": "F CATALOG,TAKEDUMP -- to dump the CAS\r\nF CATALOG,TAKEDUMP(SYSPLEX) -- to dump the cas across teh sysplex.\r\nF CATALOG,CLOSE(CATALOG.xxxx) -- This causes the control blocks to be released and automatically rebuilt when a new request for the catalog is received.\r\nF CATALOG,RESTART -- performing a CAS restart / FORCE CATALOG,ARM"
  },
  {
    "Vendor": "BMC",
    "component/product": "Subzero",
    "type": "License",
    "info": "As per BMC we can have all CICS regions running from one lpar and DB2 regions running on another lpar. This would reduce the MLC cost of subsystems."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "symdump/batch",
    "type": "version",
    "info": "invoke symdump panels and issue the command OPTIONS"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "symdump/batch",
    "type": "stop",
    "info": "command to stop symdump batch and collect an IBM dump. Run the CAS9 task point to the CAIENFPRM"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "utility to list the info. In couple datasets. //STEP1 EXEC PGM=IXCMIAPU //SYSPRINT DD SYSOUT=* //SYSIN DD * DATA TYPE(CFRM) REPORT(YES) -- CFRM couple dataset (HLQ, many different parms)\r\n/*\r\nDATA TYPE(LOGR) REPORT(YES) -- CFRM couple dataset (HLQ and all the logrstreams defined many different parms)"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "types",
    "info": "XCF-Local Mode\r\n–No couple data sets\r\nMonoplex\r\n–Has couple data sets\r\n–Determined by PLEXCFG=MONOPLEX -- in PROGxx\r\n• First system into sysplex updates the sysplex couple data set to indicate that no other system is permitted to join the sysplex.\r\n• Must re-IPL the system to change Multisystem capable\r\n–Has couple data sets\r\n–A system can join an existing sysplex if it can:\r\n• Use the same sysplex couple data sets as the rest of the sysplex\r\n• Establish signal connectivity with every system in the sysplex\r\n• Use the same common time reference as the rest of the sysplex"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "Find the active policy by issuing the command: D XCF,POL -- CFRM"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "utility",
    "info": "To define a CFRM policy.\r\n//STEP20 EXEC PGM=IXCMIAPU\r\n//STDOUT DD STDERR=*\r\n//SYSABEND DD STDERR=*\r\n//SYSIN DD *\r\nDATA TYPE(CFRM) REPORT(YES) DEFINE POLICY NAME(POLCF1N1) REPLACE(YES)\r\nCF NAME(xxx\r\nSTRUCUTURE NAME(xxx\r\n.\r\n.\r\n.\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "SETXCF START,POLICY,TYPE=CFRM,POLNAME=POLCF1N1 -- to activate a new policy in CFRM dynamically. We can also start it during ipl in the COUPLExx member."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "The CDS and all accesses to the data therein are managed by XCF. \r\n None of the traditional access methods with which you might be familiar are used for these data sets. The data set is only accessed via XCF channel programs"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "To report the policies and defined structure in CFRM policy.\r\n //STEP1 EXEC PGM=IXCMIAPU \r\n //SYSPRINT DD SYSOUT=* \r\n //SYSIN DD * \r\n DATA TYPE(CFRM) REPORT(YES) \r\n /*\r\n DATA TYPE(LOGR) REPROT(YES)"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "list all the couple datasets\r\n /D XCF,COUPLE."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "/d xcf,cf -- display the coupling facililty systems"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "cfrm",
    "info": "/SETXCF START,REALLOCATE"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "cfrm",
    "info": "/DISPLAY XCF,REALLOCATE,TEST"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "cfrm",
    "info": "/DISPLAY XCF,REALLOCATE,REPORT"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "/setxcf start,rebuild,cfname=CF116T -- to start duplexing"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "/setxcf stop,rebuild,cfname=CF116T -- to stop duplexing"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "couple",
    "info": "/D CF -- to know the level."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "commands",
    "info": "Display External Timer Reference(ETR) data -- D ETR,DATA"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "command",
    "info": "d xcf,structure -- displays all the structure in the cfrm policy structire are assinged to which CF."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "xcf",
    "info": "to display individual coupling facility\r\n/D XCF,CF,CFNAME=xxxxx"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "xcf",
    "info": "command to display a strucutre\r\nD XCF,STR,STRNAME=xxxx"
  },
  {
    "Vendor": "ibm",
    "component/product": "system",
    "type": "commands",
    "info": "D M=STOR"
  },
  {
    "Vendor": "ibm",
    "component/product": "system",
    "type": "commands",
    "info": "D M=CPU"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "STATUS command to list a informaiton including the license, customer number and so on"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "STATUS command to list a informaiton including the license, customer number and so on"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "to refresh the gsvxgsvx options without recycling -- MODIFY SYSVIEW,RELOAD SCFG / F SYSIEW,MODIFY IMSDATA,parmlib\r\nF SYSVIEW,RELOAD SECURITY -- when we update any user or user access in sysview security"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "options",
    "info": "the GSVXSCFG dd in the SYSVIEW task points to the dataset where GSVXGSVX is searched for."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "to continue a command to the next line use \",\"."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "issue COMMANDS command to list all the command support by SYSVIEW. We can use the same to run in batch too."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "batch",
    "info": "use the GSVXBAT pgm to run SYSVIEW commands in batch \r\n//STEP1 EXEC PGM=GSVXBAT\r\n//SYSIN DD * \r\nCOMMAND=(XMVS D,al)\r\n COMMAND=CAILMP  \r\nMENU OFF        \r\nCOMMAND=END     "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "batch",
    "info": "commands to submit a job and get the job output to a dataset. Execute these commands as the next step of the step you want to capture data. //SYSIN DD * COMMAND=(JOBS OPSIPLCK) COMMAND=(SORT STDATE) COMMAND=(1,?)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "if we have issue in issuing mvs commands in sysview then check the command char in profile general or query cmdchar"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "issue xmvs xsdata command to issue a command across all the connected systems."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "LONGCMD to invoke a panel for a long commands."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "groups",
    "info": "Issue the command SECURITY to list the USER and COMMAND groups. To chekc if SYSVIEW is using INternal security or external security check the option  EXTERNAL SECURITY in USER GORUPS and GLOBAL option"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "CPCLPAR, CPC LPAR Capacity Information\r\n- The CPCLPAR command provides a summary of CPC capacity for the LPAR"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "CPCSUM, CPC LPAR Capacity Summary\r\n- The CPCSUM command provides a summary of CPC capacity within your data center."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "PARTINFO, Partition Information\r\n- The PARTINFO command displays information about the logical partitions defined in the physical hardware complex."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "PRISM, Processor Resource/System Manager\r\n- The PRISM command displays PR/SM and LPAR configuration information. and memory information"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "Besides these screens mentioned above, there is also the RMF monitor displays :\r\nRMCAP, RMF CPC Capacity\r\nRMJOBS, RMF Job Information\r\nRMMSU, RMF CPC LPAR Detail\r\nRMPROC, RMF CPC LPAR Processor Information"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "//SYSIN DD * COMMAND=(CTRANLOG PERIOD 1H) /* this command can be used to get the transaction log for a period of the last 1 hr."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "commands",
    "info": "example to write commands spanning multiple lines in batch\r\n COMMAND=(XMVS SETPROG LPA,ADD,MODNAME=HBOSMFEX,DSNAME=SYS2.IBM.CDP.+) \r\n COMMAND=(V1R1.SHBOLPA)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "cci",
    "info": "the command SYSTEMS showup all the systems that can be accessed through that sysview login sesssion. You can select any available session and work with them directly.\r\nthis is possible only when we have CCITCPGW task of CAS9 running on the system and the CCIPARM of the task needs to have the statement of all the systems that we should be able to conncet from that system.\r\nwe can also use XSCONN systemname to connect to another system."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "IPLINFO -- has all the ieaysxx parms and the parmlib concat and other ipl related info."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "IPLSTATS -- to understand the steps in an IPL"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "SYSSYM -- to list the sysbols in the system."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "commands",
    "info": "command for auto refresh -- UPDATE (60 refresh every 60 seconds)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "commands",
    "info": "SPACE -- to list all the volume and the available space."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "SYSVIEW",
    "type": "working",
    "info": "SYSTEM command : If you are referring to the SYSTEMS ALL command (All is the default) after issuing the command please issue the SYSVIEW command LISTLOG. Page over to the right to the DATA portion of the display. SYSVIEW is using the XSSS Subtask of the SYSVUSER STC"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "report wrter",
    "info": "to generate reports in csv format -- SYS2.SYSVIEW.R16.CNM4RSAM($CSVJCL)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "to select only few recrods of a column we can use SELECT TYPE eq STC and TYPE eq JOB and so on."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "IMS logs",
    "info": "When you issue 'XMVS /DIS SUBSYS ALL' from SYSVIEW on SYSF, please perform the following.\r\n1. Issue 'XMVS /DIS SUBSYS ALL'\r\n2. Issue 'LINK LISTLOG' 3. Issue CAPO to open a capture file\r\n4. Issue CAPI to capture the LISTLOG\r\n5. Issue CAPC to close the capture file.\r\n6. Check the LISTLOG for errors when the command was issued. If any are seen, please forward me the capture file that was created.\r\n7. Check SYSLOG for messages related to the E-MVS CONSOLE created to issue the display command.\r\n8. Check for messages that may show errors while creating and issuing the commands in SYSLOG.\r\n9. If you can please send 20 minutes of SYSLOG before and after the command was issued."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "hchecker -- brings up the IBM health checker staus panel if we are running the HZPROC (Health Checker STC)."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "if we have Set sdsfmigrate on ... then we cannot use ? to list the availble line commands ... we need to use the ?? to list the available commands."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "XMVS command. it would comeup like command issued in ULOG in SDSF. but the ouput is not captured in syslog."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "set implicitset yes --"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "dscat dsname to list and browse or edit the dataset.\r\ndscat userid list all the userid datasets."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "TOPICS bring up a manual. we can use find to get to the topics."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "REVIEW to find all the commands issued"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "APFSTAT to check the status of dataset and remvoe any not found datasets."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "REBUILD to do a linklist update dynamically. we need to use a add/delete before the REBUILD."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "PARTINFO --"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "DELAYS -- to check for any delays for jobs based on cpu or device or contention"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "set freesysdd yes -- free my dataset"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "set scrollv csr all -- to set the scroll to CSR postion instead of page."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "prism -- give many lpar related info and also has the memory and msu and other lpar related info. STORAGE command also gives us the memory usage."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysview",
    "type": "commands",
    "info": "capture -- caplist\r\nREVIEW -- it lists all the previous commands.\r\nUPDATE -- refresh command on any screen / UPAATE OFF -- to stop the refreshing."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysview",
    "type": "command",
    "info": "Dynamic capture:\r\nCAP OPEN / CAPI desc name / CAP CLOSE\r\nplexcpl -- list all the couple datasets and xcfa line command give the logstream definition.\r\nset freesysdd yes -- echo to my terminal for any output."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "cics interface",
    "info": "If you are an existing user of SYSVIEW 16.0 then:\r\n1. Stop any CICS regions being monitored by SYSVIEW, or use the GSVT transaction to stop SYSVIEW for CICS within the region.\r\n2. Start any CICS regions being monitored by SYSVIEW, or use the GSVS transaction to start SYSVIEW for CICS within the region."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "IMS interface",
    "info": "1. Perform an LLA REFRESH if the IMS Monitor Exit module GSVPDCMX is in the LINKLIST concatenation.\r\n2. Refresh the exit by issuing the IMS type-2 command: REFRESH USEREXIT TYPE(IMSMON)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "UFILESYS lists all the file systems mounted on the system and their mount points"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "reporting",
    "info": "https://docops.ca.com/ca-sysview/15-0/en/reporting/using-ca-explore-report-writer/sample-reports/mvs-sample-reports\r\n\r\nYou can check the MVS Sample Reports: \r\nMVS003: Plot in horizontal format CPU utilization on 1-hour intervals.\r\nMVS004: Plot a scatter consisting of job residency on the vertical axis and job CPU on the horizontal axis.\r\nMVS005: Plot in vertical format CPU utilization on 15-minute intervals."
  },
  {
    "Vendor": "Time zone",
    "component/product": "time zone",
    "type": "time zone",
    "info": "https://www.worldtimebuddy.com/"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Topsecret",
    "type": "Ver check",
    "info": "TSS* STC - TSS9000I"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "topsecret",
    "type": "dataset",
    "info": "b.\tIt seems that Top Secret is not configured to collect Datasets information and I have read the manual and it states the following to issue this command:\r\nc.\tTSS ADDTO(AUDIT) resource(resource-name) and where resource-name can be DATASET\r\nd.\tIf LOG(SMF) has been specified in the CA Top Secret control options, ensure that SMF record type 80 is being recorded This needs to be done as well and verified."
  },
  {
    "Vendor": "ibm",
    "component/product": "trace",
    "type": "type",
    "info": "Master Trace -- records console traffic, such as messages, operator commands, and system responses., \r\nSystem Trace -- is part of the operating system that records system events that occur during the initialization and running of z/OS, \r\nGTF Trace -- Another trace you may find useful is the Generalized Trace Facility (GTF), which records similar information to the System Trace, but can be customized to trace only specific events and write the results to either a data set, often named SYS1.TRACE, or to a trace table (tracing of channel programs and associated data for I/O events, tracing of address space, tracing of DU of work).\r\nComponent Trace -- which is commonly used to gather trace data for a specific MVS component\r\nTransaction Trace -- The data gathered shows the flow of work between components used to service that transaction"
  },
  {
    "Vendor": "ibm",
    "component/product": "trace",
    "type": "command",
    "info": "off using the TRACE MT,OFF console command\r\non using the TRACE MT console command\r\nTRACE ST -- system trace on\r\nTRACE ST,OFF -- sytem trace off\r\nTRACE ST,nnK (the size can also be configured as nnnM or nG, although care needs to be taken that there is sufficient storage)\r\nSTART GTF -- start GTF trace\r\nSTOp GTF -- stop gtf trace\r\nTRACE CT -- to start component trace.\r\nTRACE TT -- to start/stop transaction traces."
  },
  {
    "Vendor": "ibm",
    "component/product": "training",
    "type": "website",
    "info": "https://www.ibm.com/training/journey_description?journeyId=230"
  },
  {
    "Vendor": "Tone",
    "component/product": "TRX",
    "type": "License",
    "info": "On the TRX main panel select option 11 to check the no of days left for keys expiration"
  },
  {
    "Vendor": "Tone",
    "component/product": "trx",
    "type": "commands",
    "info": "tso trx add fi(xxxx) da(xxxx) -- add a file to concatenation"
  },
  {
    "Vendor": "Tone",
    "component/product": "TRX",
    "type": "commands",
    "info": "tso trx list fi(xxxx) -- to list a dd concatenation"
  },
  {
    "Vendor": "Tone",
    "component/product": "TRX",
    "type": "commands",
    "info": "tso trx drop fi(xxxx) da(xxxx) -- remove a file to concatenation"
  },
  {
    "Vendor": "Tone",
    "component/product": "trx",
    "type": "commands",
    "info": "TRX LIST -- lists all the allocated datasets for the logon. Similar to TSO ISRDDN.\r\nTRX LIST LONG"
  },
  {
    "Vendor": "Tone",
    "component/product": "trx",
    "type": "commands",
    "info": "to allocate a profile for a new user. TRX ADD USER(yyy) MODEL(zzz)"
  },
  {
    "Vendor": "Tone",
    "component/product": "trx",
    "type": "setup",
    "info": "we can define a application profile for a product and call it in our clist. You can check the option \"CHANGE USER PROFILES\" in the trx panels for a definition of the application. We can have like what dataset are to be concatenated, when that application is referenced."
  },
  {
    "Vendor": "tone",
    "component/product": "trx",
    "type": "setup",
    "info": "When the user types TRX LIST in any ISPF command field, TRX displays all the TSO files which TRX has allocated in the session and all the datasets within those files. TRX LIST displays files allocated by any active application profile \r\nand by the user's profile. If any of the datasets were allocated through an application profile, TRX shows the name of the profile. "
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "commands",
    "info": "SUBMIT (stress, strain) -- submits the job userid.STRESS.CNTL and userid.STRARIN.CNTL"
  },
  {
    "Vendor": "IBM",
    "component/product": "TSO",
    "type": "profile",
    "info": "use TSO PROFILE NOPREFIX command if your userid is being taken as HLQ automatically"
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "commands",
    "info": "TSO DSPRINT -- to print a dataset to JES2 or a printer."
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "tso",
    "info": "search order for commands -- TSO ALTLIB DISPLAY"
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "commands",
    "info": "SUBMIT (jcl(asmfclg) mydata) -- JCL for the job is JCL.CNTL(ASMFCLG) and input data is MYDATA.DATA"
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "prod invocation",
    "info": "Command to invoke panels of product if we have a module that can invoke them … currently sysview. We have the module SYSV that can invoke the panels in SYS*.**.CNM4BLOD. We can issue the command TSO CALL 'sys*.**.CNM4BLOD(SYSV)'"
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "commands",
    "info": "allocate ddname(xxxx) path('/xxx/aaa') \r\n OCOPY INDD(xxxx) OUTDD(aaa) TEXT CONVERT(BPXFX311) TO1047"
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "commands",
    "info": "COMPARE SESSION (or COMPARE *) -- to compare the changes we have done in the current edit session before saving."
  },
  {
    "Vendor": "ibm",
    "component/product": "TSO",
    "type": "TSO ISRDDN",
    "info": "we can use ENQ -- to identify the Enqueues for the listed datasets.\r\nDUP -- to check for duplicate members.\r\nM parmlibname PARMLIB -- searches for the parmlib in parmlib concatenation. (First issue PARMLIB and then M parmlibname"
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "commands",
    "info": "listalc status -- similar to TSO ISRDDN -- but only dislay as line item."
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "dataset allocaiton",
    "info": "https://webfocusinfocenter.informationbuilders.com/wfappent/TL2s/TL_lang/source/files129.htm\r\n? tso ddname : Lists allocated files. Produces a listing on file SYSPRINT even if you issue the OFFLINE command.\r\n? TSO DDNAME ddname : Lists file attributes. Produces a listing on file SYSPRINT even if you issue the OFFLINE command.\r\n-? TSO DDNAME ddname : Places file attribute information into Dialogue Manager variables. Attributes are returned as values for Dialogue Manager variables."
  },
  {
    "Vendor": "ibm",
    "component/product": "tso",
    "type": "isrddn",
    "info": "ISRDDN command lists all the DD's assigned to our logon. it also ha the following uses.\r\n1. TSO ISRDDN -- lists all the allocated datasets to that session.\r\n2. the following command can be issues after issuing TSO ISRDDN\r\n3. M xxxxx --- searches all the allocated datsets from the DD list.\r\n4. PARMLIB --- shows the system parmlib concatenation for the IPL. -- we can use M xxx to find a parmlib.\r\n5. LINKLIST --- lists all the datasets of LINKLIST concatenation. -- we can use M xxx to find a mem.\r\n6. ENQ -- enq on the system. -- ENQ (jobname/userid/STC) to check for contention. RESET to see ENQ with defaults. we can also use CON command it jsut list any ENQUEUS or displays a message NO ENQUUE exsists.\r\n7. LPA -- lists both the datasets in LPA and LINKLIST.\r\n8. DUP -- list the members that are in multiple datasets across LPA, LINKLIST and otehr DD allocations."
  },
  {
    "Vendor": "ibm",
    "component/product": "tss",
    "type": "list",
    "info": "tso tss whohas uid(0) -- lists all user that has the UID(0) access authority -- omvs super user."
  },
  {
    "Vendor": "ibm",
    "component/product": "tss",
    "type": "alloc",
    "info": "alloc dataset(zuser.test.cntl) volume(test01) unit(3390) tracks space(2,1)\r\n recfm(f) lrecl(80) dsorg(ps)"
  },
  {
    "Vendor": "Macro4",
    "component/product": "TUBES",
    "type": "version",
    "info": "to identify the version of the TUBES product in TUBES STC."
  },
  {
    "Vendor": "Macro4",
    "component/product": "Tubes",
    "type": "commands",
    "info": "issue ANOTHER command on the tubes main panel to add another session."
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "command",
    "info": "use the command TRANSFER when you get a message like \"you are already logged on in tube main panel\""
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "setup",
    "info": "ADDSESS applname [sessionnumber] [S] -- command to add a session dynamically to our MENU\r\napplname -- the applid of the application and it should have been defined in the TUBES config parms.\r\nsessionnumber -- we can assign a session number to the newly added session or it take a no. by default. we can also define the range of session number in TUBES config using the parm DSESSRANGE. if DSESSRANGE is not specified then the default number starts from 9999, 9998, 9997 and so on.\r\nS -- to invoke the added session simultaneously.\r\nDynamically added session would be active only for that logon."
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "setup",
    "info": "if we want to change the profile of an user.\r\n1. issue the command QUERY LU xxxxx (xxxx is available in your applicaiton listing page on top left corner).\r\n2. Make a note of the current PROF.\r\n3. Check the member TUCON01 in you CONFIG DD concatenation. and look for a member that has the user definition.\r\n4. we also need to check for a meber that has PROFILE defintions and make a note of which PROFILE the user wants.\r\n5. Update the USERS member with the USER userid MENU menuid PROF profile auth 9\r\n6. issue the command /f tubes,update member usermember"
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "PROFILE",
    "info": "to identify the current profile for your id issue the command\r\n QUERY LU xxxxx (xxxx is available in your applicaiton listing page on top left corner)."
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "command",
    "info": "QQ or LOGOFF -- to logoff all sessions and comeout\r\nDISCONNECT -- to exit without disconnecting active sessions."
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "command",
    "info": "PUSH escape /> -- saves the current screen image in storage for later retrieval.\r\nPULL escape /. -- invokes the PUSH-PULL INDEX display\r\nCUT escape *c -- invokes a CUT operation.\r\nPASTE escape *p -- invokes a paset option."
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "initialization",
    "info": "in classic cnfiguration first member tubes TUCONxx -- is the first parm that tubes looks to start the task.\r\nxx is specified in TUBES STC PARM='CONFIG xx'"
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "commands",
    "info": "commands to check the PROFILE that a user is running with.\r\nvalue t_prof.1\r\nvalue t_prof.2\r\nvalue t_prof.3\r\nvalue t_signonpanel"
  },
  {
    "Vendor": "ibm",
    "component/product": "unix",
    "type": "kernel",
    "info": "The z/OS UNIX kernel manages this processing by performing tasks such as the following:\r\n\r\nManaging I/O\r\nScheduling work\r\nOpening files\r\nManaging shared memory\r\n\r\nThe z/OS UNIX kernel is linked to WLM so that when a z/OS UNIX program runs, and requests that another program is to be executed - through a fork or spawn function, WLM uses an IBM-supplied procedure, BPXAS, to start a new address space so that the program can run."
  },
  {
    "Vendor": "ibm",
    "component/product": "unix",
    "type": "access",
    "info": "z/OS UNIX support enables two open systems interfaces on the z/OS operating system: an application programming interface (API) and an interactive shell interface."
  },
  {
    "Vendor": "ibm",
    "component/product": "unix",
    "type": "theory",
    "info": "The z/OS Language Environment provides application programmers working in a z/OS environment with the guarantee of a common language development and execution environment."
  },
  {
    "Vendor": "ibm",
    "component/product": "unix",
    "type": "comparision",
    "info": "Activity zOS unix\r\nGeneral Programming Rexx and Clist shell scripts and REXX\r\nEditing Data ISPF ed and vi\r\njob manamgement SDSF ps, jobs, kill\r\nRunning a background job submit, from tso submit, crontab\r\nprogramming compile, link c89, c99, c+, c++\r\ndebugging z/OS debugger dbx\r\nData management ISPF, DFSMShsm tar, cpio, pax"
  },
  {
    "Vendor": "LRS",
    "component/product": "VPS",
    "type": "Ver check",
    "info": "STC - LRS1480N, VSV0001N"
  },
  {
    "Vendor": "ibm",
    "component/product": "vtam",
    "type": "commands",
    "info": "OMVS command to check the resolver: HOST google.com"
  },
  {
    "Vendor": "macro4",
    "component/product": "vtamprint",
    "type": "upgrade",
    "info": "Applications that create documents in CICS interface with Columbus Z by linking to the supplied CICS report creation program, M4VACICU. M4VACICU in turn connects to M4AS which routes the documents through to the JES spool via various IBM SAPI calls. M4AS makes use of access registers for this type of cross memory communication.\r\nIn z/OS 2.3, IBM introduced maintenance that affected the way these access registers are handled. Without fix ASO00059 applied, an S0E0 abend occurs.”"
  },
  {
    "Vendor": "macro4",
    "component/product": "vtamprint",
    "type": "setup",
    "info": "The VTAMPRNT has a main task M4AS(M4AS is essential for all spool access requests. It also permits user-defined job names for output created by the Print Distribution System, and the CICS to JES Facility, and minimizes the delay time before such reports are printed from the spool) . When M4AS starts it looks for a member M4VA by default as the first member to start. M4VA has statements for various options and one of them s USERS. We can specify the member name for users. VTAMPRNT also uses the same members for USERS to be able to access VTAMPRNT"
  },
  {
    "Vendor": "macro4",
    "component/product": "vtamprint",
    "type": "setup",
    "info": "the VTAMPRNT task looks for M4VA member as the first member to start the configuration in the dataset pointed by M4SPARM DD."
  },
  {
    "Vendor": "IBM",
    "component/product": "WAS",
    "type": "what is",
    "info": "WebSphere Application Server for z/OS is a comprehensive Java 2 Enterprise Edition (J2EE) and Web services application system.\r\nIt is built on open standards-based technology, such as CORBA, HTML, HTTP, IIOP, and J2EE-compliant Java technology standards for servlets, JSP, and Enterprise JavaBeans (EJB). It also supports all Java APIs needed for J2EE compliance\r\n\r\nA server is the primary run-time component; this is where your application executes.\r\nThe server provides containers and services enabling the execution of specific Java application components. Each server runs in its own Java Virtual Machine (JVM)."
  },
  {
    "Vendor": "IBM",
    "component/product": "WAS",
    "type": "what is",
    "info": "A node is a logical grouping of server processes. They share a common configuration and operational control. A node is usually associated with a physical installation of the WebSphere Application Server.\r\n\r\nA cell is a grouping of nodes into a single administrative domain.\r\nIn the base configuration, a cell contains only one node, which may have multiple servers.\r\nIn the network deployment configuration, a cell can consist of multiple nodes that are administered together."
  },
  {
    "Vendor": "IBM",
    "component/product": "WAS",
    "type": "Models",
    "info": "Web Based Computing\r\nIntegrated Entrerprise Computing\r\nMultithreading distributed Business Computing\r\nService Oriented Computing"
  },
  {
    "Vendor": "ibm",
    "component/product": "website",
    "type": "install",
    "info": "link for PSP maintenance check -- http://www14.software.ibm.com/webapp/set2/psearch/search?domain=psp"
  },
  {
    "Vendor": "ibm",
    "component/product": "website",
    "type": "inst.Ftp",
    "info": "https://www.ibm.com/support/knowledgecenter/en/SSLTBW_2.4.0/com.ibm.zos.v2r4.ieav100/pduuex13.htm"
  },
  {
    "Vendor": "ibm",
    "component/product": "website",
    "type": "hardware",
    "info": "https://www.ibm.com/it-infrastructure/resources/tools/z-mainframe-product-comparison/ -- hardware comparision."
  },
  {
    "Vendor": "ibm",
    "component/product": "website",
    "type": "upgrade",
    "info": "information on upgrading IBM products \r\n https://www.ibm.com/support/pages/upgrading-information-cics-when-changing-releases-cics-zos-db2-or-ims"
  },
  {
    "Vendor": "ibm",
    "component/product": "website",
    "type": "zos",
    "info": "github link for most of zos work. https://github.com/IBM/IBM-Z-zOS"
  },
  {
    "Vendor": "ibm",
    "component/product": "website",
    "type": "compatibility",
    "info": "https://www.ibm.com/software/reports/compatibility/clarity/index.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "website",
    "type": "codeset",
    "info": "https://www.aivosto.com/articles/charsets-codepages.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "concept",
    "info": "setting performance goals for work, and letting the workload manager handle processing to meet the goals.\r\nWLM manages the system resources that are available and can only meet performance objectives if the necessary resources are available.\r\nWith workload management, you define performance goals and assign a business importance to each goal. You define the goals for work in business terms, and the system decides how much resource, such as CPU and storage, should be given to the work to meet its goal."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "concept",
    "info": "This explicit definition of workloads and performance goals is called a service definition.\r\nPerformance management is the process workload management uses to decide how to match resources to work according to performance goals\r\nYou can turn over management of batch initiators to workload management, allowing workload management to dynamically manage the number of batch initiators for one or more job classes to meet the performance goals of the work."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "concept",
    "info": "One service definition for sysplex\r\nhas multiple service policies to specify the goals of work but only one is active at a time.A service policy is a named set of overrides to the performance goals and processing capacity boundaries in the service definition\r\nhas multiple service classes :divided into multiple time periods and group that has common performance goals each.\r\nWorkloads, which aggregate a set of service classes for reporting purposes.\r\n     Within a workload, you group work with similar performance characteristics into service classes. You create a service class for a group of work that has similar:\r\n       Performance goals  : Response time / Execution velocity / Discretionary goals :  and how importnant (Importance comes into picture when the goals are not being met in the system, then wlm looks at  importance and assign resource to the workload that has highest importance. (Lowest,low,meduim,high,highest).\r\n       Resource requirements : Periods are a way of defining different goals for work depending on the amount of resources the work consumes. Duration is the amount of resources (including all processor types), in service units, that the work consumes before it is switched to the goals of the next period.\r\n       Business importance to the installation \r\nResource groups, which define processor capacity boundaries within a system or across a sysplex. You can assign a minimum and maximum amount of CPU service units on general purpose processors, per second, to work by assigning a service class to a resource group.\r\nClassification rules, which determine how to assign incoming work to a service class and report class or tenant report class.\r\nScheduling environments, which are lists of resource names along with their required states. If a z/OS® image satisfies all of the requirements in a scheduling environment, then units of work associated with that scheduling environment can be assigned to that z/OS image."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "concept",
    "info": "WLM can have upto 100 different service classes.\r\nDispatching is a number between 0 and 255\r\nService classes can have from one to eight performance periods.\r\nI/O priority group can optionally be used to prioritize access to I/O\r\nA service class is defined by the z/OS administrator, and can have any name up to 32 characters. Each service class can have up to eight performance periods. Each performance period specifies an importance; this could be blank for discretionary work, and goal; discretionary, velocity, or response time.\r\nThere can be many classification rules specifying one service class. Classification rules can specify the names of patterns of many different workload characteristics, including address space name, transaction name, and userid. Storage critical is specified in classification rules, the I/O priority group is specified in the service class definition.\r\nThe importance level and goal are specified for each performance period. A period with a velocity goal could have any importance level from 1 (very important) to 5 (not important)"
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "concept",
    "info": "Under workload management, various subsystems including SRM cooperate with the z/OS workload manager component (WLM). The workload manager allows you to assign tasks to different service classes. Each service class is a grouping of performance goals and other factors that define requirements for similar types of work. You can assign any of the following three types of performance goals to each service class:\r\n\r\nResponse time goals, which detail the amount of time required to complete the work under that service class, and the percentage of work under that service class that completes within that time\r\nExecution velocity goals, which detail the amount of acceptable delay that work within that service class, should encounter\r\nDiscretionary goals, which are used for work not assigned a specific performance goal"
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "concept",
    "info": "The use of the Performance Index (PI) allows operations and performance personnel to easily manage the system. Any task or service class with a PI greater than 1 is not meeting its goal. \r\nWLM captures the state of all work units several times per second, and after a defined number of seconds it combines this with other data such as CPU service and transaction end times to perform policy readjustment.\r\n\r\nThe service class (SC) describes a group of work within a workload with similar performance characteristics. A service class is associated to only one workload, and it can consist of one or more periods.\r\n\r\nA PI is numeric and expressed as follows:\r\n• PI = 1 means that the SC period is exactly meeting its goal.\r\n• PI > 1 means that the SC period is missing its goal.\r\n• PI < 1 means that the SC period is beating its goal.\r\n\r\n2 types of PI sysplex PI and LOCAL PI."
  },
  {
    "Vendor": "IBM",
    "component/product": "sysplex",
    "type": "ARM",
    "info": "to display the restart groups /D XCF,ARM,DETAIL"
  },
  {
    "Vendor": "ibm",
    "component/product": "zaware",
    "type": "theory",
    "info": "Managing the products that are used in your organization:\r\n– Handling the increases in the variety of messages being issued, and the rate at which they are issued\r\n– Determining which messages are important\r\n– Managing changes to messages\r\n– Identifying new messages and determining whether they are important in your environment\r\n_ Determining whether a system is configured appropriately:\r\n– Checking configuration settings against industry preferred practices values or organization-selected values\r\n_ Determining the operating state of your systems:\r\n– Identifying when the system might be misbehaving\r\n– Capturing abnormalities in system behavior or configuration, preferably before they become visible as a service interruption\r\nIBM zAware can warn you about changes in messages on your system before the reason for the difference escalates into a problem."
  },
  {
    "Vendor": "ibm",
    "component/product": "zcx",
    "type": "zcx",
    "info": "z/OS Container Extensions (zCX) is among these new technologies. zCX brings a new Linux capability inside of z/OS. This capability is distinct from UNIX System Services, in that a complete Linux on Z OS is part of z/OS. It runs in a started task just like any other started task. It contains both a full Linux system and Docker, a portable software packaging and execution environment"
  },
  {
    "Vendor": "ibm",
    "component/product": "zCX",
    "type": "zCX",
    "info": "zCx -- zOS container extensions available from z/OS V2.4 and z14 machine. Comes as a base product.\r\ndocker images on zOS. the interface for the containers is through standard DOCKER CLI.\r\n\r\nit is a package of ( LINUX KERNEL + LINUX DOCKER ENGINE + STANDARD DOCKER CLI ) is provided by IBM for zCX\r\nzcx has linux containers (can run MandoDB, Inginx, Kafka binary images and run as linux container).\r\n\r\nThe package and container run in a STC on zOS. it has a z/OS Linux virtualizaiton layer. All the work load is zIIP elgible.\r\n\r\nThe containers interact with the TCP/ip stack running in zOS to connect with standard zOS application like (CICS, MQ, DB2,IMS).\r\n\r\nlinux storage/disk access (via zos owned and managed vsam datasets). user hyperswap (realtime switch to seconday vsam datasets).\r\n\r\nThis helps to have Systems or Record and Systems of Engagement on the same zOS image."
  },
  {
    "Vendor": "ibm",
    "component/product": "zedc",
    "type": "theory",
    "info": "zEDC Express software feature enabled in an IFAPRDxx parmlib member.\r\nd IQP -- to chekc the status of zEDC."
  },
  {
    "Vendor": "ibm",
    "component/product": "zedc",
    "type": "theory",
    "info": "For HSM as you might already be aware that you have to do the following:\r\nThe change to DF/HSM Parmlib Member: ARCCMDxx or perform a dynamic change:\r\nTo test zEDC when backing up to DASD, issue the following modify DFSMShsm command:\r\nF hsm,SETSYS ZCOMPRESS(DASDBACKUP(YES))\r\n2. To test zEDC when migrating to DASD, issue the following modify DFSMShsm command:\r\nF hsm,SETSYS ZCOMPRESS(DASDMIGRATE(YES))\r\n3. For validation of these functions, backup or migrate a volume without using zEDC compression to have this uncompressed backed up volume or migrated volume available to compare to the results of the same volume that was backed up or migrated with zEDC compression.\r\nOnce testing is completed and you are ready to implement zEDC compression permanently,\r\nthe following SETSYS commands should be added to the ARCCMDxx parmlib member:\r\nSETSYS ZCOMPRESS(DASDBACKUP(YES))\r\nSETSYS ZCOMPRESS(DASDMIGRATE(YES))\r\nOr to utilize zEDC for all functions:\r\nSETSYS ZCOMPRESS(ALL)"
  },
  {
    "Vendor": "ibm",
    "component/product": "zedc",
    "type": "theory",
    "info": "•\tOne of the requirements to enable zEDC zLIB is to create a Security Profile for zEnterprise Hardware Compression Facility and this is done by creating the RACF Profile in FACILITY Class:"
  },
  {
    "Vendor": "ibm",
    "component/product": "zedc",
    "type": "implementation - 1",
    "info": "To Implement the zEDC Feature, you require the following:\r\nUpdate SYS1.PARMLIB(IFAPRDxx) and where xx is the system prefixes and for SYST System, it would be '0T'.\r\nUpdate the following SYS1.PARMLIB(IFAPRD0T) with the following changes:\r\nPRODUCT OWNER('IBM CORP')\r\nNAME('z/OS')\r\nID(5650-ZOS)\r\nVERSION RELEASE MOD\r\nFEATURENAME(zEDC)\r\nSTATE(ENABLED)\r\nCreate the following member in SYS1.PARMLIB or the PARMLIB that is designated for the system.\r\nMember: IQPPRMxx and where for SYST, it would be IQPPRM0T\r\nHere's the contents of the member IQPPRM0T:\r\nZEDC,\r\nMAXSEGMENTS=4,\r\nDEFMINREQSIZE=4,\r\nINFMINREQSIZE=16"
  },
  {
    "Vendor": "ibm",
    "component/product": "zedc",
    "type": "implementation - 2",
    "info": "Here's the Manual which describes the definitions of above:\r\n[IQPPRMxx Definitionshttps://www.ibm.com/docs/en/zos/2.1.0?topic=parameters-statementsparameters-iqpprmxx\r\nOnce the above all changes are completed then request for System IPL.\r\nAfter the system IPL, you can confirm by invoking the following command:\r\n/D IQP and it would display the following:\r\nD IQP\r\nIQP066I 11.57.49 DISPLAY IQP 771\r\nzEDC Information\r\nDEFMINREQSIZE: 1K (STATIC)\r\nINFMINREQSIZE: 1K (STATIC)\r\nFeature Enablement: Enabled"
  },
  {
    "Vendor": "ibm",
    "component/product": "zedc",
    "type": "implementation - 3",
    "info": "The last change is to DF/HSM Parmlib Member: ARCCMDxx or perform a dynamic change:\r\nTo test zEDC when backing up to DASD, issue the following modify DFSMShsm\r\ncommand:\r\nF hsm,SETSYS ZCOMPRESS(DASDBACKUP(YES))\r\n2. To test zEDC when migrating to DASD, issue the following modify DFSMShsm command:\r\nF hsm,SETSYS ZCOMPRESS(DASDMIGRATE(YES))\r\n3. For validation of these functions, backup or migrate a volume without using zEDC compression to have this ncompressed backed up volume or migrated volume available to compare to the results of the same volume that was backed up or migrated with zEDC compression.\r\nOnce testing is completed and you are ready to implement zEDC compression permanently, the following SETSYS commands should be added to the ARCCMDxx parmlib member:\r\nSETSYS ZCOMPRESS(DASDBACKUP(YES))\r\nSETSYS ZCOMPRESS(DASDMIGRATE(YES))\r\nOr to utilize zEDC for all functions:\r\nSETSYS ZCOMPRESS(ALL)\r\nOne other option to be Explored is IGDSMSxx and add the following Statement:\r\nCOMPRESS(ZEDC_P)"
  },
  {
    "Vendor": "ibm",
    "component/product": "zfs",
    "type": "jcl",
    "info": "while creating the zFS dataset in the JCL in the second step using the IOEGAFMT have the aggregate parm in smaller case as below. //CREATE EXEC PGM=IOEAGFMT,REGION=0M,\r\n // PARM=(’-aggregate OMVS.PRV.COMPAT.AGGR001’"
  },
  {
    "Vendor": "IBM",
    "component/product": "zOS",
    "type": "IPL",
    "info": "To find the start of IPL messages in SYSLOG look for IEA371I."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "upgrade",
    "info": "IBM has decided to replace the HTTP Server powered by Domino with the HTTP Server powered by Apache, so before we upgrade SYSR to z/OS 2.3, IBM recommended us to migrate the current HTTP server powered by Domino on SYSR (z/OS 2.1) to one powered by Apache first (this is an older version than the one on z/OS 2.3), and suggested that this would simplify the migration of z/OS to 2.3"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "search order",
    "info": "Search Order when we issue the /START xxxx --- command.\r\nSearch Order for a /START xxxx command.\r\nWhen the system has to process the start of a task, It checks for the member in IEFJOBS DD of MSTJCLxx.\r\nIf a member is found in IEFJOBS DD concat, the system examines the first record for a valid JOB statement and, if one exists, uses the member as the JCL source for the started task. It fails execution saying NO VALID JOBCARD if no valid JOB card in its first record. If there is no member by that name in the IEFJOBS concat., or if the IEFJOBS concat. does not exist, the system searches the IEFPDSI DD for the member. If the member is found in IEFPDSI and no jobcard then system assumes that the source JCL is a procedure and creates JCL with jobcard (default for stc). or runs it with the jobcard found in member.\r\nThe system does not look for a procedure in IEFJOBS DD concat. that is called using the EXEC PROC statement in the jcl. it checks in IEFPDSI concat.\r\nif no member xxxx is found in IEFJOBS and IEFPDSI DD of MSTJCLxx then the system moves to JES2 proclib search order.\r\nJES2 proc has PROC00/01/02 and so on DD stat. defined either in the JES2 JCL or JES2PARM. the system searches for xxxx in the PROCyy concat. as specified in the JOBCLASS definition for STC. you can check it by issuing the command /$D JOBCLASS(STC),PROCLIB.Jes2 does not allow for a jobcard in the procs started by jES2."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "link pack area",
    "info": "we have 3 LPA - PLPA/LPA(LPALSTxx), MLPA(IEALPAxx), FLPA/FIX(IEAFIXxx)\r\nIn IEASYSxx we have FIX (IEAFIXxx), LPA(LPALSTxx), MLPA(IEALPAxx)\r\n\r\nLPA, which is searched in this order:\r\na. Dynamic LPA modules, as specified in PROGxx members\r\nb. Fixed LPA (FLPA) modules, as specified in IEAFIXxx members \r\nc. Modified LPA (MLPA) modules, as specified in IEALPAxx members\r\nd. Pageable LPA (PLPA) modules, loaded from libraries specified in LPALSTxx or PROGxxs"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "search order",
    "info": "lpa search order\r\n LPA, which is searched in this order: \r\n Dynamic LPA modules, as specified in PROGxx members\r\n Fixed LPA (FLPA) modules, as specified in IEAFIXxx members\r\n Modified LPA (MLPA) modules, as specified in IEALPAxx members\r\n Pageable LPA (PLPA) modules, loaded from libraries specified in LPALSTxx or PROGxx"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "utility",
    "info": "amblist\r\n//STEP1 EXEC PGM=AMBLIST \r\n//SYSLIB DD DISP=SHR,DSN=SYS1.LINKLIB \r\n//LOADLIB DD DISP=SHR,DSN=XXXXX.TUBES.LOCAL.BE.LOADLIB \r\n//SYSPRINT DD SYSOUT=P \r\n//SYSIN DD * \r\nLISTLOAD OUTPUT=MODLIST,DDN=LOADLIB,MEMBER=M4TUBE21 \r\nTITLE=('OLOAD MODULE LISTING FOR MYJOB',20) \r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "vsam",
    "info": "use the command print ch ids(/) all next to a vsam file to print its contents in ISPF."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "parmlib",
    "info": "TSO PARMLIB -- lists all the entries in IKJTSOxx parmlib. it has the list of authcmd and authpgm\r\nSET IKJTSO=xx to dynamically update"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "parmlib",
    "info": "D PPT,all -- lists all the entries and options in the SCHEDxx member"
  },
  {
    "Vendor": "IBM",
    "component/product": "zOS",
    "type": "Ver check",
    "info": "WHO command in SDSF."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "time zone varibale",
    "info": "OMVS - TZ, MVS - CLOCKxx, CEEPRMxx (LE env. variables)."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "installaton",
    "info": "types :\r\nServerpac -- : installed through custom pac installation daialogue :all licensed product or one product can be done too.\r\nCBPDO -- only smp/e installable prducts. no dialog help. need to do through smp/e jcls.\r\nsystempac -- pre installed zos/susbsystems/product based on our answers to questions and are sent a dumped volumes."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "zAAP",
    "info": "zAAP are generarlly used for JAVA executions but with z14 these are disabled and the work load is now handled by zIIP itself."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logstream",
    "info": "disply all the logstream /d logger,logstream\r\n\r\nif we want to know the HLQ for the logstream then run the job \r\n//STEP1 EXEC PGM=IXCMIAPU\r\n//SYSPRINT DD SYSOUT=*\r\n//SYSING DD *\r\nDATA TYPE(LOGR)\r\nREPORT(YES)\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "gdg",
    "info": "Traditionally, when defining a new generation data group, the LIMIT parameter allowed you to specify up to 255 generation data sets to be associated with the GDG. With z/OS 2.2, a new EXTENDED parameter allows you to extend this number to a maximum of 999"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "mainframe",
    "info": "“mainframe” refers to the main cabinet where frames of these cores served as the memory for the central processing unit (CPU) that was housed with them. And “core memory” likewise hearkens back to this—as do “core dumps” when you get to see the contents of memory displayed over reams of paper or the virtual equivalent."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "https://community.ibm.com/community/user/ibmz-and-linuxone/blogs/destination-z1/2019/12/23/a-brief-history-of-mainframe-memory-technology"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "commands",
    "info": "ue the /CMDS commands to display the commands that are waiting.When a command flooding happens we can check the wating command list using this command."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "cpu capcity",
    "info": "/* REXX */ rct = c2d(storage(d2x(c2d(storage(d2x(c2d(storage(10, 4))+604), , 4))+228), 4)) say 'CEC MSU capacity='c2d(storage(d2x(rct+32), 4))';' , 'defined LPAR MSU capacity='c2d(storage(d2x(rct+28), 4))"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "D M=STOR -- displays the real storage available for the lpar."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "utility",
    "info": "to list the directory information of members in a pds\r\n//STEP1 EXEC PGM=IEHLIST //SYSPRINT DD SYSOUT=* //DD1 DD VOL=SER=TCH305,DISP=SHR,UNIT=SYSALLDA //SYSIN DD * LISTPDS DSNAME=SYS2.VANTAGE.CONF.SYSTSCR,VOL=SYSALLDA=TCH305 /*"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "utility",
    "info": "to take a backup of a pds with similar attributes.\r\n//STEP1 EXEC PGM=IEBCOPY //SYSUT1 DD DISP=SHR,DSN=SYS1.PARMLIB //SYSUT2 DD DISP=(NEW,CATLG,DELETE),DSN=SYS1.PARMLIB.D090720, // LIKE=SYS1.PARMLIB,VOL=SER=TCH980 //SYSPRINT DD SYSOUT=*"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "search order",
    "info": "Module Search Order:\r\n1. Program Management first searches for the module in the Job Pack Area (JPA). The JPA is in the private address space of the user that requested the load module.\r\n2. If the module is not in the JPA, Program Management then initiates a directory search against the JOB/STEP/TASK libraries to find the location of the module.\r\n3. If Program Management does not find the module in the JOB/STEP/TASK libraries, it searches the Link Pack Area\r\n(LPA). The LPA resides in both the common service area CSA) and the extended CSA (ECSA).\r\n4. Finally, if the module is not in the LPA, Program Management issues a directory search against the LNKLST libraries to find the location of the module."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "iefusi exit",
    "info": "As you must have heard our IEFUSI Exit discussions in our Daily Meetings, I would like to move forward in Implementing the Changes by Disabling/Removing the IEFUSI Exit from the Linklist Libraries.\r\nIEFUSI Exit Description:  IEFUSI is an exit to limit region sizes (128MB) , every now and then there is a need to increase these limits when newer applications need larger virtual storage to run. I guess the potential impact of disabling IEFUSI is a small chance of having a runaway task which may allocate too much virtual storage and cause page data sets usage or paging rates to increase beyond acceptable values.\r\n The IEFUSI Exit was designed more than 20Years ago and when our Processors were designed to have limited Central Storage and thus we could not afford to have huge address spaces. With the Technology and our Processors Configuration, currently majority of our Processors are configured with more than 10GB versus 1GB 20Yrs ago and thus now we have to allow our Environment to operate with more than 1GB.\r\nNote: The (IBM Sample Exit) IEFUSI Limits the address space at 128MB only and which seems very little and here’s the Impacts of disabling the exit:\r\nIMPACTS:\r\n-If an Runaway task occurs then there is a possibility of an Exhausted Paging Storage and can initiate Paging Shortage messages in the SYSLOG.\r\n-From my understanding and from my observation, there are enough Paging Datasets exists in each system -I will check the Paging Datasets before Implementing the following changes\r\nThis change will be implemented in STEPS through Test Systems and then subsequently on the Production Systems.\r\nPROCESS:\r\n- Disable Exit IEFUSI through SMFPRMxx Member of PARMLIB"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "start task",
    "info": "to start a job/procedure in a name desired by us.\r\n/s xxxx,jobname=yyyy --- xxxx -- qualified job or procedure name that you want to run. YYYY is the new name under which the xxxx proc or job would run instead of taking the name from the JOB statement or proc statement."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "utility",
    "info": "As a z/OS Systems Programmer of many years, one of my favourite utilities is AMBLIST. If I'm debugging an S0C4 Protection Exception or S0C7 Data Exception and the PSW address points someway down the Load Module, then running AMBLIST, I can list the Load module and its CSECT structure and find which subroutine is indicated by the PSW as having failed. If I want to check if a program is defined as Authorized and/or Reentrant, then AMBLIST will dissect the module and give me these details. If I want to know what PTF last hit a System Module, then AMBLIST will give this to me (Yes I know SMPE can also list this information), but sometimes IBM Level 2 will want to see the dump of the module and so I can just FTP this straight over. or email it as an attachment. On a wider scale it can map all modules in the Link Pack Area (LPA).\r\n//AMBLIST EXEC PGM=AMBLIST,REGION=16M\r\n//SYSPRINT DD SYSOUT=*\r\n//SYSLIB DD DSN=Loadlib,DISP=SHR\r\n//SYSIN DD *\r\nLISTLOAD MEMBER=loadmodulename,\r\n[OUTPUT={MODLIST|XREF|BOTH|MAP}]\r\nLISTLOAD, LISTIDR, LISTLPA, LISTOBJ\r\n//"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "slip",
    "info": "SLIP MOD,DISABLE,ID=X33E -- to disable a slip trap"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "linlist",
    "info": "You should not make any changes to libraries that are part on an active/in-use lnklst concatentaion. UNALLOCATE does not stop the active concatenation from being accessed/used.The 'SETPROG LNKLST,UNALLOCATE' command merely releases the XCFAS enqueue placed on the datasets in the concatenation. The concatenation remains in effect and continues to be used by the system. Originally, there was never an enqueue placed on the linklist concatenation. This led to the possibility of the actively used datasets being altered/removed from the system by other systems sharing the devices. To help prevent this, the XCFAS enqueue was added. One problem with this enqueue is that it prevents other systems in the sysplex from altering like named datasets on their system that are not part of their linklist concatenation. So to allow for this activity, the UNALLOCATE parameter was provided to release the enqueue, not the datasets, allowing you the ability to alter like named datasets that are not part of the linklist concatenation in the sysplex."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "pdse",
    "info": "The abend213-30 means:\r\nAn attempt was made to open a partitioned data set (PDS) for OUTPUT,DISP=SHR. The PDS is already open in this condition, and a DCB is already open for output to the data set. The data set might be on the same system or on another system that is sharing the volume. Access was not serialized before the attempt to open the data set.\r\nFor this type of activity we recommend clients use PDSE, as this is not possible with PDS.\r\nWith this Extended sharing, it provides the ability for users on different MVS systems in a sysplex to create, read, or update members of a PDSE concurrently.\r\nAny number of users or systems can concurrently share a PDSE or members in it for input (read) or output (write).\r\nMultiple members can be updated by different users on the same system, but only one user can update a member in place at a given time. In addition, only one system can access the PDSE when update in place is being done."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "history",
    "info": "1964 -- System/360 -- OS/360\r\n1970 -- system/370 -- MVS, MVS/XA, MVS/ESA\r\n1990 -- System/390 -- MVS/ESA,OS/390\r\n2000 -- zSeries -- z/OS"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "processor",
    "info": "Type of processor: CP, SAP (ystem assist processor for I/O), IFL, zAAP(java), zIIP(db2), ICF, spares, capacity on demand.\r\nCUoD – Capacity Upgrade on Demand (permanent)\r\nOn/off CoD – temporary capacity CBU – capacity backup upgrade – generally used for DR – reserved emergency backup capacity for all processor configurations."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "spool",
    "info": "Simultaneous Peripheral Operations OnLine (SPOOL) -- helped to relieve the multiprogramming constraints that were caused by the need for card readers and printers.\r\n When the program tries to write to a printer, the supervisor recognizes that the request is for a spooled device. It passes the request to JES, which diverts the output record to a spool data set. \r\nStatus information is passed first to JES in case adjustment is required before being delivered to the program. A similar technique is used when a program tries to read or write cards.\r\n After program listings have been written to spool, JES can direct them to printers automatically."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "address space",
    "info": "A map of storage made availale for both applicaitons and users. the range of address is upto 2^64\r\nThe memory frames (4K pages) are called real storage and the disk slots(4K pages) are called auxiliary storage. The quantity of virtual storage and the mechanisms needed to support it are called an address space."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "utility",
    "info": "Stand alone utility : ICKDF, ADRDSSU, SADMP\r\nCommonly used dataset utilities : iebcopy, iebgenr, dfsort, idcams"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "console",
    "info": "console commands:\r\nD C,K -- list all teh options for console messge flow. (K is shot form for CONTROL command).\r\nK S -- list the current configuration for console message flow.\r\nK S,DEL=RD,SEG=20,CON=N,RNUM=20,RTME=001,MFORM=(J) -- (CON -- delete message with/without confirmation).\r\nRNUM,RTME -- specify the no. of lines to scroll and the time for each scroll).\r\nDEL=RD -- rolling mode, DEL=N -- no rolling to happen.\r\nD C,U=0040\r\nD C,U=/0040 -- to list detials of console on unit address 0040\r\nin the display of D C, D C,cn=xx -- AUTH=(ALL) indicates that any INFO, SYS, IO, or CONS\r\n-- ROUT=(ALL) indicates that routing codes 1 to 128 are assigned to this console"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "console",
    "info": "In any single MVS system, the maximum number of consoles that can be defined is 250, and of these you can have up to 99 concurrently active. In a sysplex, this 99 console limit is multiplied by the number of systems."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "console",
    "info": "MCS -- Multiple console support\r\nSMCS -- SNA/VTAM Multiple console support\r\nHMCS -- Hardware Management console multiple console support\r\nEMCS -- Extended Multiple console support."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command",
    "info": "d j,l,user=xxxx -- to display the tasks owned by user xxxx."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command",
    "info": "d u,dasd,onlin.\r\nA (allocated)\r\nBSY (busy)\r\nBOX (hardware error)\r\nF (offline)\r\nNRD (not ready)\r\nO (online)\r\nSPD (channel program is temporarily suspended while the system is using it)"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command",
    "info": "d M=DEV(03AD) -- devive id.\r\nd m=chp(65) -- channel path.\r\nD M=DEV((device,(chp)),ROUTE=BOTH,HEALTH -- to check the error in the channe path devices.\r\nD M=CONFIG(xx) -- compares the contents of current status of the system, including processors, storage, channels, and devices with the contents of a CONFIGxx logical parmlib membe"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "mpf - Message processing facility",
    "info": "MVS messages have routing codes and message levels that determine how messages are routed throughout the environment. For MCS, SMCS, and extended MCS consoles, you can specify which routing codes a console can accept, allowing messages to be sent to the relevant person. After a message passes through the MPF, subsystems like JES2 or NetView can receive the message for processing. After subsystem processing occurs, the message passes to the SYSLOG/hardcopy log\r\nIf a .DEFAULT entry has been coded in the MPFLSTxx member, then all message IDs that appear below it will take those defaults instead of the system defaults.\r\nT MPF=xx -- to change the MPF settings.\r\nT MPF=NO -- no MPF filtering to happen.\r\nz/OS Message Flood Automation can be used to react to message flooding before buffers fill and console queues begin to build."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "mpf - Message processing facility",
    "info": "AUTO - Is the message eligible for automation processing?\r\nSUP - Is the message to be suppressed?\r\nRETAIN - Is the message to be retained by the Action Message Retention Facility (AMRF) and be viewable with the D R,L command?\r\nAUTO(NO),SUP(YES),RETAIN(YES) are the IBM supplied default parameters that can be overridden with a .DEFAULT entry.\r\nThe .NO_ENTRY entry provides the parameters to be used in handling any message that does not have a matching entry coded elsewhere in the MPF list."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "mpf - Message processing facility",
    "info": "Message Flood Automation handles three types of messages with each type containing its own set of attributes in relation to the allowable amount of messages encountered during a specific time.\r\nThese message types are:\r\nSPECIFIC messages, which are messages identified by your organization\r\nACTION messages, which are those relating to system failures and messages requiring an immediate or eventual action\r\nREGULAR messages, which are those that do not meet the categories above\r\nMSGFLDxx PARMLIB -- is for Flood automation filteration. is specified in the CONSOLxx member.\r\nD MF,STATUS -- to display the message flooding status.\r\nMessage flood automation can identify where messages have been issued from.\r\nThe message type will be placed in intensive mode."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "supervisor",
    "info": "supervisor : Part of an operating system that is responsible for loading, dispatching, and supporting (with I/O, storage management, etc.) problem programs.\r\nSVC : The mnemonic for the supervisor call machine instruction.\r\nThe supervisor turns the problem state bit on when it gives control to a problem program. A problem program cannot turn it off in PSW.(BIT 15 (P))"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "zarch",
    "info": "Interrupton allows the sytem to stop executing the currnet program and pass control and bring in other pgm to be executed. There are six different kinds of interruptions: Different routines handles each of these interruptions. SVC : Pgms issues SVC calls for I/O to happen on its behalf.\r\nI/O : Occurs when the SVC call's I/O is completed and the Channel Subssytem causes the interruption.\r\nExternal : External interruptions can be caused by the interrupt key on the console, by another processor, or by a timer. Timers are used by operating systems to ensure that problem programs do not run too long and the CPU can be shared. Program : Program interruptions are usually caused by page faults or program errors. when trying to access a page that is not in real storage a page fault occurs and the supervisor must arrange for the required page to be brought in from auxiliary storage. also when a pgm trie to treate char as string during some calc.\r\nRestart : The restart interruption is caused by a PSW restart being invoked from the HMC, or by a restart signal from another processor.\r\nMachine-Check :The sixth and final interruption type is the machine-check interruption. A machine-check interruption is triggered when the processor recognizes that a hardware error has occurred within its own circuitry."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "DAT uses the tables built by the supervisor to translate virtual addresses into real addresses."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "address space",
    "info": "----------------------------------------------------------------------- 16 EB\r\nHigh User Region ----------------------------------------------------------------------- 512 TB\r\nDefault Shared Memory Addressing\r\n----------------------------------------------------------------------- 2 TB\r\nLow User REgion\r\n----------------------------------------------------------------------- 4 GB\r\nRESERVER\r\n----------------------------------------------------------------------- 2 GB BAR\r\nP - Extended LSQA/SWA/Subpools 229/230/249\r\nP - Extended User region -- 31 bit user pgm are loaded here\r\nC - Extended CSA\r\nC - Extended PLPA/FLPA/MLPA\r\nC - Extended Sqa\r\nC - Extended Nucleus -- operating system control programs. read only common storage.\r\n----------------------------------------------------------------------- 16 MB LIne\r\nC - Nuclues -- operating system control programs.\r\nC - SQA -- system tables critical for the entire system. -- if full can use space from CSA.\r\nC - PLPA/FLPA/MLPA -- zOS operating system modules.\r\nC - CSA -- Common Service area -- used for inter address space communication.\r\nP - LSQA/SWA/subpools 229/230/249 -- Local system queue area / Schedule work area.\r\nP - User region -- 24bit addressing user pgm are loaded here\r\nP - system region -- used for system functions to perform work for the address space. 16K in size.\r\nC - PSA -- contains critical info. about both the zos and the processor. (PSW, 6 interruptions, storage areas and control blocks."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "address space",
    "info": "The Local System Queue Area (LSQA) contains tables and queues that are associated with the particular address space, such as information on the location of its pages.\r\n\r\nThe Scheduler Work Area (SWA) contains data which exists from job start to job end. It contains the control blocks and tables derived from the JCL statements that make up a job.\r\n\r\nSubpools 229, 230, and 249 are groups of logically related storage blocks with their own storage characteristics. These different storage types are referenced by various authorized programs."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "hardware issues",
    "info": "Machine check handler(MCH) -- when an Machine check interruption occurs MCH will collect all the details and write to the LOGREC.\r\nAlternate CPU Recovery (ACR) component gives multiprocessing systems the ability to recover from failures on a processor by recovering the error on another operational processor.\r\nSubchannel Logout Handler (SLH) does not perform any recovery function. It simply logs channel detected error conditions as records in the logrec data set. It then allows device dependent error recovery procedures to retry the failed I/O. Channel Control / Interface control / channel Data / Address limit / Measurement Check\r\nDynamic Device Reconfiguration (DDR) helps circumvent I/O errors on devices by supplying an alternate I/O device (demountable only) to process the data in case a hardware device fails.\r\nThe Missing Interrupt Handler (MIH) continuously checks to see if expected I/O interruptions have occurred within a specified time.If this time limit is exceeded the system considers that the interrupt is missing and will issue a message to the operator and place a record on the logrec data set.\r\nThe Recovery Termination Manager (RTM) handles all abnormal termination of tasks and address spaces. It then passes control to specific recovery routines which are associated with the terminating functions. Also produces diagnostic data in dumps and in the logrec dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "hardware issues",
    "info": "Dynamic Device Reconfiguration supplies an alternate I/O device in case of hardware failure.\r\nMissing Interruption Handler continuously checks whether expected I/O interruptions have occurred within a specified time.\r\nRecovery Termination Manager handles all abnormal termination of tasks and address spaces.\r\nMachine-Check Handler is given control if a machine malfunction impacts on the system.\r\nAlternate CPU Recovery gives multiprocessing systems the ability to recover from failures on a processor by recovering the error on another operational processor.\r\nThe Subchannel Logout Handler logs channel detected errors as records in the SYS1.LOGREC data set."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "parmlib",
    "info": "IECIOSxx -- parmlib has details around hardware interruption time lines."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "wait state",
    "info": "Waits and hangs are terms used to describe the situation when the operating system or something running within it stops processing. The system can enter one of the following states:\r\nDisabled Wait\r\nEnabled Wait\r\nA hang of a subsystem, address space or job.\r\n\r\nA PSW beginning with 0002 (000A in ESA/390 mode) indicates a disabled wait. A PSW containing 0706 (070E in ESA/390 mode) at the beginning with zeroes in the remaining digits indicates an enabled wait."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "Wait state",
    "info": "An enabled wait is caused by the system waiting for:\r\nWork; it really does have nothing to do, although this is unlikely.\r\nThe system is waiting for an operator reply or action.\r\nA system resource; which could be an I/O device, a page in storage, a queue, or a software lock on the resource.\r\nA system resource; this could be an I/O device, a page in storage, or a software lock on the resource.\r\n\r\nCheck for :\r\nMount pending requests/ \r\nout standing messages -- issue D R,L\r\nContention for a system resources --- issue D GRS,C\r\nall active jobs in swapped out status --- check in DA panel\r\nUse the D U commands to check for devices in BSY, MTP or NRD status."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "HZR",
    "info": "Runtime diagnostics task: This is a base component of zOS.\r\nIt can be started using the command /Start HZR,SUB=MSTR\r\nRuntime Diagnostics browses the OPERLOG (this is a logstream) for any critical messages and if found, lists them as an identified event.\r\n\r\nThe F HZR,ANALYZE command is used to start Runtime Diagnostic interrogation.\r\n\r\nF HZR,ANALYZE to do the diagnostics and provide a report on the system where the command is issued.\r\nF HZR,ANALYZE,SYSNAME=system name - searches for critical messages in the OPERLOG and looking for enqueues for the system. The system has to be in the same plex where the command is entered.\r\nF HZR,ANALYZE,DEBUG=HIGHCPU -- to get more information about the HIGHCPU usage jobs.\r\nRuntime Diagnostic processing will usually run for under minute, gathering and analyzing information.\r\nThe Runtime Diagnostics start command can be modified to instruct this process to run on another system.\r\n/p hzr -- to stop run time diagnostics"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command Force",
    "info": "FORCE Jobname -- Jobs, stc and appc programs.\r\nFORCE jobname,TCB=address,RETRY=YES(with caution) -- Jobs, stc and APPC programs.\r\nFORCE U=tsouserid -- TSO users.\r\nFORCE identifier -- Mount commands, external writers, output processing for a job and zOS unix process."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command\r\nDISPALY JOB",
    "info": "The D A,xxxxx, D J,xxxxx, and D JOBS,xxxxx commands will all display output showing the value of CT (CPU time). If this command is entered often then you can determine whether job activity is occurring."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command VARY",
    "info": "VARY COMMMAND:\r\nV 282,UNAVAILABLE -- to ensure that allocation of the device 282 is not done. this is done after we vary 282 offline to avoid any waiting issues.\r\nV PATH(ddd,pp),OFFLINE -- to vary a ddd -- device and pp -- channel path (CHPID) offline. use the command DS P,ddd to get the CHPID for the device.\r\nV CU(xxxx,pp) -- vary a control unit and the path offline. use the command D M=CU(XXXX) -- to check the CHPID attached to the control unit."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command AUTOR",
    "info": "Auto Reply for WTORS: -- IBM provides a facility reply to know WTORS automatically if not replied in sepcified time.\r\nD AUTOR,POLICY -- display the active auto replies defined in member AUTORxx as specified in IEASYSxx\r\nD AUTOR,WTORS -- currently being tracked WTORS by auto reply funciton.\r\nSETAUTOR OFF -- stops auto replying to the WTORS.\r\nSETAUTOR IGNORE,RID=reply id\r\nSET AUTOR=(xx,x)."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command Classification",
    "info": "COMMAND CLASSIFICATION:\r\nClass M1, M2, and M3 commands -- A maximum of 50 commands within each class are allowed to execute concurrently that run in MASTER SCHEDULER Address space or CONSOLE address space.\r\nClass C1, C2, and C3 commands\r\nInline commands\r\nCMDS -- As well as displaying executing and waiting commands, the CMDS command can be used to delete commands that are waiting for execution, or to cancel commands that are executing."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command CMDS",
    "info": "CMDS DISPLAY\r\nCMDS DISPLAY,CLASS=xx --- display the current running command list/no of commands in class XX\r\nCMDS SHOW --- shows which job/task are the waiting commands issues.\r\nCMDS SHOW,CLASS=xx CMDS REMOVE,CMD=command name,job=jobname,class=class,id=number -- cna be seen from the SHOW command.\r\nCMDS ABEND,CMD=DUMP,ID=712. -- extreme caution with the use of this command because the system could be left \"in an inconsistent state\".\r\nCMDS FORCE,CMD=xxx,ID=xx -- only if abend fails.\r\nCMDS DUMP"
  },
  {
    "Vendor": "IBM",
    "component/product": "ZOS",
    "type": "COMMAND\r\nDASD/TAPE",
    "info": "G XXXX,YYYY -- SWAP TAPE DRIVE XXXX TO YYYY"
  },
  {
    "Vendor": "IBM",
    "component/product": "ZOS",
    "type": "COMMAND console",
    "info": "D PFK -- TO SHOW THE PF KEYS ASSIGNED TO IN THE CONSOLE.\r\nK -- to clear the screen\r\nV CN(xxxx),online/offline -- to vary a console xxxx online or offline."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command\r\nUSER",
    "info": "to dispaly the address space id of user -- D TS,ALL\r\nto cancel a user who is struck during logon -- C u=*logon*,a=xx (xx -- address space id from D ts,all)"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command\r\nCHIP/CONTROL UNIT/CPU",
    "info": "CF CHP(xx),ONLINE -- to configure a channel path to be online\r\nCF CPU(xx),online -- to confugure a cpu xx to be online.\r\nCF CHP(XX),ON,NOVARY -- will bring the channel path 00 online but not the paths attached to the channel."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command\r\nshutdown",
    "info": "F xxxx,CEMT P SHUT -- to shutdown a CICS region.\r\nz NET -- to shutdown VTAM\r\n$P jES2 -- to shutdown JES2\r\n$P JES2,TERM -- terminate JES2 but not terminate active programs and devices."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command IPL",
    "info": "to create the link pack area -- R 00,CLPA -- clears the memory and rebuilds it.\r\nS JES2\r\n*01 $HASP426 speify options - jES2 z/os 2.3 ssname=jes2\r\nR 01,warm,noreq -- this is how we can respond to $HASP426"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "hiper disptach",
    "info": "HIPERDISPACH YES/NO is mentioned in IEAOPTxx"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "IPL-3\r\naddress space",
    "info": "So we know that the CSA/ECSA both spill down (24bit) and up (31bit) to the next megabyte boundary. So why does it\r\ndo this? The answer is because of the Segment Table. When an Address Space is created it is copied from the\r\nMASTER in order to ensure that this new Address Space has the common areas (SQA/ESQA, PLPA/EPLPA, CSA/ECSA)\r\nin the same location. In addition a Segment Table is also created which is divided up into 1meg chunks.\r\nThis Segment Table is 2gig is size. Whenever a Virtual Address is reference from the Program Status Word (PSW),\r\nthe Real Address is located by using the Segment Table as an index to locate the entry in the Page Frame Table\r\nand this locates the Real Address. This is handled by the Real Storage Manager. This Page/Frame of Real Storage\r\ncan be either in Storage or potentially paged out to the Local Page Dataset. This conversion process is called\r\nDynamic Address Translation or DAT processing. DAT processing occurs on this Virtual Address providing Bit 5 in\r\nthe PSW is turned on to allow for it. The current Segment Table is located due to Control Register 1 pointing to it. In part 4 of this discussion I will take you thru an example of the DAT Process"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "serverpac install",
    "info": "READY ISPSTART CMD(CPPECHKV) CMG999 Message ISPV010 - ISPV010 message not found in 'ISPMLIB' library. when we get this error we need to check for message ISPV010 in local ISPF libraries and try to concatenate that library to the ISPMLIB DD concatenation in the job."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "serverpac install",
    "info": "S04C Abend\r\nISPI021 Unrecoverable error in initialization of\r\ncommand tables ISPI022 ISPF cannot continue. ISPF abending. ISPSTART ENDED DUE TO ERROR+ USER ABEND CODE 0999 REASON CODE 00000000\r\nEnsure to have a unused ISPPROF where ever it is referred to and also ensure if you have the ISPF table library concatenated across the job steps. Check for the prefix to be your usreid\r\nAlso ensure to have the right SYS1.SISP* libraries for all the ISP* DD."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "serverpac install",
    "info": "CPP0608001E Order OS242118 Already Exists on the Order Inventory and Cannot be R\r\nCPP9999999I Program CPP608M ENDED Highest Return Code = 8. go and delete the order entry in serverpac installation dialogue."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "cobol",
    "info": "Cobol Options\r\nV4.2: https://www.ibm.com/support/knowledgecenter/SS6SG3_4.2.0/com.ibm.entcobol.doc_4.2/CG/igycch264.htm\r\nV6.2: https://www.ibm.com/support/knowledgecenter/SS6SG3_6.2.0/custom/igycch264.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logger",
    "info": "/d logger,conn -- displays all the connected logstreams on the system and their type DASD or STRUCTURE."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logger",
    "info": "/d logger,str -- display all the structure defined under logger"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logger",
    "info": "/d xcf,cf -- to identify the name of LOGGER or LOGR couple dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logger",
    "info": "sample job to create a LOGGER structure type.\r\n//DEFSTR EXEC PGM=IXCMIAPU \r\n//SYSPRINT DD SYSOUT=A \r\n//SYSIN DD * \r\nDATA TYPE(LOGR) \r\nDEFINE LOGSTREAM NAME(ATR.PLEX1.MAIN.UR) \r\nLOWOFFLOAD(60) \r\nHIGHOFFLOAD(80) \r\nDASDONLY(YES) \r\nHLQ(LOGR) \r\nLS_SIZE(1024) \r\nLS_DATACLAS(DCVSM04K) \r\nLS_MGMTCLAS(MCSTD1) \r\nSTG_SIZE(1024)\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logger",
    "info": "System logger process records that are captured in 2 different ways.\r\n1. Sysplex structure a. Primary memory or interim storage is a List structure and when it is full it is backed up to a dataset, if there is no backup created then we would not see any DASD datasets and the data resides in the LIST structure.\r\nb. When it needs to backup it creates an LDS with the naming convention as provided in the structure definition and adds an LLQ to it. c. Based on the definition it would maintain certain no of backup datasets\r\nd. For someone outside all of this would be not known when you try to access data we would get data even from backups just by referring to the base name.\r\ne. The structure can be shared among many systems in sysplex\r\n2. Dasd only\r\na. Primary memory or interim storage is in a LDS dataset and when it is full it is backed up to a dataset, if there is no backup created then we would only see the base DASD dataset.\r\nb. When it needs to backup it creates another LDS with the naming convention as provided in the base definition and adds an LLQ to it. c. Based on the definition it would maintain certain no of backup datasets\r\nd. For someone outside all of this would be not known when you try to access data we would get data even from backups just by referring to the base name.\r\ne. The DASD only type logstream cannot be shared among many systems in sysplex each system needs to have its own DASD logstream."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logger",
    "info": "issue:\r\nOur issue:\r\nIXG251I IKJ56228I DATA SET LOGR.ATR.PLEX1.DELAYED.UR.A0000002 NOT IN CATALOG OR CATALOG CAN NOT BE ACCESSED *039 ATR202D GAP FOUND IN ATR.PLEX1.DELAYED.UR. REPLY RETRY OR ACCEPT TO\r\nACCEPT THE DATA LOSS LOGR.ATR.PLEX1.DELAYED.UR.A0000002 is a backup dataset that might have got created in the past. I think by default they have taken the management class of MCVSTOR and got deletd on 31st December 2020 (just a guess as none of us worked against this dataset that we know of).\r\nThe problem was that we first tried to reply ACCEPT but then we got the message again that’s when we got confused and tried recreating them thinking that RRS is looking for a base dataset which was not the case. It was only saying that a backup dataset is not found and we you may lose data. We have AUTODELETE(NO) specified so LOGR is not going to delete the backup datasets. If we need to delete the backups we need to run a specific utility. So, as the dataset got deleted by itself RRS was throwing these messages. May be, we need to reply ACCEPT across the plex systems. I will check with IBM and read a little more.\r\nNOTE : On Sunday we did run jobs and recreated the CF structures that is not needed as the CF structure were in good condition. Our understanding was wrong and we recreated it."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logger",
    "info": "important parms while defining a logstream.\r\n1. Name -- Name of the logstream\r\n2. Highoffload -- % of usage of the primary storage(staging) when the data is moved to secondary storage(offload)\r\n3. RETPD -- Specifies the retention period, in days, for log data in the log stream. The retention period begins when data is written to the log stream\r\n4. AUTODELETE(YES/NO) -- if YES.. then data is deleted automatically when RETPD is satisfied. Else we need to run a job to delete the data.\r\n4. DASDONLY(YES)  -- specifies that the logstream is a dasd type and not structure are defined."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "jcl",
    "info": "jcl to submit a job from another job.\r\n//job stat.\r\n//step1 exec pgm=iebedit\r\n//sysut1 dd dsn=abc.xyz(jclmember),disp=shr\r\n//sysut2 dd sysout=(*,INTRDR)\r\n//sysin dd *\r\nEDIT START=ADMIN10P,TYPE=INCLUDE,STEPNAME=(JSTEP2,JSTEP5,JSTEP6)\r\n/*"
  },
  {
    "Vendor": "Ibm",
    "component/product": "zos",
    "type": "HMC",
    "info": "never leave the HMC logon in a service mode. always log off when logged on n service mode."
  },
  {
    "Vendor": "IBM",
    "component/product": "zos",
    "type": "Coupling facility OS.",
    "info": "D CHPID ALL -- lists all the connected chpid'd. --- this works only with coupling facility in the HMC operating system messages."
  },
  {
    "Vendor": "IBm",
    "component/product": "zos",
    "type": "Coupling facility OS.",
    "info": "the command SHUTDOWN would bring down CF lpars. we need to issue it in CFLPAR operating system messages console."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "commands",
    "info": "config chp(xx-yy),offline -- will bring all the chipd between XX and YY offline."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "status",
    "info": "Did network clear the ARP tables? I believe we are resuing the original IP addresses after any change in network. we need to check on load parm and load addr."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "messages",
    "info": "IST1631I TRLFCL1 SUBCHANNEL 8721 QDIO CULA UNAVAILABLE -- issue\r\nsolution -- OSAFC PCHID 110 on IBM1 z15 was toggled offline/online last night due its connection issue, and TRLFCL1 and OSAFCT were waiting for reactivation. This will be fixed by SYST IPL"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "central storage",
    "info": "d m=stor -- displays the total central storage and any available storage.\r\nif any UNASSIGNED STORAGE is available in the DISPLAY you can configure it using the command\r\nCONFIG STOR (dddM),ONLINE command.\r\nif any IN OFFLINE STORAGE ELEMENT(S) is availablein the DISPLAY you can configure it using the command\r\nCONFIG STOR(E=id),ONLINE\r\nD ASM,ALL -- displays all the auxilary storage(Central memory that resides on DASD storage)."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "Memory",
    "info": "CSA and SQA sizes are specified in the sys1.parmlib.\r\nCSA(a,b) = The subparameter a specifies the size of the CSA, located below 16 MB. The subparameter b specifies the size of the extended CSA, located above 16 MB.\r\nCSA(a,b) = A = A decimal number, n, indicating n 1 KB (1024-byte) blocks. The number is 0 through 9999.\r\nCSA(a,b) = B = A decimal number, n, indicating n 1 KB blocks. The number is 0 through 2080767.\r\nSQA(a,b) = The subparameter a specifies the size of the SQA, located below 16 MB. The subparameter b specifies the size of the extended SQA, located above 16 MB. These values are added to the system's minimum SQA of eight 64 KB blocks (or 512 KB) and minimum extended SQA of approximately 8 MB. Both the SQA and extended SQA are fixed in central storage as they are used\r\nSQA(a,b) = A= A decimal number, n, indicating n 64 KB (65536-byte) blocks. The number is 0 through 256.\r\nSQA(a,b) = B = A decimal number, n, indicating n 64 KB blocks. The number is 0 through 32511."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "slip",
    "info": "d slip=xxxx xxxx is the I'd set for the slip"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "webpage",
    "info": "developing a webpage and host it in zos.\r\nhttps://www-01.ibm.com/servers/resourcelink/svc00100.nsf/pages/zOSV2R3sc278417/$file/dpr1cg01.pdf\r\nPage54: Installing and configuring IBM HTTP Server on the z/OS V2R2 system\r\ni am using nicepage.com and i designed the web there and then you can export the data from windows to distribute systems\r\nthe most important is exporting data......the translation codepage would not allow you to read it or use on z/OS unless you do FTP with the following command:\r\nquote site sbdataconn=(ibm-037,iso8859-1) <=== Very important and save this command when transferring data"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "dataset sharing",
    "info": "I'm receiving this error when I try to access a dataset in 2 different jobs at the same time with the same userid for the job. But I'm referring to two different members.\r\nIEF403I I7223893 - STARTED - TIME=11.29.18\r\nIEC813I PDS OWNER: JN=I7223894,SYSNAME=SYSE ,TCB=007FEAB8,\r\nIEC143I 213-30,IFG0194D,I7223893,BTERM,SYSPRINT,5204,ZIODF7,\r\nSYS5.CTS.CA7.ADHOC.JCLOUT.LOG(I7223893)\r\nIEA995I SYMPTOM DUMP OUTPUT 109\r\nSYSTEM COMPLETION CODE=213 REASON CODE=00000030"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "dataset sharing",
    "info": "The abend213-30 means:\r\nAn attempt was made to open a partitioned data set (PDS) for OUTPUT,DISP=SHR. The PDS is already open in this condition, and a DCB is already open for output to the data set. The data set might be on the same system or on another system that is sharing the volume. Access was not serialized before the attempt to open the data set.\r\nFor this type of activity we recommend clients use PDSE, as this is not possible with PDS."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "best practises",
    "info": "1. LOGS : SMF logs RMF Logs\r\nSYSLOG\r\nSYSLOGD (FTP, inetd, regent logs)\r\nLOGREC"
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "best practises",
    "info": "MFA : Message flood automation : free tool from IBM. Could be used to manage messages during a loop condition or so. will help us to stop many same messages being written to console."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "best practises",
    "info": "SMPE : multiple target zone for one prodct based on the customer if we have a central install method."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "changes on central storage (memory) will need to carry out in Image profile of lpars, z/OS or CF, the profiles are defined in Customize/Delete Activation Profiles in HMC."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "utility",
    "info": "utility to try and get source code from a module\r\n//DISASM EXEC PGM=ASMDASM,PARM='HEX'\r\n//STEPLIB DD DISP=SHR,DSN=SYS1.SASMMOD2\r\n//SYSLIB DD DISP=SHR,DSN=SYS1.MMM.LINKLIB --- change to your load module location.\r\n//SYSPRINT DD SYSOUT=*,DCB=BLKSIZE=121,CHARS=GT15\r\n//SYSPUNCH DD SYSOUT=T\r\n//* DISP=(,CATLG),\r\n//* UNIT=SYSDA,DCB=BLKSIZE=3200,\r\n//* SPACE=(TRK,(5,2),RLSE)\r\n//SYSIN DD *\r\nDUMPSMF --- loadmodule that you want to get the source code."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "MVS/LPAR Busy",
    "info": "lpar busy is derived from instrumentation within the hypervisor (the microcode that controls PR/SM) (hard ware prespective).\r\nMVS busy is CPU busy from the perspective of the operating system (z/OS). Essentially it is the amount of time that z/OS did not go into a wait state. (software prespective)."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "lpa",
    "info": "LPA DELETE MODNAME(HBOSMFEX) FORCE(YES) CURRENT\r\nLPA DELETE MODNAME(GLASYSG) FORCE(YES) CURRENT\r\nLPA DELETE MODNAME(GLAMDBG) FORCE(YES) CURRENT"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logstream",
    "info": "List the logstream details.\r\n//LOGLIST EXEC PGM=IXCMIAPU\r\n//SYSPRINT DD SYSOUT=A,DCB=RECFM=FBA\r\n//SYSIN DD *\r\nDATA TYPE(LOGR) REPORT(NO)\r\nLIST LOGSTREAM NAME(WILLIN.IYLX4.DFH*) DETAIL(YES)"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "compare",
    "info": "compare 2 dataset uing rexx -- isp.sispsamp(isrsclst) - exec 'isp.sispsamp(isrsclst)' 'new(TEST.COMPARE.NEW) old('tet.compare.old) outdd(test.prod.list)'\r\n\r\nIn rexx we can use \r\nparms = \"deltal,linecmp,seq\"\r\nADDRESS ISPEXEC \"select pgm(isrsupc) parm(\"parms\")\"\r\n\r\nIn jcl\r\nSTEP1 EXEC PGM=ISRSUPC,PARM=(DELTAL,LINECMP,'')"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "compiler",
    "info": "INput (source code, C++, COBOL, PL/1) -- Translator(high level to assembler) + Assembler(Assembler code to machine code) -- Output(Object Module). [(object module) + (object module) ] Binder (call within object moudels are combined) --- output LoadModule\r\nListing -- errors that helps the programmer correct the source"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logrec",
    "info": "the erep (environmental record editing and printing program) has 2 funcitons:\r\nproduce arious reports\r\nmaintain backup copies of logrec.\r\nBy default, the name of the LOGREC data set is SYS1.LOGREC. It is possible to use a different data set name by specifying a LOGREC parameter in a system parameter list (IEASYSxx)."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "address space",
    "info": "The System Queue Area (SQA) contains system tables that are critical to the entire system. If z/OS uses up all the SQA, it can dynamically obtain more storage from the CSA.\r\n\r\nIf all the CSA has been used up, z/OS would be unable to create more address spaces and a system failure could result."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "SRM",
    "info": "System Resource Manager : (manages CPU, STORAGE and I/O).\r\nhas two equally important objectives. These are:\r\nTo achieve optimal use of the system resources\r\nTo ensure that site specified response and turnaround times are being satisfied\r\nUses WLM policies to determines which address spaces should be given access to resources and how much they should get"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "Wait state",
    "info": "Diabled Wait -- processing stops and the system loads a wait state PSW\r\nThere are two types of disabled wait:\r\nRestartable, meaning that a PSW restart can be performed\r\nNon-restartable, where a stand-alone dump is taken before the system is reIPLed"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "loops",
    "info": "A loop or endless loop occurs when a program endlessly repeats the same sequence of instructions. There are three types of loops:\r\nEnabled loops that can be interrupted; in this way, they move from CPU to CPU in a multiprocessor\r\nDisabled loops that cannot be interrupted so they take over a single processor and put the others under extra strain\r\nSpin loops that occur when one processor requires a resource that another processor is holding\r\n-The system can automatically recover from a spin loop when a specified interval is exceeded; recovery is based on IBM default actions or those specified in the EXSPATxx parmlib member.\r\n-The system can automatically recover from an enabled loop by canceling a job when the system limits on the amount of CPU processing that the job can use is exceeded.\r\n-An operator may be able to recover the system from a disabled loop by performing a PSW restart on the processor that is at 100% utilization."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command Force",
    "info": "Using FORCE command to cancel a task\r\n1. Cancel the task many time usiing the regular cancel tasks --- C task\r\n2. Check the WTOR for the tasks. -- D R,L\r\n3. Check the problem is not an enabled wait. -- Issue the command D A,taskname and check for the CPU time, do it multiple times so we can identify if the CPU time is increasing to know if it is in enabled wait state.\r\n4. Check the CAS. -- F CATALOG,LISTJ(taskname)\r\n5. if a dump is required, enter the DUMP command and respond to the prompt with the name of the job to be removed as well as the MASTER SCHEDULAR ADDRESS SPACE(ASID 1).\r\n6. if it is a non-cancellable procedure then use FORCE taskname,ARM\r\n7. issue the FORCE taskname as a last resort."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command SEND",
    "info": "messaging Commands :\r\nL 'text' -- to log a message to the LOG.\r\nSE 'message' -- all users.\r\nSE 'message',USER=(userid)\r\nSE 'message',USER=(userid1,userid2...useridn)\r\nSE 'message',USER=(userid),logon -- the message will be stored in the broadcast data set and will be retrieved when the user next logs on if they are not logged on at the time of issuing the command.\r\nSE 'message',SAVE -- the message is saved in the broadcast and is shown to users as they logon and already logged in users will see it with their next logon.\r\nSE LIST -- to see all the messages saved in the BROADCAST dataset.\r\nSE MSGNO -- to send a saved message to all users.\r\nSE MSGNO,DELETE -- to delete any saved message."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command Classification",
    "info": "COMMAND CLASSIFICATION: \r\nM1 -- attached to the master scheduler address space, required to clear backlog of commands\r\nM2 -- run in the master scheduler address space.\r\nM3 -- has only SEND command\r\nC1 -- attached to the console address space, required to clear backlog of commands.\r\nC2 -- \r\nC3 -- ROUTE command.\r\nInline COmmands -- command that run in USER address space and do not have 50 commands concurrent limit."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logger",
    "info": "/d logger -- to know the status if system logger is active or not in a system."
  },
  {
    "Vendor": "IBm",
    "component/product": "zos",
    "type": "HMC",
    "info": "offline the crypto chipids.\r\n1. Logon to HMC.\r\n2. select the CEC.\r\n3. Check for SINGLE OBJECT under Recvery services.\r\n4. it opens up the SE pages.\r\n5. Select Systems management\r\n6. on the options select CRYPTOS.\r\n7. it would list the CRYPTO chips.\r\n8. Select the CONFIGURE ON/OFF under Crypto servie operations. and change status."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS CIM",
    "type": "theory",
    "info": "The Common Information Model (CIM) is a standard data model developed by a consortium of major hardware and software vendors (including IBM®), called the Distributed Management Task Force (DMTF). It provides a common definition for describing and accessing systems management data in heterogeneous environments. It allows vendors and system programmers to write applications (CIM monitoring clients) that measure system resources in a network with different operating systems and hardware, and to actually manage those systems."
  },
  {
    "Vendor": "IBM",
    "component/product": "zos docs",
    "type": "website",
    "info": "https://www.ibm.com/support/knowledgecenter/SSLTBW_2.3.0/com.ibm.zos.v2r3/en/homepage.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "Capacity provisioning",
    "info": "Which four scopes can be defined for a Capacity Provisioning policy created in z/OSMF?\r\nMaximum defined capacity\r\nLogical processor\r\nMaximum processor\r\nMaximum group capcaity"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "share",
    "info": "zosmf workflows share - https://share.confex.com/share/123/webprogram/Handout/Session16079/Using%20zOSMF%20Workflows%20to%20Configure.pdf"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "workflow",
    "info": "As mentioned previously, workflows are comprised of steps. Some of these steps will have a dependency on other steps in the workflow, and cannot be actioned until the prerequisite step is completed or skipped. It is not unusual to see optional steps in a workflow, as many of these workflows come from IBM or third-party suppliers who will code the workflow with a number of different scenarios in mind, some of which may not be applicable to your environment. As you will see shortly, you have the option to skip these steps. Steps can contain sub-steps with up to five levels of nesting allowed. A maximum of 500 combined steps, and sub-steps are allowed for a workflow."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "concept",
    "info": "z/OSMF requires RMF, RMF Monitor III, and RMF DDS to monitor z/OS.\r\nz/OSMF can use the RMF Linux Data Gatherer, rmfpms, to monitor Linux on System z.\r\nz/OSMF can use the RMF XP DDS to monitor Linux on System z, AIX, Windows, and Linux on System x."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "network",
    "info": "When accessing the z/OSMF Configuration Assistant, the initial page will prompt you to select a backing store file that holds the configuration data you want to view or work on that Configuration Assistant used to obtains network configuration data"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "network",
    "info": "--AT-TLS is a perspective that can be selected when adding a TCP/IP stack to a z/OS image. AT-TLS is one of several TCP/IP technologies that can be configured for a z/OS image.\r\n--A log of saved changes relating to a backing store can be viewed.\r\n--When a new backing store file is created, it does not immediately becomes the active file so any future changes will be saved to it. we need to create backing store files whenever the configurations are changed.\r\n--Attributes associated with a networking protocol can be modified once they have been configured for a z/OS image.\r\n--The Manage Backing Stores... option will display a list of current and available backing store files and allow, via the Actions menu, to create a new backing store file."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "WLM",
    "info": "z/OSMF can perform all the functions of the ISPF WLM panels, and provides screens to view the WLM status for each system.\r\nIt can load the current WLM from the WLM couple data set.\r\nService definitions can be created, copied, removed, imported, and exported using z/OSMF."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "Capacity provisioning",
    "info": "z/OSMF connects to a Provisioning Manager using a CIM server connection.\r\nProvisioning Manager connections are manually defined from the z/OSMF Capacity Provisioning screen."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "Capacity provisioning",
    "info": "z/OSMF Capacity Provisioning provides a web-based interface to the Capacity Provisioning Manager running on the z/OS system.\r\nThe Domain Status report shows information on the current state of the Provisioning Manager and the domain that it manages.\r\nThe Active Configuration report shows information about the active domain configuration and the status of its CPCs and systems.\r\nz/OSMF uses the CIM Server to communicate with a domain Provisioning Manager.\r\nz/OSMF allows you to modify a Provisioning Manager connection definition."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "monitoring performance",
    "info": "The z/OSMF Resource Monitoring screens can be used to graphically view performance metrics for z/OS. z/OSMF performance management uses the RMF Distributed Data Server (DDS), together with RMF Monitor III and other RMF features.\r\nThe z/OSMF Resource Monitoring can also be used to monitor Linux on z System images on the mainframe, as well as AIX, Windows, and Linux systems running on System x systems in a zEnterprise BladeCenter Extension system. For this monitoring, z/OSMF Resource Monitoring uses the RMF XP Distributed Data Server"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "monitoring performance",
    "info": "z/OSMF requires RMF, RMF Monitor III, and RMF DDS to monitor z/OS.\r\nz/OSMF can use the RMF XP DDS to monitor Linux on System z, AIX, Windows, and Linux on System x."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "software management",
    "info": "Portable software instances : Software instances that can easily be distributed across a network and loaded either from the host z/OSMF system, uploaded from a local workstation, or downloaded from a server.\r\nSoftware instances: A configuration of installed software, related libraries, and data sets that are defined under a single SMP/E global zone.\r\nProducts : Used to display a list of products that have been defined in any of your software instances.\r\nCategories : Used to combine software instances and deployments into meaningful groups.\r\nSettings : Allows you to define software instance defaults.\r\nDeployments : Provides you with a checklist of tasks that are required to deploy a software instance.\r\nz/OSMF retrieves information from the global and target zones, and from product information files."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "software management",
    "info": "Missing FIXCAT SYSMODs : Will identify missing FIXCAT APARs that are required for certain software fixes.\r\nSoftware Instance Validation: will verify that the software libraries associated with the software instance exist and that they contain the data required.\r\nSoftware Instance Comparison : Used to display functional and service differences between two software instances.\r\nEnd of Service : Will identify products that are approaching, or have already met, their end of service support.\r\nMissing Critical Service : If ERROR HOLDDATA has identified exceptions or unresolved items, then this report will assist in identifying the SYSMODs used to resolve them."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "software deployment",
    "info": "z/OSMF can deploy SMP/E installed z/OS software on the same z/OS system by creating a copy on the Parallel Sysplex with local deployment, or on a remote Parallel Sysplex through remote deployment.\r\nIt will create the jobs to perform the deployment, but not submit them.\r\nFor remote deployments, it uses HTTP for z/OSMF communication, and FTP to transfer files."
  },
  {
    "Vendor": "IBM",
    "component/product": "zPDT",
    "type": "zpdt",
    "info": "VATLST00 setup in zPDT system.\r\n - Create USER.PARMLIB(VATLST00).\r\n VATDEF IPLUSE(PRIVATE),SYSUSE(PRIVATE)\r\n PUBLIC,0,1,3390 ,N\r\n USER* ,0,0,3390 ,N\r\n This will ensure that new data sets are written to USER00 and that temporary data sets are written to PUBLIC.\r\n - copy ADCD.Z111S.CLIST(ISPFCL) to USER.CLIST(ISPFCL) and change the first line from PROC 0 VOL(SBSYS1) to PROC 0 VOL(USER00)"
  },
  {
    "Vendor": "ibm",
    "component/product": "zpdt",
    "type": "zpdt",
    "info": "The IBM z System Personal Development Tool (zPDT) provides an environment with one or more IBM z System processors (with several emulated I/O device types), based on a personal computer Linux environment"
  },
  {
    "Vendor": "Open systems",
    "component/product": "SSH",
    "type": "theory",
    "info": "SSH stands for Secured SHell. It is a protocol used by systems to talk to eachother over a network(Client and server) in a secured manner.\r\ntelnet started back in 1960's for systems to communicate with each other but it was not secured overnetwork (not connected directly by wires). SSH came in around 1995 it was secured by way of encryption. (data is converted in cipher text). and by having a key.\r\nSSH components == CLINET + SERVER(where the data resides) + AUTHENTICATION Mechanism."
  },
  {
    "Vendor": "Open systems",
    "component/product": "SSH",
    "type": "theory",
    "info": "Serever : Can run Windows or LINUX or zOS or MAC or IOS or ANDROID OS. LINUX or MAC has SSH by default.\r\nWindows or zOS or IOS and ANDROID Needs to run SSH.\r\nCLient : same as server by a less powered version of OS. (Putty, git bash are good enough to start commmunicaiton using SSH).\r\nAuthentication : To authenticate the communication between 2 systems. It can be done by a password or by using PUBLIC and PRIVATE Keys\r\nssh user@ip -- ssh root@ip of system. it asks for the password."
  },
  {
    "Vendor": "Open systems",
    "component/product": "SSH",
    "type": "theory - keys",
    "info": "to generate a key issue the command \r\nssh-keygen -- it would ask us to specify where the keys has to be stored.\r\nssh-keygen -t rsa -- to produce a public/private key of type RSA and stores it in the location specified. we can also have a password for our keys to be more secure. The public key needs to be copied into the remote system. id_rsa\r\nid_rsa.pub are general naming convention that the key gets generated."
  },
  {
    "Vendor": "Open systems",
    "component/product": "ssh",
    "type": "theory - communicaiton",
    "info": "how the communication is established with open ssh.\r\n\r\nSystem A(becomes client) trying to connect to System B(becomes server)\r\nstep 1 : Client send ssh connection request.\r\nstep 2 : server send a randon message.\r\nstep 3 : client encrypts the message with a private keys and send it back to server.\r\nstep 4 : server decrypts the message using the public keys that is already stored on it and if the keys match then the connection is established."
  },
  {
    "Vendor": "prycroft",
    "component/product": "Interactive Monitoring program",
    "type": "",
    "info": "free utility to monitor zOS system."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "workflows",
    "info": "1) Assign users/team to perform the task -- select a task > select Actions > Assignment and Ownership > select team/user\r\n2) User/team to accept the assigned task -- select a task > select actions > accept > 3) perform the task -- select a task > select actions > perform -- read the instructions and complete the taks > finish"
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "syslog",
    "info": "From the SYSLOG panel, you can display the SYSLOG for another LPAR in the sysplex with the SYSID parameter: \r\nSYSID SYST -- tries to access the SYST LOG from the current system if in sysplex and operlog is active."
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "srch",
    "info": "the command SRCH can be used in APF, LINKLIST, PROC, PARMLIB, LPA options page to search for members."
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "options",
    "info": "we can use SMSV and SMSG to list the status of SMS volume nd SOMS storage groups that are active on the system."
  },
  {
    "Vendor": "Open systems",
    "component/product": "Ansible",
    "type": "Theory",
    "info": "It is 1) Declarative : no need to tell how to do but only what to do\r\n2) Agent Less : no need to run any task on the end machine to implement the task\r\n3) IDEMPOTENT : it keeps history and let us know if something has already been completed and do only tasks that are to be done.\r\n4) Community : it is an open source so we already have many play books that are developed and we can use them."
  },
  {
    "Vendor": "Open systems",
    "component/product": "html",
    "type": "chrome",
    "info": "to open dev tools page in chrome use CTRL + SHIFT + I"
  },
  {
    "Vendor": "Open systems",
    "component/product": "html",
    "type": "checker",
    "info": "we can write a code and check it for html error in https://validator.w3.org/\r\n CSS error in jigsaw.w3.org/css-validator/"
  },
  {
    "Vendor": "IBM",
    "component/product": "zos",
    "type": "memory page",
    "info": "o\tSince MVS/XA Environment, IBM and other datacenters practiced with the following:\r\na)\tThe PLPA Dataset should be 1Cyl only and allow to flow into Common Dataset\r\nThe PLPA with 1-Cyl and Common Dataset should be on the same DASD, except PLPA dataset should be contagious and which means that PLPA should be the first Dataset created on the DASD and followed by Common Dataset.\r\nThis causes the majority of PLPA pages to be written to the COMMON page dataset during IPL. The allows the operating system to use the chained CCW’s within a single dataset and Improves Performance with both datasets are on the same volume.\r\nThe message (“ILR005E PLPA PAGE DATA SET FULL, OVERFLOWING TO COMMON DATA SET”) should be ignored during IPL.\r\nNow, you might ask why do we have to do this? Here’s an answer:\r\no\tThe PLPA and other things like MPLA contains system level programs that are often run by multiple address spaces.\r\no\tFor this reason, the LPA residing in common area, which is addressable by every address space, eliminating the need for each address space to have its own copy of the program."
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "Theory",
    "info": "Tubes can be accessed from a TN3270 terminal, using the TN3270 server facility of Tubes, and non-VTAM sessions can\r\nthen be accessed from Tubes over TCP/IP"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "appl defintion",
    "info": "TUBE VBUILD TYPE=APPL\r\nTUBES APPL ACBNAME=TUBES,AUTH=(ACQ,PASS,NVPACE),EAS=nnn,\r\nPARSESS=YES,VPACING=0\r\nTUB001 APPL ACBNAME=TUB001,AUTH=(ACQ,NVPACE),EAS=nnn,\r\nPARSESS=YES,VPACING=0,MODETAB=M4TUMODE\r\n\r\nIn this example, the name TUBES is the name of the Tubes system ACB; that is, the ACB that will be used for logging on to Tubes itself, and will be specified on the ACB parameter of the Tubes SYSTEM statement. TUB001 defines the default session ACB that Tubes will use to establish sessions with applications"
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "Theory",
    "info": "Tubes supports VTAM FASTPATH. This reduces the amount of validation performed by VTAM and increases the throughput. Installations wanting to use FASTPATH should code SRBEXIT YES on the APPL statement for each minor node in the application major node for Tubes. This includes the Tubes ACB, TUBES, and all the dummy ACB definitions."
  },
  {
    "Vendor": "macro4",
    "component/product": "tubes",
    "type": "logon",
    "info": "Users who would normally enter the system using the signon panel can in fact bypass this display by entering their userid (and password if required) as VTAM logon data when logging on to Tubes. For example:\r\nLOGON APPLID=TUBES,DATA=userid/password\r\nLOGON APPLID=TUBES,DATA=userid/password/newpassword/newprofile\r\nor, if just the new profile were required:\r\nLOGON APPLID=TUBES,DATA=userid///newprofile"
  },
  {
    "Vendor": "Open systems",
    "component/product": "hypervisor\r\nVirtualizaiton",
    "type": "theory",
    "info": "Virtual machines are completely isolated. benefits: Learn and experiment. you dont want to endanger the main OS. test an app in different OS.\r\nTYPE2: Creating machinge on top of an exsisting hardware (Hardware >> HOST OS>> HYPERVISOR >> GUEST OS)\r\nGenerally for personal computers.\r\nTYPE1: Creating machinge on top of an exsisting hardware without host os (Bare metal hypervisor) (Hardware >> HYPERVISOR >> GUEST OS\r\nHypervisor controls the hardware resource.\r\nEX: VMWARE ESxi, Micorsoft Hyper-v\r\ngenerally used by big corporations.\r\nEliminate the tightly coupled situation of running OS directly on the HArdware. with virtualization we can create virtual machine image (OS as a portable file with all the required applications). we can backup images and they are called snapshots.\r\nVirtual machines are portable without being dependent of any physical server."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "topsecret",
    "type": "command",
    "info": "TSS PE(A93LNZZ) DSN(UKPCA7AD.*) ACC(UPDATE) -->>> GENERIC DEFINITION -\tOR - TSS PE(A93LNZZ) DSN(UKPCA7AD.CA7.UK01.MUF.CUSMAC) ACC(UPDATE) -->>> SPECIFIC DEFINITION A specific definition always overrides any generic definition so if both are found and are valid then the specific one will take precedence. TSS REFRESH(A93LNZZ) JOBNAME(*) ->>> refresh the cache in one system. Even though the DB is shared across the plex you may have to refresh each system manually"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "jcl",
    "info": "job to delay/wait/sleep the execution for some time.\r\n//* //STEPX EXEC PGM=AOPBATCH,PARM='sh /bin/sleep 60' --- this make the job to be in running state for 60 secs.\r\n//STDOUT DD SYSOUT=* //STDERR DD SYSOUT=* //STDIN DD DUMMY\r\n/* REXX */ CALL SYSCALLS 'ON' ADDRESS SYSCALL \"SLEEP\" 60 CALL SYSCALLS 'OFF' EXIT 0"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "Architecture -- CHPID",
    "info": "I/O Adapters -- connected to dasd, network devices, NAS (Network accessed stoarge). I/O adapter are identified as CHPID (channel path Identifiers). CHPID is assocaited with a physical port location called PCHPID (Physical channel path identifier) and a subsystem that managers the I/O of the machine."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "Operating system",
    "info": "It is the set of rules and methods that describe the functionality, organization, and implementation of the computer system\r\nProcess Management + MEMory management + Security Management + communications Management + Resource Managemet + File Management"
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "Operating system",
    "info": "Major Components : Crypto services, SDSF, SMP/e, RMF, SMF, DFSMS, WLM, JES, zOS Unix services, SNA(TCP/IP)"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "Operating system",
    "info": "IRD : Intelligent resource director. Optimizes processor and channel resuce utilizaiton across lpars in a CEC. It groups LPARS into a Cluster and allows WLM to manage the resources.\r\n1. LPAR CPU managment\r\n2. Dynamic Channel path management.\r\n3. Channel subsytem Priority queuing"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "Operating system",
    "info": "HYpersockets provide high speed connectivit within the CEC.These connections are virtual.\r\nHyperdispatcher helps in sahring teh CP's workign with WLM."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "Operating system : ZDAC",
    "info": "zDAC : zdiscovery and Autoconfiguration : Can detect certain resources on FICON and SAN and stream lines the process of configuring HCD."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "Operating system",
    "info": "HMC : acts as remote connected options for SE. We can maintain multiple system in a single HMC and One system in Multiple HMC's"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "Operating system : SE",
    "info": "Support Element: LIC (licene for internal code) that is used to control and monitor CPC\r\nlogging and problem determination functions.\r\nhardware system definitions for server\r\nIOCDS that is used to POR time\r\nBOC(Battery operated clock) to set CPC TOD clocks and POR time\r\nEthernet adapters for connectivity."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "sysplex",
    "info": "Parts of sysplex:\r\n1. STP : Server time protocol: Multiple systems accessing the data at the sma etime.\r\n2. GRS : Global resource serialization\r\n3. XCF : Manages communication between applicaiton in a sysplex. Issue command on one system on behalf of another system in sysplex.\r\n4. Coupling links : Lpars to memory. Direct memory access communicaiton between sysplex memory and attached system memory.\r\n5. Couple Datasets : Contains information related to the parallel sysplex systems.\r\nBASE SYSPLEX : all systems physically connected to each other.\r\nPARALLEL SYSPLEX : All systems connected to coupling facility to communicate.\r\nRolling IPL : shutting down couple of lpars in a sysplex and doing changes and bringing it back into plex."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "security",
    "info": "Confidentiality\r\nAvailability\r\nIntegrity\r\n\r\n4767 cryptographic co-processor enable the security. On mainframe it is crypto express."
  },
  {
    "Vendor": "ibm",
    "component/product": "education",
    "type": "website",
    "info": "https://www.ibm.com/it-infrastructure/z/education"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "theory",
    "info": "PROTECT ALL -- will not allow any HLQ's which do not have RACF entry. Avoids users creating datasets with HLQ that are not protected.\r\nLogging needs to be enabled only them SMF records are generated.\r\nPERMIT can be done only when we have SPECICAL access or for your own userid."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "cryptography",
    "info": "CPACF (Central processor assist for cryptographic function) hardware component is located on the processor for Symmetric key functions and CRYPTO Express.\r\nSecured Key : never leave the CRYPTO card.\r\nProtected Key : Clear KEy : Key in storage and read by authorised users."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "hardware",
    "info": "IOCDS : Input output configuration dataset. represents the connections between the resources (channels, FICON switches, COntrol units and other devices) and the machines that use them. It is a series of statements. It gets stored on the SE. Tehy are picked when the system is powered on.\r\nI/O Subsystem that contorl CHANNEL (physical connection between the lpar and the machine I/O cards) Operations. it requries the hardware I/O configuration and to define that we use"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "hardware",
    "info": "IOCP: has five statements: \r\nID Statement:\r\nREsoruce name: MIF ID : every logical partition in the configuration.\r\nCHPID : all the channels in the systems, these are the logical connection between the lpar and the PCHPID. It also specifies if the channel is dedicated, shared or reconfigurable or span. if connected to FICON switch it handles the assignments also.\r\nCTLUNIT : the characteristics of the CTLUNIT, CHannel paths , UNIT address that the CU addresses.\r\nIODEVICE : need the device number, CTLUNIT it is connected to."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "IPL",
    "info": "IPL : Initial program load\r\nPOR : Load input output configuraiton dataset from the support element harddrive into the hardware system area and creates subchannels for each device defined in IOCDS.\r\nStopping all the work that is being done on all the lpars and taking down all the lpars."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "IPL",
    "info": "Activation Profiles :\r\nRESET : How license internal code is loaded and how much central and expanded storage does the lpar's get.\r\nIMAGE : How much processor (dedicated or shared) and how many and how much memory.\r\nLOAD : the Channel addres that OS needs to be loaded from. GROUP :"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "IPL",
    "info": "Hardware IPL\r\nIPL RIMs\r\nNIP RIMs\r\nMSI\r\nJES"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "csm",
    "type": "migration",
    "info": "Migrate CA CSM to zOSMF\r\nhttps://knowledge.broadcom.com/external/article?articleId=197545"
  },
  {
    "Vendor": "macro4",
    "component/product": "license",
    "type": "license",
    "info": "use the line command LMVIEW to view the licene against the license member"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "The LISTDIR command can show update information for PDS members.\r\nOn the VTOC command, there's a RefDate field which shows when a data set was last referenced.\r\nThat would include both updating or browsing the data set, but if it's an old date they can at least tell that's it hasn't been referenced in a while.\r\nIt looks like the VTOC command is only for one VOLSER. That field is also available from DSINFO, so you could do a DSCAT for whichever data sets you're interested in, then drill down to DSINFO"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "utility",
    "info": "copy volumes.\r\n//LXD2C2BB JOB ,'IBMUSER',MSGLEVEL=(1,1),TIME=(5,0),REGION=4096K, // MSGCLASS=H,CLASS=A\r\n//STEPT02 EXEC PGM=ADRDSSU\r\n//SYSPRINT DD SYSOUT=*\r\n//SOURCE DD UNIT=3390,VOL=SER=LNX200,DISP=OLD\r\n//TARGET DD UNIT=3390,VOL=SER=LNX900,DISP=OLD\r\n//SYSIN DD *\r\nCOPY FULL INDDNAME(SOURCE) OUTDDNAME(TARGET) -\r\nCOPYVOLID ALLEXCP /*\r\nExplanation from IBM manual:\r\nOn the DFSMSdss COPY FULL command, include the COPYVOLID keyword to cause DFSMSdss to copy the volser to the new volume. When the copy operation completes, the two volumes are identical, including the volser. Because z/OS allows only one volume with a particular volser to be online at a time, DFSMSdss varies offline the volume that was the target of the copy."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "lcu",
    "info": "we can have upto 32 UCB's per LCU."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "copy",
    "info": "steps to do a volume copy and use the new UCB.\r\n1. In the IODF define the new UCB\r\n2. Make it offline for the system where the copy is required.\r\n3. Make is available as offline to any other system where the original volume is not accessed on day to day to avoid any constraints of the volume being used when the copy is done.\r\n4. Make the required IODF change to make hte new UCB online and OLD UCB offline with the next IPL.\r\n4. shutdown the org system.\r\n5. ensure to have all the required access to all the datasets in the org volume to copy for the access.\r\n6. make both the org vole and new ucb vol online to the system where the copy would be run.\r\n7. run the COPYVOLID to copy over the volumes.\r\n8. IPL the system."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "OPSMVS",
    "type": "command",
    "info": "/OPSMOUNT DEVNUM=xxxx,VOLSER=yyyyyy -- if OSPMVS is controlling the device online, then we need to use this command"
  },
  {
    "Vendor": "IBM",
    "component/product": "DASD",
    "type": "replicaiton",
    "info": "when doing a reverse replicaiton and we get an error like Volumes are online... its better to RESET CLEAR on the system systems that are shutdown just to ensure that they are not holding onto the volumes. also, it is always good to do a RESER CLEAR whenever a system is shutdown."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "zOS V2.5",
    "info": "Enhanced System Recovery Boost for IBM z15 servers. This capability enables clients to leverage a class of boost that can be applied to a range of z/OS sysplex recovery processes, including sysplex partitioning, CF structure recovery, CF data-sharing member recovery, and IBM HyperSwap®.\r\nServerPac for z/OS V2.5 as a portable software instance and guided process within z/OSMF without requiring extensive z/OS systems skills\r\nz/OS BCPii provides a powerful way for z/OS applications to automate and control the operations of Z hardware in multiple languages, including REXX. A new z/OS BCPii API named HWIREST is introduced for the z15 that enables applications to access many previously unavailable attributes of the z15, including central processor complex (CPC) storage, storage allocated for an LPAR, CPC environmentals such as exhaust air temperature and dew points, and detailed information about processors and their assignments to an LPAR"
  },
  {
    "Vendor": "Ibm",
    "component/product": "zos",
    "type": "zOS V2.5",
    "info": "DFSMShsm recover UNIX files to a new directory: With the PTF for APAR OA58612, this enhancement is also available on z/OS V2.3 and later.\r\nDFSMShsm UNIX file-level backup and recovery with EXCLUDE criteria: With the PTF for APAR OA57868, this enhancement is also available on z/OS V2.3 and later.\r\nImprove monitoring the status of z/OS UNIX system limits, the default value for LIMMSG keyword in the z/OS UNIX PARMLIB member (BPXPRMxx) is changed, enabling warning console messages to appear whenever a system limit is reached by a given process."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "console",
    "info": "The z/OS Operator Consoles task uses EMCS consoles to support console operations. Some setup is required for each console. For a sample job that provides the required setup, see SYS1.SAMPLIB(IZUGCSEC)"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "recovery",
    "info": "SDSF is enhanced to display information about the use of system recovery boost. With the PTF for APAR PH26552, this enhancement is available on z/OS V2.3 and later."
  },
  {
    "Vendor": "ibm",
    "component/product": "Mainframe",
    "type": "server upgrade",
    "info": "Describe how your company handles hardware changes during an active agreement (ex. End of support, MIPS increase/decrease, etc.).\r\n1. Have the current setup documented (Capacity, network, CHPID, DASD backup/replication)\r\n2. Identify the new server as per our requirement based on our current capacity and any near future capacity that we would need.\r\n3. Make note of any software maintenance that would be required for the OS/Subsystems/products and storage box for supporting the new hardware and apply them.\r\n4. Once the system is in our DC (Work with IBM partners to install it )\r\n5. Work with the network (open systems + Mainframe) to identify and update the network changes that would be required.\r\n6. Create new IODF’s that would have details about the new hardware.\r\n7. Have new CFRM policies defined if the systems are in SYSPLEX that points to the new server.\r\n8. Setup the new server in the HMC and get it updated to have all the configuration\r\n9. Complete the installation of the server and do a POR using SE. (Based on the requirement we need to be connected to the prod storage box or a new storage box)\r\n10. Start a driver system if we have the feasibility.\r\n11. Plan for the movement of systems one after the other (plan for the DASD movement too / sharing with OLD box)\r\n12. Shutdown a test on current server and using the new IODF, new licenses, updated parms bring up one TEST system on the new server and do some testing.\r\n13. For prod system as per plan we can shutdown all systems at once on current and bring them up on new server or go one system after another."
  },
  {
    "Vendor": "ibm",
    "component/product": "modernization",
    "type": "zcx",
    "info": "https://github.com/ambitus/ambitus"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "iodf",
    "info": "Changing IODFxx to a different volume. and IPLing the system\r\n- Initialized UCBxxxx with label ABC123, (new volume)\r\n- Copied HCD.IODF72 to SYS0.IODF72 on ABC123 via the HCD panel option,\r\n- Allocated SYS0.IPLPARM on ABC123,\r\n- Copied LOADX* from SYS1.IPLPARM to SYS0.IPLPARM,\r\n- Updated LOADX* in SYS0.IPLPARM to use HLQ SYS0 instead of HCD for the IODF.\r\nThen I reIPLed the system with load parameter newucbX2, it came up OK."
  },
  {
    "Vendor": "Ibm",
    "component/product": "pprc",
    "type": "commands",
    "info": "metro mirror command to pause and failover\r\nHere are the two commands that need to be run:\r\nOn DS277\r\npausepprc -dev IBM.2107-75LGX21 -remotedev IBM.2107-75LGK41 2800-28E6:2800-28E6\r\nOn DS224\r\nfailoverpprc -dev IBM.2107-75LGK41 -remotedev IBM.2107-75LGX21 -type mmir 2800-28E6:2800-28E6"
  },
  {
    "Vendor": "Rocket",
    "component/product": "EOS",
    "type": "License",
    "info": "for any DR test. we dont need to get a special key if the DR test is for less than 21 days.\r\nYou can check the EOS Control Profile. PROF + enter on the command line after logging on the EOS. Then option 6, select Control Profile. If the BACKUP CPU field is blank, you are good to go"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "trace",
    "info": "1) Start the TCPIP packet trace\r\na. TRACE CT,ON,COMP=SYSTCPIP,SUB=(TCPIP)\r\nb. R xx,OPTIONS=(TCP,ACCESS),JOBNAME=(appjobname),END\r\nc. TRACE CT,256M,COMP=SYSTCPDA,SUB=(TCPIP)\r\nd. R xx,END\r\n2) Start the PKTTRACE processing. PORTNUM is the port number that the application is listening on:\r\na. V TCPIP,TCPIP,PKT,CLEAR\r\nb. V TCPIP,TCPIP,PKT,ON,IP=remote_ip_address,portnum=xxxx\r\n3) Recreate problem .\r\na. Collect dumps of TCPIP :\r\nb. DUMP COMM=('TS007241198-2')\r\nc. R xx,JOBNAME=(TCPIP),CONT\r\nd. R yy,SDATA=(PSA,CSA,RGN,TRT),END\r\n4) Stop the TCPIP packet trace\r\n5) V TCPIP,,PKT,OFF\r\n6) Stop component trace\r\na. TRACE CT,OFF,COMP=SYSTCPIP,SUB=(TCPIP)"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "D TCPIP,,N,ARP"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "d tcpip,,n,home"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "D TCPIP,,N,ROUTE"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "compatibility",
    "type": "website",
    "info": "https://ftpdocs.broadcom.com/WebInterface/phpdocs/0/MSPSaccount/COMPAT/zos_compat.HTML Broadcom compatibility."
  },
  {
    "Vendor": "Rocket",
    "component/product": "EOS",
    "type": "website",
    "info": "https://webapps.bmc.com/support/faces/az/supportlisting.jsp\r\nEOS dates for BMC, COMPWARE and FDR products"
  },
  {
    "Vendor": "bmc",
    "component/product": "compatibility",
    "type": "website",
    "info": "https://customerapps.bmc.com/spac/o/welcome.html\r\ncompatibility sheet for BMC, COMPWRAE and FDR products"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "dvipa",
    "info": "There are 2 sites, with the OSA adapters in both sites spanned across the same lan segment. The subnet where the VIPA/DVIPA addresses reside is different from the OSA adapters. When the router needs to forward a packet to a VIPA/DVIPA it will use the MAC address of an OSA that has advertised the route. The OSA will receive the packet and look up the destination IP address to find out which LPAR sharing the OSA owns that address and forward it to that TCPIP stack. If the IP address is not registered in the OSA the packet will be discarded by the OSA. The OMPROUTE configuration for the VIPA/DVIPA was defined as an INTERFACE statement so it only advertised the subnet route. When all LPARs were in the same site this was not a problem as the packet would be forwarded to the OSA and the OSA would then send it to the TCPIP stack that owned the VIPA/DVIPA. When LPARs were moved to the second site the subnet address gets advertised from both sites. The subnet must still be routed to via the OSAs and the router will route the packets based on the subnet route it has learned. If that subnet route is for an OSA on the site where the VIPA/DVIPA is active the packet will be delivered correctly. If it is not active on the site where the subnet route is pointing the OSA will discard the packet when it arrives. The advertisement of the subnet from different TCPIP stacks creates a disjoint subnet, where addresses within the subnet are not reachable via the OSA address where the subnet route is advertised from. The OSA sharing logic is allowing this to work when everything is in one site even though the configuration is not supported. To avoid this it is recommended to ONLY advertise the host routes which avoids the advertisement of a disjoint subnet. To do this requires the OMPROUTE configuration to have the VIPA/DVIPA interfaces to be defined with OSPF_INTERFACE and the Advertise_VIPA_routes=HOST_ONLY. The network diagram that showed the subnet spanning the sites is not correct and will be updated. In reality the subnet does not span a single site either, but is really unique per TCPIP stack that has a VIPA/DVIPA within the subnet. The TCPIP registering all of its active IP addresses to the shared OSA is allowing this to work but if you change the TCPIP configuration for the OSA interfaces to use VMAC this will break as packets will be forwarded based on the VMAC instead of the destination IP address."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "dvipa",
    "info": "V TCPIP,,OSAINFO,INTFNAME=osa_interface_name can be used to display the IP addresses that are registered in the OSA for the TCPIP stack where the command is issued. This will show you how the shared OSA routing is working for a VIPA/DVIPA in the subnet.\r\nThe OMPROUTE configuration was changed to OSPF_INTERFACE with Advertise_VIPA_Routes=HOST_ONLY and the Attaches_To_Area=3.0.0.2 so the routes are advertised in that area. The VIPA/DVIPA addresses are pingable."
  },
  {
    "Vendor": "IBM",
    "component/product": "network",
    "type": "Enterprise extneder",
    "info": "D NET,EEDIAG,TEST=YES,IPADDR=(169.10.244.212,169.4.83.1),LIST=DETAIL -- chekc the enterprise extender connection from source to destination IP."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "Enterprise extneder",
    "info": "D NET,ID=SWGEU18,SCOPE=ALL -- this command is to check whether the EE node is active from SYSG to EU18"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "Enterprise extneder",
    "info": "if it is not active state issue V NET,INACT,ID=SWGEU18 -- wait for some time to get it inactive"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "Enterprise extneder",
    "info": "before we try to activate the node make sure it is not active by issuing the command D NET,ID=SWGEU18,E - we should get below response IST453I ID PARAMETER VALUE DOMSP.SWGEU18 NOT VALID"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "Enterprise extneder",
    "info": "to activate the node issue the following command V NET,ACT,ID=SWGEU18,SCOPE=ALL"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "parms",
    "info": "improve monitoring the status of z/OS UNIX system limits, the default value for LIMMSG keyword in the z/OS UNIX PARMLIB member (BPXPRMxx) is changed, enabling warning console messages to appear whenever a system limit is reached by a given process."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "oview, obrowse, oedit"
  },
  {
    "Vendor": "bmc",
    "component/product": "fileaid",
    "type": "commands",
    "info": "z\r\ntso xvjlook"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "utility",
    "info": "in 3.4 listing we can use APPEND hlq.**.LLQ and so on to list more datasets as required with different HLQ's\r\nin 3.4 listing we can use exclude sting or exclude string all -- will exclude all the datasets with that string in the name.\r\nin 3.4 listing we can use VA (list attributes), VS(show space), VT(created and changed time), and VV(volume)."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "stc",
    "info": "RMF -- Control Address space\r\nRMFGAT -- RMF Monitor III gatherer\r\nGPMSERVE -- RMF Distributed Data server\r\nGPM4CIM -- RMF XP (Cross platform monitoring)\r\nRMFM3B -- RMF Monitor lll bath reporting)"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "logon proc",
    "info": "To call a rexx in logon proc or any other procedure.\r\n//TRXPR01 EXEC PGM=TRX,REGION=0M,DYNAMNBR=65, // PARM='EX ''SYS1.CMDPROC(ALCDYNM0)'' '"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "moniotr iii",
    "info": "the RMFGAT zIIP exploitation can be controlled initially by means of new monitor III parmlib parm zIIPUSE.\r\nF RMF,F III,ZIIPUSE/NOZIIPUSE"
  },
  {
    "Vendor": "ibm",
    "component/product": "zcx",
    "type": "zcx",
    "info": "each linux docker server represented by a z/OS owned, managed and advertised dynamic vipa (dvipa). Allows restart of the zcx instance in another system in the sysplex."
  },
  {
    "Vendor": "ibm",
    "component/product": "wml",
    "type": "wml",
    "info": "Watson Machine learning."
  },
  {
    "Vendor": "macro4",
    "component/product": "vtamprint",
    "type": "kill",
    "info": "Columbus Z Shutdown\r\nAn MVS Modify 'F VTAMPRNT KILL,IMMED' may cause an abend S0C4 in module\r\nCPTERM+5B0. KILL,IMMED is an invalid command but it is not being flagged as\r\nsuch when issued using the MVS modify command.\r\nPlease use 'F COLUMBUS,KILL IMMED' and the problem will not occur."
  },
  {
    "Vendor": "macro4",
    "component/product": "vtamprint",
    "type": "working",
    "info": "Applications that create documents in CICS interface with Columbus Z by linking to the supplied CICS report creation program, M4VACICU. M4VACICU in turn connects to M4AS which routes the documents through to the JES spool via various IBM SAPI calls. M4AS makes use of access registers for this type of cross memory communication.\r\n\r\nIn z/OS 2.3, IBM introduced maintenance that affected the way these access registers are handled. Without fix ASO00059 applied, an S0E0 abend occurs.”"
  },
  {
    "Vendor": "ibm",
    "component/product": "operlog",
    "type": "operlog",
    "info": "V OPERLOG,HARDCPY -- to active the operlog\r\nV OPERLOG,HARDCPY,OFF -- to deactivate the operlog\r\nD conosles,hardcopy -- to check if operlog is getting the messages or syslog"
  },
  {
    "Vendor": "macro4",
    "component/product": "vtamprint",
    "type": "setup",
    "info": ""
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Dispatch",
    "type": "LDS full",
    "info": "Check for MSG/ARCHIVE/ARCHDUP/ARCHRES in 8; 2 -- any messages are waiting\r\nCheck for tasks that are active in 8;1 -- ensure all the archive and other tasks are active. (arch1, arch2, arch3)\r\nDispatch archive if happening to tape then they are not cataloged."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Dispatch",
    "type": "MAXDS",
    "info": "CADD134W Report -- ABC --- olv and archive and print --- ,\r\n1 entry in olv -- maxds would be down only when the report is removed from olv -- 1 entry in archvie -- once the archive happens then the header2 record get updated with archive flag is completed. (17500) --- 91%\r\n1 entry for print -- once the print happens then the header record2 gets updated\r\nMaxds -- header2 record that has 3 process flags as one entry -- only when the above 3 actions get performed the maxds entry gets reduced or removed by cadzspl process.\r\nmy lds count would -- 3\r\nWhen will the count gets reduced in LDS 1. When the olv file retention is over then cadsview run and remvoe the entry then LDS entry gets deleted for olvs entry of the report and the report is archived and it is printed once all these 3 tasks are completed then maxds count comes down"
  },
  {
    "Vendor": "IBM",
    "component/product": "omvs",
    "type": "filesystem",
    "info": "mounted as OWNER(xxxx) and in our USS Environment, for some reason it is coded as NOAUTOMOVE, so when xxxx System is Shutdown then these filesystems goes into Orphan Mode and in IO Error state. Any filesystems that are in IO Error impacts performance and your Backup Environments as system will continue to access IO Errors and results into Higher CPU as it occurs on FDR Backups, when we do backups such as /*."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "ACF2",
    "type": "logon proc",
    "info": "1.\tDefine the logon proc to Top Secret: TSS ADD (DSTC) TSOPROC(TSOPROC) 2.\tDefine permissions: TSS PE(A93LNZZ) TSOPROC(TSOPROC) 3.\tRefresh the cache: TSS MODI CACHE(CLEAR) , then TSS REFRESH(A93LNZZ) JOBNAME(*)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "replacement",
    "type": "replacement",
    "info": "1. List all the CA products and their functionalities to understand the usage of the products.\r\n2. Run reports to identify the usage of CA products running on the system and Identify if any products are not used that can be omitted from the conversion.\r\n3. Make a note of the configurations wrt to security requirements.\r\n4. Identify the application that each CA-product is specifically using and tools that are independent of any application.\r\n5. Match the product usage wrt to the system programming teams (z/OS, CICS, Database, Storage, network, Middle ware, security)\r\n6. Categorize the products as scheduling / automation / monitoring / reporting / application assist for easy identification of replacement products.\r\n7. Work with different vendors and identify products that could be possible replacements for the respective CA products and drill down to identify one product for each CA product based on the functionalities that the new product would match with CA products. (we may endup having multiple products for each product or vice versa)."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "replacement",
    "type": "replacement",
    "info": "8. Plan couple of teams to work on the replacement and have the products allotted accordingly this way we can run multiple product replacement parallelly. 9. Identify a test lpar in the customer environment where we can run the identified replacement products and test it.\r\n10. Install the products and test them (Both the system programmer testing and application testing needs to be completed where ever possible). Here we can first work with trail licenses and once we conclude that all the functionalities can be replace we can go for a working license.\r\n11. Ensure to work with security teams to establish similar security rules.\r\n12. Most of the products can run in parallel to the CA products, so we can move the replacement product to prod system and start it parallelly and test it. 13. Once the testing is completed we can either move the functionalities fully from CA product to the replacement product or move them part by part as we test. 14. We can do incremental approach rather than a big bang approach.\r\n15. Once we are successful on one production system we can move to the other system.\r\n16. We can start shutting down CA products as we complete the replacement installs"
  },
  {
    "Vendor": "IBM",
    "component/product": "linklist",
    "type": "commands",
    "info": "to check for the current users of a lnklst\r\nd prog,lnklst,users,name=linklistname"
  },
  {
    "Vendor": "IBM",
    "component/product": "tso",
    "type": "commands",
    "info": "TSO CONSOLE : enables us to issue any console command from our TSO session instead of going to the SDSF.\r\nwe need have the below access to use the command\r\nPERMIT console CLASS(TSOAUTH) ACCESS(read) ID(<userid>)"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "console",
    "info": "The sample job to setup the security is in SYS1.SAMPLIB(IZUGCSEC).\r\nI went through the job but wanted to start only the following setup as I believe I have access to other resources and we don’t want to do some others at this point.\r\nSYSTCONS is the name that I would using for the console in zosmf.\r\nRDEFINE OPERCMDS MVS.MCSOPER.SYSTCONS UACC(NONE) PERMIT MVS.MCSOPER.SYSTCONS CLASS(OPERCMDS) ACCESS(READ) + ID(A93LNZZ) ADDUSER SYSTCONS OPERPARM(AUTH(MASTER) ROUTCODE(ALL) MSCOPE(SYST) STORAGE(15))"
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware",
    "type": "website",
    "info": "z15 animated.\r\nhttps://www.ibm.com/demos/it-infrastructure/product.html#14/1401;C1315\r\nhttps://www.ibm.com/demos/it-infrastructure/zEnhancedTour/index.html#z15;C1315\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "datasets search and group",
    "info": "we cna group jobs from different datasets and copy them into the same folder and place it on the desktop"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "requirements",
    "info": "-The z/OSMF server requires a minimum of 4 GB of system memory to be configured\r\n-having one z/OSMF server active in a sysplex or monoplex is sufficient, but you might choose to have more, based on your workload requirements. The goal is to ensure that at least one z/OSMF server is always active in your environment.\r\n-The sample job IZUSEC provides RACF commands for creating a certificate authority (CA) and a server certificate"
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "commands",
    "info": "Command to refresh SDSF parm updates. if we are using the ISFPRMxx member then check the SDSF JCL and identify the xx and update it for any changes and then issue the below commands to refresh the SDSF task with updates.\r\nF SDSF,REFRESH\r\nF SDSF,REFRESH,M=01,TEST\r\nF SDSF,REFRESH,TEST"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "sdsf",
    "info": "1. Go to general setting and sdsf and update the logon proc, account number and sdsf groupid (Check in WHO command)\r\n2. go to Jobs and resources and select SDSF to invoke the panels."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "commands",
    "info": "display command to identify the suffix of parmlibs that are read from IEASYSxx\r\nD IPLINFO,PROG -- dispaly the PROG=(xx,xx,xx) from the IEASYSxx member\r\nD IPLINFO,SVC -- display the IEASVCxx from the IEASYSxx member\r\nD IPLINFO,ZAAPZIIP -- displays the availability of zaapziip pu\r\nD IPLINFO,ZAAPZIIP,STATUS -- to display if the ziip is acitve on this lpar."
  },
  {
    "Vendor": "ibm",
    "component/product": "zcx",
    "type": "website",
    "info": " https://www.ibm.com/support/z-content-solutions/container-extensions/"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "theory",
    "info": "if we need to receive any files from outside systems or other mainframe to a system then that systme should be running FTPD* task (server task). Else we would only be able to send files and wont be able to receive files."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "CEA",
    "info": "CEA - Common event adapter - SYS1.SAMPLIB(CEASEC) -- security setting required to for setting up CEA. provides the ability to deliver z/OS events to clients such as CIM server, and create or manage TSO user address spaces under ISPF task."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "first page",
    "info": "If we want custom messages in our logon please check the General setting in z/OSMF settings and update the CUSTOMIZATION tab."
  },
  {
    "Vendor": "amazon",
    "component/product": "aws",
    "type": "mainframe modernizaiton",
    "info": "Automated Conversion with Refactoring -- an automated conversion approach, which retains functional equivalence and critical business logic while converting core legacy applications to maintainable, refactored object-oriented Java. The code is analyzed during the assessment to determine cloud-readiness and the required effort to obtain the desired level of elasticity (i.e. horizontal scalability and vertical scalability) required by the application workloads."
  },
  {
    "Vendor": "modern systems",
    "component/product": "CTU",
    "type": "mainframe modernizaiton",
    "info": "COBOL-to-Universal Solution (CTU) software solution supports typical mainframe-based COBOL application components, including CICS, JCL, and common utilities, such as IDCAMS and SORT, in addition to data stores like DB2 for z/OS, IMS, VSAM, and IDMS databases\r\n         is used to reverse-engineer the COBOL code into an intermediate language, and then to forward-engineer the target Java code. the resulting Java application became object-oriented and separated into three layers: presentation logic, business logic, and data access."
  },
  {
    "Vendor": "amazon",
    "component/product": "aws",
    "type": "mainframe modernizaiton",
    "info": " CICS BMS Maps were migrated to equivalent web pages which mimic the original 3270 screens as closely as possible \r\n  During the refactoring process, all VSAM records were analyzed and a DDL generated for each of the best layouts chosen."
  },
  {
    "Vendor": "amazon",
    "component/product": "aws",
    "type": "mainframe modernizaiton",
    "info": "https://aws.amazon.com/mainframe/"
  },
  {
    "Vendor": "IBM",
    "component/product": "Python",
    "type": "website",
    "info": "https://www.ibm.com/products/open-enterprise-python-zos"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "commands ",
    "info": "if we need to rename a PDS member in REXX best to it the following way.\r\n/* rexx */                                                              \r\ntrace i                                                                 \r\naddress tso                                                             \r\n\"ALLOC FI(MYDD) DA('SYS1.PARMLIB') SHR REUSE\"                           \r\nif RC=0 then                                                            \r\n   do                                                                   \r\n/* oldname and newname are variables containing the name of the old     \r\new members  */                                                          \r\n\"ALTER 'SYS1.PARMLIB(PROGYY)' NEWNAME('SYS1.PARMLIB(PROGDD)') FILE(MYDD)\r\n\"                                                                       \r\n\"FREE FI(MYDD)\"                                                         \r\n   end                                                                  "
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "features",
    "info": "Sending diagnostics data to IBM using zOSMF"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "configuration",
    "info": "we need to update the member IZUPRMxx to have any plugins activated."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "commands",
    "info": "TSO NETSTAT ALLCONN (CLI GPMSERVE  -- to check the connecitons that are coming to that address space/STC."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "sysplex",
    "info": "Resource authorizations for the Sysplex Management plug-in. IBM provides job IZUSPSEC in SYS1.SAMPLIB"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "amapdupl",
    "info": "we can use this utility to send files to IBM cases using ftp and it would send the data in multiple ftp sessions running in parallel. this way we can send large files without being timed out and asap.\r\n//FTP     EXEC PGM=AMAPDUPL                                          \r\n//SYSUDUMP DD  SYSOUT=*                                              \r\n//SYSPRINT DD  SYSOUT=*                                              \r\n//SYSUT1   DD  DISP=SHR,DSN=CEA.Y00.DA9885E4.CACBFA06.X00.VEW        \r\n//SYSIN    DD  *                                                     \r\nUSERID=anonymous       --- worked with anonymous                                               \r\nPASSWORD=anonymous     --- worked with anonymous                                              \r\nTARGET_SYS=testcase.boulder.ibm.com                                  \r\nTARGET_DSN=zosmftest.file.transfer   --- file name to be used at the target system.                                  \r\nWORK_DSN=xxxxxx.ZOSMF.FTP   -- workfile on our system to be used as it converts the file to be sent to a specific format                                        \r\nCC_FTP=03                                                            \r\nWORK_DSN_SIZE=500                                                    \r\nDIRECTORY=/toibm/mvs/                                                \r\nCASE=xxxxxx  --- case number                                                     \r\n//                                                                   "
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "sysplex management",
    "info": "Getting the error IZUS403W The channel path information on remote systems nameis not available. when trying to see the CF conenectivity view details. we need to do the following security setup across all systems in sysplex to resolve this error.\r\nSETROPTS GENERIC(REALM)\r\nRDEFINE REALM SAFDFLT APPLDATA('plex name')\r\nSETROPTS RACLIST(REALM) CLASSACT(REALM)\r\nSETROPTS RACLIST(REALM) REFRESH   "
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "concatenate",
    "info": "concatenate a new path to the existing envrionment variable.\r\nexport PATH=$PATH:/yugi/bin -- will concatenate the /yugi/bin locaiton the existing PATH values."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "capacity",
    "info": "CEC MSU and LPAR MSU\r\n/* REXX */                                                            \r\n   rct = c2d(storage(d2x(c2d(storage(d2x(c2d(storage(10, 4))+604), ,  \r\n     4))+228), 4))                                                    \r\n   say 'CEC MSU capacity='c2d(storage(d2x(rct+32), 4))';' ,           \r\n     'defined LPAR MSU capacity='c2d(storage(d2x(rct+28), 4))         \r\n                                                                      "
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "page dataset",
    "info": "PAGTOTL system parameter, which was specified at IPL. specifies the maximum no. of page datsets that can be defined to be active on the system. specified in IEASYSxx. if we have 8 .. then 1 plpa, 1 common, 5 local and 1 reserved."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "IRA200E AUXILIARY STORAGE SHORTAGE\r\n\r\nExplanation\r\n  The system detected a shortage of available slots in the auxiliary storage paging space. This message is issued when at least 70% of all available auxiliary storage slots in paging data sets and storage-class memory in the system are in use.\r\n  The system issues message IRA206I to identify address spaces with the largest amount of auxiliary storage and message IRA210E for address spaces that have the largest increase in the amount of allocated central plus auxiliary storage."
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware",
    "type": "migration",
    "info": "We can setup a PPRC when we have to move one DC storage to another and for tape migration from one DC to another we can use TCP/IP (grid to grid).."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "to find the port number\r\nnetstat -b | grep SSHD1 \r\nnetstat -b | grep TN3270"
  },
  {
    "Vendor": "ibm",
    "component/product": "education",
    "type": "website",
    "info": "look for \"IBM ACademic Initiative z/OS\" in youtube.."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "website",
    "info": "https://mediacenter.ibm.com/tag?tagid=z%2Fos%20management%20facility\r\nvideos to understand working with zosmf."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "reorg",
    "info": "CDS reorg\r\n1.\tLISTCAT the CDS, run EXAMINE job to check for any errors during INDEXTEST and DATATEST.\r\n2.\tTake 2 backup copies of the CDS and also a full volume backup.\r\n3.\tEnsure a quieter time and stop HSM on the system where I am performing the REORG.\r\n4.\tEXPORT the CDS to a PS file.\r\n5.\tIf a RESIZE of CDS is required, then create a bigger CDS dataset using IDCAMS DEFINE CLUSTER job. Before this I would rename the existing CDS to .OLD\r\n6.\tIMPORT with TEMPORARY option to import the CDS from the PS file in Step 4 to the newly created CDS dataset. This step would first delete the existing CDS during the job run.\r\n7.\tStart HSM on the system and run the checks like LISTCAT, HSM commands etc.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "long command",
    "info": "If you are typing a long command that will not fit on the command line, you can use the \\ (backslash) continuation character at the end of the first line. When you then press <Enter>, the command line is cleared so that you can continue typing."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "spawn error",
    "info": "if any time we get spawn error not able to create address space then \r\nBPXP005I A FORK OR SPAWN ERROR WAS ENCOUNTERED.\r\nRETURN CODE 00000070 REASON CODE 0B17001A\r\n  then issue the command Issue 'F BPXOINIT,SHUTDOWN=FORKINIT' to drain any unused BPXAS initiators.  This will cause new BPXAS initiators to be created during subsequent fork attempts.  This command can be issued repeatedly without harm to the system."
  },
  {
    "Vendor": "ibm",
    "component/product": "Python",
    "type": "install",
    "info": "https://www.ibm.com/docs/en/python-zos/3.10?topic=configuration-installing-configuring-pax-format"
  },
  {
    "Vendor": "ibm",
    "component/product": "node.js",
    "type": "install",
    "info": "https://www.ibm.com/docs/en/sdk-nodejs-zos/14.0?topic=configuring-installing-pax-edition"
  },
  {
    "Vendor": "ibm",
    "component/product": "node.js",
    "type": "version",
    "info": "issue the command  node to know the version installed."
  },
  {
    "Vendor": "ibm",
    "component/product": "python",
    "type": "version",
    "info": "issue the command python --version"
  },
  {
    "Vendor": "ibm",
    "component/product": "node.js",
    "type": "command",
    "info": ".exit command to quit the nodejs environment."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "cics update",
    "info": "Apply this fix and either recycle any monitored CICS regions, or use the GSVT (terminate) and GSVS (start) transactions to recycle SYSVIEW for CICS within each CICS region."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "proc step",
    "info": "JCL RESTART is an optional keyword parameter which is used to restart a job from a particular step\r\nthe syntax of RESTART parameter if you want to run from a particular step of a proc\r\nRESTART=JCL-STEP.PROC-NAME.PROC-STEP"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "hfs2zfs",
    "info": "tso %bpxwh2z\r\ntso %bpxwmigf\r\nin OMVS give bpxwmigf -source hfsfile -target zfsfile -mode rw -swap -srename hfsfilerename -trename targetrename (we name have the same name so we dont update the BPXPRXxx with the zFS file names)"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "unmount $(mount -q pathname)"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "mount -t zfs -f filesystem pathname"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "profile",
    "info": "we can create a .profile file in our folder so that update are made to that file for local to that user."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "alias",
    "info": "we can create aliases for command in our .profile and use them like alias ll = ls -l\r\nalias md = mkdir"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "/samples/copytree  sorucepath targetpath  to copy an entire directory to anotehr new directory but the target has to be empty."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "zfsadm grow -a 'file systme name' -size 0  -- to increase the file size."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "command",
    "info": "alter / datasetname -- we can do a lot of changes to vsam datasets."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "cp /dev/null filename to empty a file."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "CRON",
    "info": "CRON is a schedular that can be used to do some tasks. it also has to be started in /etc/rc \r\nCRON is a daemon.\r\nwe have the definition of CRON setup in /etc/cron -- had the definiton file queuedefs -- where we specify how the actiosn are to happen. Ex \r\n# queue definitions file                                                      \r\n# Queue name is a single character                                            \r\n# Default queue for at is `a', for batch is `b', and `c' for crontab          \r\n# #j is the max number of jobs to run simultaneously in that queue            \r\n# #n is the nice value for non-super user jobs in that queue                  \r\n# #w is the # of seconds to wait before rescheduling because of full queues.  \r\n# queue.4j2n30w                                                               \r\na.4j1n                                                                        \r\nb.2j2n90w                                                                     \r\nc.5j2n15w                                                                      "
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "CRON",
    "info": "we can have the schedule commands in /usr/spool/cron/crontabs/filename  -- \r\nex : \"1 0 * * * rm -Rf /tmp/tomcat* \" -- \"minute  hour  day_of_month  month  weekday  command\" --- it says on First minute of the oth hour any day any month any weekday issue the command \"rm -Rf /tmp/tomcat*\r\n\r\nCron log : /usr/spool/cron/log"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "zfsadm aggrinfo filesystem -long  to get more details of the file systems."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "automount",
    "info": "we can automount setup for any file systems. we can use auto.map to update what files systems have to be automounted when referred.\r\nwe need to start the autmount in /etc/rc -- /usr/sbin/automount\r\nupdate the file /etc/auto.master with the automount requirements. ex : /u       /etc/auto.map   -- this indicate that any entry in /u will have to check the /etc/auto.map to chekc what file system has to be mounted.\r\nupdate the file /etc/auto.map -- ex : the below statements will mount a file system OMVS.PLEX2.U.username.. if not available it would be created.\r\nname       *                                                   \r\ntype       zFS                                                 \r\nfilesystem OMVS.PLEX2.U.<uc_name>                              \r\nmode       rdwr                                                \r\nduration   nolimit                                             \r\ndelay      10                                                  \r\nsetuid     yes                                                 \r\nallocany   space(5,5) cyl storclas(scapphfs) mgmtclas(mcapphfs)\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "automount auto.master"
  },
  {
    "Vendor": "fdr",
    "component/product": "upstream",
    "type": "command",
    "info": "f upstream,reschedule."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "website",
    "info": "https://ibm.biz/zOSMFCommunity \r\nhttps://galaxy.ansible.com/ibm/ibm_zosmf\r\nhttps://ibm.biz/zOSMFGuildHome\r\nz/OSMF One Stop Hub\r\nz/OSMF Community\r\nz/OSMF Guild\r\nz/OSMF Marketplace\r\nz/OSMF blogs\r\nz/OSMF videos\r\nzTrial of z/OSMF\r\nIBM Knowledge Center: IBM z/OS Management Facility\r\nz/OSMF Value Proposition chart\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "command",
    "info": "TSO HSEND QUERY ACTIVE --- to check if any hsm related activity is happening.\r\n/F HSMx,QUERY ACTIVE\r\n/F HSMx,STOP\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "delete report",
    "info": "//SMFRPTR  EXEC PGM=ICETOOL                                       \r\n//RAWSMF   DD   DISP=SHR,DSN=LCL3M.SMF.SMF65.SORTED               \r\n//TEMPSMF  DD DSN=&&TEMPS,SPACE=(CYL,(100,100)),UNIT=3390,        \r\n//         DCB=(RECFM=VBS,LRECL=32000)                            \r\n//REPORT   DD DSN=&SMFRPT.,DISP=(,CATLG,DELETE),                  \r\n//         UNIT=3390,SPACE=(CYL,(2000,1000),RLSE),                \r\n//         DCB=(RECFM=FBS,LRECL=121,BLKSIZE=2420)                 \r\n//TOOLMSG  DD SYSOUT=*                                            \r\n//DFSMSG   DD SYSOUT=*                                            \r\n//TOOLIN   DD *                                                   \r\n   COPY FROM(RAWSMF) TO(TEMPSMF) USING(SMFI)                      \r\n   DISPLAY FROM(TEMPSMF) LIST(REPORT) -                           \r\n     TITLE('SMF Type-65 Records') DATE TIME PAGE -                \r\n     TITLE('Delete Types: IN-Insert DE- Delete UP-Update') -      \r\n     HEADER('Time') ON(7,4,TM1,E'99:99:99') - C'hh:mm:ss'         \r\n     HEADER('Date') ON(11,4,DT3,E'9999-999') - C'yyyy-ddd'        \r\n     HEADER('System') ON(15,4,CH) -                               \r\n     HEADER('Jobname') ON(51,8,CH) -                              \r\n     HEADER('Delete type') ON(23,2,CH) -                          \r\n      HEADER('Entry name') ON(121,44,CH) -                \r\n      HEADER('Catalog name') ON(76,44,CH) -               \r\n    BLANK                                                 \r\n /*                                                     "
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "delete report",
    "info": "//SMFICNTL DD *                                          \r\n   OPTION VLSHRT,VLSCMP                                   \r\n   INREC IFTHEN=(WHEN=(1,2,BI,LT,164),OVERLAY=(164:X))    \r\n /*                                                       \r\n   SORT FIELDS=(11,4,Y2Y,A)                               \r\n   SORT FIELDS=(121,44,CH,A)                              "
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "https://www.ibm.com/docs/en/zos-basic-skills?topic=1960s-what-is-virtual-storage"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "restart ",
    "info": "We tested the RESTART command here and it is working as designed.  We noticed that the DB.1 screen for job CA7PSRR shows INSERT-RMS: N which indicates CA 11 is not being used.   This has to be set to Y to use the format of the  RESTART command that you issued  in the case description.  The information sent for the DB.1 screen does not match the problem you are describing in this case  as the job sent does not have the CA 11 step inserted into it.  We would need documentation from you showing what is not working  based on what the case description is reporting as a problem/concern   "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "restart ",
    "info": "//ERRORS DD SYSOUT=*                     \r\n//SYSPRINT DD SYSOUT=*                   \r\n//SYSUDUMP DD SYSOUT=*                   \r\n//SYSIN DD *                             \r\n/LOGON                                   \r\nJCLOVRD,JOB=CTSTEST,SET=OFF              \r\n/LOGOFF                                  \r\n/*                                       "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "restart ",
    "info": " //STEP1 EXEC CA7BTI                                      \r\n //**********************************************         \r\n //*TEST JOB THAT RUNS CA7 COMAND IN BATCH                \r\n //**********************************************         \r\n //ERRORS DD SYSOUT=*                                     \r\n //SYSPRINT DD SYSOUT=*                                   \r\n //SYSUDUMP DD SYSOUT=*                                   \r\n //SYSIN DD *                                             \r\n /LOGON                                                   \r\n RESTART,JOB=7391,FORCECOMP=YES                           \r\n /LOGOFF                                                  \r\n /*                                                       "
  },
  {
    "Vendor": "ibm",
    "component/product": "zowe",
    "type": "website",
    "info": "https://developer.ibm.com/tutorials/zowe-step-by-step-tutorial/"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "alerts",
    "info": "security vulnerability alerts for z systems. SystemzSecurity <syszsec@us.ibm.com>\r\nTo access the data:\r\n1. From a web browser enter http://www.ibm.com/servers/resourcelink\r\n2. Select \"Sign in\" from this page and enter your IBM ID and password\r\n3. Select \"Problem solving\" on the left hand side\r\n4. Select \"Security alerts\" under the \"Software\" column\r\n\r\nOn the \"Security alerts\" page you will see links for the IBM Z security/integrity data followed by links for many security related notifications for various platforms.  Open the links for \"z/OS Security/Integrity Data\" or \"z/VM Security/Integrity Data\", as appropriate, to view the current list of relevant security information.\r\n\r\nTo receive notification that updates are available, you can Subscribe to this list via the \"Subscribe to this page\" link on the upper right hand side of the \"Security Alerts\" page.  Select the appropriate notification options on the subscription page and \"Submit\" the request.  For z/OS there is usually some form of update each month.  You will then receive notification that the hold data has been updated indicating a new APAR is available. Keep in mind no data is pushed to you, once notified of an update you will need to log on and retrieve the data.  Also, be aware that email notifications are not always reliable, due to various networking and security technologies, and are not a substitute for vigilant checking.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "command",
    "info": "racdert id(usird) list -- to list the certificates assinged to the user."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "ARTS – Automated Rerun Tracking systems : The command interfaces directly with CA WA Restart Option (CA11) if its installed"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "LSTP CA7PSRR : Command displays the steps for the job both restartable and non-restartable, and condition codes for jobs in failed state."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "PRE P,JOBNAME : Can be used for specifying the type of preprocessing to be performed on next run of job. P sets the job to Production processing, R sets for Rerun/Restart processing.\r\nFor eg PRE R,CA7PSRR,CC=0020 can be used to set the 1st step condition code to 0020."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "CANCEL : Delete the instance of job from ca7 queue : Cancel,job=ca7psrr,force=yes,reason=xxxxxx : Use force = yes to clear CMT – Catalog management table"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "Commands",
    "info": "LPDS,DSN=*INIT* : Displays the initialization parameters for CA7 task, eg: PF keys, libraries, batch terminals, mandatory reason parameter for cancelling job, etc."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "OINQ : Shows option table inquiry panel, useful for verifying the processing options currently in effect. "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "CINQ JOBNAME : \r\nDisplays CMT information for the job, shows the data that controls catalog maintenance and rerun execution.\r\nUseful for examining individual fields in CMT records, eg to determine which GDG was used in last execution of a job.\r\n"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "/PAGE+1\r\nUsed to move to next page/ scroll down ( use /PAGE-1 to move to previous page/scroll up)\r\nTo set PF keys for pageup & page down\r\n/PF07,M=(/page-1)\r\n/PF08,M=(/page+1)\r\nTo make changes permanent\r\n/prof,keys=save"
  },
  {
    "Vendor": "IBM",
    "component/product": "zowe",
    "type": "contacts",
    "info": "winchest@uk.ibm.com\r\njeffin.siby@ibm.com\r\n"
  },
  {
    "Vendor": "ibm ",
    "component/product": "ispf",
    "type": "command",
    "info": "swapbar \r\n/*REXX*/\r\nADDRESS ISPEXEC\r\n\"SELECT PGM(ISPTL) PARM(&ZPARM)\""
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "webbrowser",
    "info": "• z/OSMF uses session cookies to track which users are logged in from a specific browser. If you want to\r\nuse multiple z/OSMF servers from the same workstation, you might need to either launch another\r\nbrowser instance (as with Internet Explorer), or, configure another browser profile (as with Firefox). For\r\ninformation about creating Firefox profilesQ see the Mozilla web site: http://www.mozilla.com."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "language env.",
    "info": "To view the current MSGFILE de®nition on your system, you can use the following command: D CEE,ALL"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "mount",
    "info": "MOUNT FILESYSTEM('IZU.SIZUUSRD') TYPE(ZFS) MODE(RDWR)\r\nMOUNTPOINT('/global/zosmf') PARM('AGGRGROW') UNMOUNT\r\nWhen you use the IZUMKFS job to allocate and mount the user ®le system, the job uses your installation\r\ndefaults. If AUTOMOVE=Y is in effect for your installation, the following message might be displayed when\r\nthe system is shut down: \"BPXM048I BPXOINIT FILESYSTEM SHUTDOWN INCOMPLETE. 1 FILESYSTEM IS STILL OWNED BY THIS SYSTEM.\r\nTo remove this restriction, add a MOUNT statement with the UNMOUNT parameter to your BPXPRMxx\r\nmember, as shown in the previous MOUNT "
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "link",
    "info": "IZUG349I: The z/OSMF  Server home page can be accessed at    -- check teh IZUSVR task for a similar message to identify the logon page at your site.\r\n        : https://tech.mmm.com/zosmf                         "
  },
  {
    "Vendor": "Open systems",
    "component/product": "Linux",
    "type": "KVM",
    "info": "Kernel-based Virtual Machine (KVM) is an open source virtualization technology built into Linux®. Specifically, KVM lets you turn Linux into a hypervisor that allows a host machine to run multiple, isolated virtual environments called guests or virtual machines (VMs)."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "website",
    "info": "https://www.openmainframeproject.org/projects/zorow\r\nZOROW : the z/OS open Repository of workflows part of open mainframe project."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "command",
    "info": "JCLOVRD,JOB=jobnumber,SET=OFF"
  },
  {
    "Vendor": "IBM",
    "component/product": "DR",
    "type": "GDPS",
    "info": " GDPS : includes resource sharing, data-sharing, workload balancing and certain aspects of continuous availability which are provided by the Parallel Sysplex clustering technology, and data mirroring for data availability. It also supports logical Corruption protection support to protect aginst cyber attacks. \r\nLCP-M or LCP-GM -- provides the ability to secure point-in-time captures of critical data using either flashcopy or safeguarded copy."
  },
  {
    "Vendor": "EMC",
    "component/product": "DR",
    "type": "GDDR",
    "info": "EMC® Geographically Dispersed Disaster Restart (GDDR)."
  },
  {
    "Vendor": "IBM",
    "component/product": "DR",
    "type": "GDPS",
    "info": "GDPS/PPRC, which is based on IBM PPRC (Peer-to-Peer Remote Copy, synchronous) technology. Now called as METRO Mirror."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "MSTR",
    "info": "MSTJCL00 does not contain the START command that starts the primary job entry subsystem during master scheduler initialization. You can define and start the primary job entry subsystem using the PRIMARY parameter in the IEFSSNxx parmlib member."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "certificate",
    "info": "Certificate required by zOSMF, if we are not sharig RACF database then we need to create one certificate across each system:\r\nRACDCERT ID( IZUSVR ) GENCERT SUBJECTSDN(CN('SYSQ.MMM.COM') +          \r\n   O('IBM') OU('IZUDFLT')) WITHLABEL('SYSQzOSMFCert.IZUDFLT'), +  \r\n   SIGNWITH(CERTAUTH LABEL('SYSQzOSMFCA')) NOTAFTER(DATE(2025/12/31))  \r\n  \r\n RACDCERT ALTER(LABEL('SYSQzOSMFCert.IZUDFLT')) ID(IZUSVR) TRUST  \r\n\r\nRACDCERT ID( IZUSVR ) CONNECT (LABEL('SYSQzOSMFCert.IZUDFLT') +  \r\n   RING(IZUKeyring.IZUDFLT) DEFAULT)                                 \r\n\r\nRACDCERT ID( IZUSVR ) CONNECT (LABEL('SYSQzOSMFCA') +                   \r\n   RING(SYSQIZUKeyring.IZUDFLT) CERTAUTH)          \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "general",
    "type": "process",
    "info": "Describe in detail Service Provider’s approach to keeping software at N-1, including: \r\n(a)\tthe process Service Provider will follow to determine the suitability, urgency, and impact on State Street of IBM RSU and ISV versions; \r\na.\tFor IBM products we apply the RSU maintenance on a quarterly or half-yearly basis based on customer’s environment and based on the HIPERs that are part of RSU maintenance. WE order them through the shopz. Or we will enable Digicert handshake with ibm and the RSU maintenance is received automatically for the base product to our smpe environment when we run the receive job and no need to order from shopz.  The RSU maintenance  IBM products and other sub systems are performed separately following the same process. For some customer we also receive the PTFs and hold data monthly and review them.\r\nb.\tFor ISV products first we make note of the installed versions and tracks the maintenance release and update them every six months. We track version GA dates on the vendor website for latest version.  We monitor the EOS dates for each version and upgrade the products to ensure that we are at N-1/N and at supported levels.  Most of the times we would like to be at N-1 to avoid any issues with N upon their GA. We would also be checking for the latest features available in the newer version and if they would help our supporting environment we would proceed with the upgrades before the planned time.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "general",
    "type": "process",
    "info": "(b)\thow Service Provider will set priorities to achieve N-1 currency amongst competing projects and services. \r\na.\tCTS generally provides a dedicated teams to support customers so each team would plan the work every quarter on what would are the upgrade / maintenance that has to be completed and plan accordingly. As we are dedicated teams we don’t have to prioritize work wrt to other customers being supported.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "general",
    "type": "process",
    "info": "Please also describe Service Provider’s approach to \r\n(c)\tmaintaining currency for hardware assets            \r\na.\tFor the current hardware we ensure that Microcode is updated every quarter or when IBM recommends for any issues. It is done in co-ordination with the hardware maintenance support team in general IBM.\r\nb.\tOn an average every hardware version released by IBM is marketed and supported for 4yrs and an extended supported for 10yrs with follow on service. We recommend customer to upgrade start their hardware  upgrade plan 1yr into the GA of the hardware and be on the supported hardware at N or N-1 before the HW WDFM(hardware withdrawl from marketing) is announced.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "F BPXOINIT,SHUTDOWN=FORKINIT -- initiators that are provided by WLM for use on fork and spawn. These initiators time out after 30 minutes on their own, but you can end them by issuing:"
  },
  {
    "Vendor": "ibm",
    "component/product": "issue ",
    "type": "message",
    "info": "IEA602I ADDRESS SPACE CREATE FAILED.  MAXUSERS WOULD HAVE BEEN EXCEEDED . Check from console issuing D A,L if there many SSH* or FTPD* address spaces then issue the command F BPXOINIT,SHUTDOWN=FORKINIT. from the D A,L check for any JOBS names that are same and repeated many times and try and check what is causing so many jobs to be in the same name and cancel them."
  },
  {
    "Vendor": "ibm ",
    "component/product": "omvs",
    "type": "daemon",
    "info": "a long-running background process that answers requests for services. like long running STC's. ome examples include inetd , httpd , nfsd , sshd , named , and lpd "
  },
  {
    "Vendor": "ibm",
    "component/product": "zomsf",
    "type": "setup",
    "info": "We need to create a file system and mount it on /SYSQ/var/zsomf-- use the job IZUMKFS in SYS1.SAMPLIB"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "compare diff -R sourcedir targetdir"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "cron",
    "info": "To list the at jobs, issue at -l."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "cron",
    "info": "to schedule regular jobs, issue : crontab myjobs"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "access",
    "info": "FTP server JES access control\r\nz/OS provides a new System Authorization Facility (SAF) resource to control which z/OS users are permitted to use the z/OS FTP server's JES operating mode. By defining a SAF SERVAUTH class profile for the EZB.FTP.sysname.ftpdaemonname.ACCESS.JES resource, clients can control which z/OS user IDs or groups are permitted to enter the FILETYPE=JES operating mode. With the PTF for APAR PH42618, this function is available on z/OS V2.3 and later."
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "IPL",
    "info": "BCPii HWIREST support for commands from ISV and TSO/E REXX environments.\r\nz/OS BCPii delivers support that allows TSO/E REXX and ISV REXX applications the ability to issue commands previously not permitted for those environments. This includes the ability to activate and load LPARs, issue requests to the console, and more\r\nThis support is available on z/OS V2.4 and z/OS V2.5 with the corresponding PTFs for APAR OA61976. It also requires an IBM z15 server with SE 2.15.0 with MCL P46598.370, Bundle S38 or higher, and HMC 2.15.0 with MCL P46686.001, Bundle H25 or higher"
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "v2.5",
    "info": "Allows access to MVS sequentional or partitioned data sets from z/OS UNIX, that have certain formats."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "v2.5",
    "info": "Dynamic Change Master Catalog, yes, without an IPL"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "v2.5",
    "info": "ISPF Updates to ISPF in support of PDSE V2 member generations, and SUBMIT command to add an optional parameter SUBSYS.\r\nAccess Method Services - IDCAMS - DELETE MASK has two new options TEST and EXCLUDE"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": " Application Transparent Transport Layer Security (AT-TLS) creates a secure session on behalf of an application.                             \r\n                                                                         \r\n Instead of implementing TLS in every application that requires a secure connection, AT-TLS provides encryption and decryption of data based on  policy statements that are coded in the Policy Agent.                                                                         \r\n - The application sends and receives cleartext (unencrypted data) as usual while AT-TLS encrypts and decrypts data at the TCP transport layer.                                                                  \r\n                                                                         "
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "STEPS:\r\n1) Use obey command to activate TCPCONFIG TTLS feature                 \r\n2) Request Mory to create Profiles:                                    \r\n   - FACILITY : EZB.<system_name>.INITSTACK with UACC(NONE)            \r\n   - PE EZB.<system_name>.INITSTACK CLASS(FACILITY) ID(*) ACC(R)       \r\n   - SETR RACLIST(FACILITY) REFRESH                                    \r\n                                                                       \r\n3) Create Policies or Copy Policies from TCPIP sample directory        \r\n4) Create PAGENT Proc                                                  \r\n5) Configure your FTP Server to use AT-TLS or create separate FTP Proc \r\n   with alternative Port #                                             \r\n6) Use Obey command to activate TN3270 configuration                   \r\n7) Use the commands above to verify that connections are               \r\n   established under AT-TLS Configurations                             \r\n8) If everything works then request for System IPL and make sure       \r\n   everything is up without making any further changes                 "
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "We would have to use zOSMF Network feature to create AT-TLS routines and then create an address space : PAGENT on SYSTEM and which runs the policies AT-TLS.\r\n\r\nThen you would have to create an address space for FTP: FTPTEST and then point to FTP Profile which would use different Port 2121 (Example)\r\n\r\nWe would have to create a Self Signed Certificate though in RACF and which would have to be used in Policies.\r\nWe would have to use zOSMF Network feature to create AT-TLS routines and then create an address space : PAGENT on SYST and which runs the policies AT-TLS.\r\n\r\nThen you would have to create an address space for FTP: FTPTEST and then point to FTP Profile which would use different Port 2121 (Example)\r\n\r\nWe would have to create a Self Signed Certificate though in RACF and which would have to be used in Policies.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "3)  AT-TLS Policies                                              \r\n  - This can be created using zOSMF Network Assistant or         \r\n    you can copy the following samples from USS Environment:     \r\n    - /usr/lpp/tcpip/samples/pagent_TTLS.conf                    \r\n      - You can copy to /etc and then use your PAGENT Proc       \r\n        to assign the name using .env file in USS.               \r\n      - The sample proc includes FTP , TN3270 and CICS Policies  \r\n      - To use the above sample policy, the changes required:    \r\n        - Port address for FTP/TN3270/CICS                       \r\n        - keyring name as it exists in the system                \r\n                                                                 \r\n    Existing Example: /SYST/etc/syst.tcpip.pol                   \r\n                                                                 "
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "ICH408I USER(USERID ) GROUP(D#826380) NAME(username )     \r\n  EZB.PAGENT.SYST.INET.TTLS CL(SERVAUTH)                                 \r\n  INSUFFICIENT ACCESS AUTHORITY                                           \r\n  FROM EZB.PAGENT.*.*.TTLS (G)                                            \r\n  ACCESS INTENT(READ   )  ACCESS ALLOWED(NONE   )      \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "define PAGENT taks to STARTED groupd and assign the same userid starting the TCPIP stc. we also need to have RESOLVER proc enabled as it is a prereq for PAGENT."
  },
  {
    "Vendor": "ibm",
    "component/product": "zoua",
    "type": "",
    "info": "ibm z open utilities for automation."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "v2.5",
    "info": "The TN3270E migration action is one of them in the workflow (see pictures below), it mentions that “As of z/OS V2R5, TN3270E support for using IBM System SSL for TLS/SSL is removed. You must configure the TN3270E server to use AT-TLS policies.”. With the health check as a means to verify if we are using native TLS/SSL support. I only showed you the health checker’s output to indicate we definitely need to take some actions before we can upgrade to z/OS 2.5 on SYSD (other LPARs are not using TN3270E). There is no other way than to move forward now, it might not take a lot of time to configure the Communication Server with AT-TLS policies. \r\nMy main concern is with the RUCSA usage in my first migration action email to you, we either need to identify, then upgrade/change the software that is (or are) using user key common storage, or may have to pay extra money to IBM to continue using such feature (which I’m not sure if 3M is willing to pay). It is critical for us to identify these RUCSA software on US and EU production LPARs ASAP, through extracting SMF 30 records of these LPARs, let me know if you need me to do that."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "Use the z/OS® UNIX pasearch command to query information from the z/OS UNIX Policy Agent. The command is issued from the UNIX System Services shell.\r\npasearch "
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "command",
    "info": "TSO NETSTAT TTLS GROUP DETAIL -- listing the TTLS groups."
  },
  {
    "Vendor": "ibm",
    "component/product": "ipcs",
    "type": "ispf invocation",
    "info": "Starting IPCS without customized access\r\nIf access to IPCS has not been customized, you can use the following procedure:\r\n1. Logon to TSO/E.\r\n2. (Optional) — Unless you want to use IPCS in line mode, you can skip this step. To start IPCS in line\r\nmode, do the following:\r\na. Add SYS1.SBLSCLI0 to the SYSPROC concatenation:\r\nALTLIB ACTIVATE APPLICATION(CLIST) DA('SYS1.SBLSCLI0')\r\nb. Enter the IPCS command:\r\nIPCS\r\nAt this point, you can enter IPCS commands in line mode. You do not need to proceed to the next\r\nstep unless you want to start the IPCS dialog from IPCS line mode.\r\n3. Start the ISPF dialog:\r\nISPF\r\n4. Choose the TSO/E commands option from the ISPF menu.\r\n5. Start the IPCS dialog by entering the following at the prompt:\r\nEX 'SYS1.SBLSCLI0(BLSCLIBD)'\r\n\r\nSelect OPTION 0 and update the dump dataset with DSNAME('IPCS.SYSF.D230130.T102848.CONSOLE.S00001 ')"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "4) Pagent Proc: SYS1.SEZAINST(PAGENT)                               \r\n------------                                                        \r\n                                                                    \r\n  - You would have to setup pagent.env and what it needs to be      \r\n    in env file is included in pagent proc above and there is       \r\n    an example within.                                              \r\n    Existing Example: /SYST/etc/pagent.env                          \r\n                                                                    \r\nPAGENT Commands:                                                   \r\n---------------                                                    \r\n- F PAGENT,QUERY                                                   \r\n- F PAGENT,REFRESH                                                 \r\n- F PAGENT,UPDATE                                                  \r\n- You can Google for PAGENT Commands to get additional commands    \r\n                                                                   "
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "5) AT-TLS FTP Server:                                                \r\n   ------------------                                                \r\n                                                                     \r\nPlease use the Existing example and note of the SYSTCPD and STDENV   \r\nDD Statements under SYST System:                                     \r\n- SYS1.TCPPARMS(SSLTRACE) - Use as-is                                \r\n- SYS1.TCPPARMS(FTPDATA1) - Change the Keyring name and Port         \r\n                                                                     "
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "6) AT-TLS TN3270 Server:                                            \r\n---------------------                                               \r\n                                                                    \r\nPlease see the following example on SYST System:                    \r\n- TCPIP.SYST.TN3270 : Use the Port configuration which includes     \r\n                      \"Conntype secure\"                             \r\n- You can copy to your TCPIP.<system_name>.TN3270 as alternative    \r\n  port and once tested then you can replace the Primary port with   \r\n  Conntype secure:                                                  \r\n                                                                    "
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "1.        TSO NETSTAT TTLS GROUP DETAIL\r\n2.        TSO NETSTAT TTLS CONN 391DB DETAIL  You get CONN xxxx # from command:\r\na.        D TCPIP,TN3270,CONN\r\n3.        Operator Command: D TCPIP,TN3270,CONN\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "keyring",
    "info": "We can group certificates for any purpose and that groups are generally called as KEYRINGS"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "There are few things we have to remember in Mocha or PCOMM or any other Applications which uses AT-TLS and which is that the Hostname would have to match with what is in the certificate.\r\n\r\nIf we use IP address to connect and use ‘verify certificate’ then it will not work and we have to communicate to the Team that they would have to use hostname instead.\r\n\r\nThe reason I address it is because we have tendency to use IP address to connect to z/OS Host and this one would not work in z/OS v2r5 as well and you can certainly do that test too using AT-TLS Port before moving into production. "
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "ipl- Address space",
    "info": "his series of articles is information about z/OS Address Spaces. First let's explain how they are created. In order to IPL a z/OS system a number of key elements need to defined/created. I'm not going to cover how the Sysres volume is created, just that ICKDSF utility is responsible for creating the IPL Text. The Systems Programmer or Operator logs on to the HMC, selects the LPAR (toggles it unlocked) and then clicks on Recovery and selects Reset Clear. Then the 8 bytes of Loadparm data is specified; first 1-4 is the Unit address of the IODF, the next 2 characters are the Load member suffix, then the IMSI single character (how much do you want to see of the messages during the IPL process, 'M' for all messages, a '.' or blank if you want to see none), and the final character identifies the IEANUC0x suffix, where IEANUC01 is the default. The Operator enters the 4 characters of the Sysres Unit Address and clicks on Load and enters the Password to acknowledge the start of the IPL process. The initial Console messages can be located by clicking on Daily and System Messages. In Part 2 I will discuss how the Master Address Space is created and how the Common System information is built and located and the importance of the Segment table"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "ipl- Address space",
    "info": "The IPL process must find the IODF In the Unit Address Volume specified, or the System enters a B1 Wait State. ReIPL. If the IODF is found and the Load member cannot be found the System enters an 88 Wait State. A ReIPL is required. Once the Load member is located either in SYSn.IPLPARM (where n is 0-9) or SYS1.PARMLIB, then the options specified in the Load member are followed. Once the IPL gets underway \r\nthe first Address Space that is created is the MASTER, Program IEEMB860 creates this and the JCL is found either in the MSTJCLxx in Parmlib or as a Load module in SYS1.Linklib. There are 3 Common Areas that are created at this time, the System Queue Areas (SQA/ESQA) where Address Space Ids are found, the Link Pack Areas (PLPA/EPLPA) for SYS1.Lpalib and any datasets in the LPALSTxx member providing CLPA has been specified in the SYSPARM member and the Common Service Areas (CSA/ECSA). In each case these are 24bit and 31bit areas. \r\nAs these 3 areas are being created the CSA/ECSA 24bit/31bit must end on a Megabyte boundary, this occurs no matter what is specified. So for example below the Line, if the allocation goes down over the megabyte by only a few bytes the CSA will take the rest of the megabyte."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "ipl- Address space",
    "info": "So we know that the CSA/ECSA both spill down (24bit) and up (31bit) to the next megabyte boundary. So why does it do this? The answer is because of the Segment Table. When an Address Space is created it is copied from the MASTER in order to ensure that this new Address Space has the common areas (SQA/ESQA, PLPA/EPLPA, CSA/ECSA) in the same location. In addition a Segment Table is also created for each Address Space, which is divided up into 1meg chunks. This Segment Table is 2gig is size. Whenever a Virtual Address is reference from the Program Status Word (PSW), the Real Address is located by using the Segment Table as an index to locate the entry in the Page Frame Table and this locates the Real Address. This is handled by the Real Storage Manager. This Page/Frame of Real Storage can be either in Storage or potentially paged out to the Local Page Dataset. This conversion process is called Dynamic Address Translation or DAT processing. DAT processing occurs on this Virtual Address providing Bit 5 in the PSW is turned on to allow for it. The current Segment Table is located due to Control Register 1 pointing to it. In part 4 of this discussion I will take you thru an example of the DAT Process."
  },
  {
    "Vendor": "Open systems",
    "component/product": "virtualization",
    "type": "virtualization",
    "info": "multiple addresses in one OS -> virtual instance (LPAR) -> clustering (parallel sysplex) -> cloud -> container (docker, K8S)"
  },
  {
    "Vendor": "Open systems",
    "component/product": "virtualization",
    "type": "virtualization",
    "info": ""
  },
  {
    "Vendor": "Open systems",
    "component/product": "virtualization",
    "type": "virtualization",
    "info": ""
  },
  {
    "Vendor": "Open systems",
    "component/product": "virtualization",
    "type": "virtualization",
    "info": "https://mainframe2cloud.com/Virtualization-Journey-Mainframe-Cloud/"
  },
  {
    "Vendor": "ibm",
    "component/product": "dump",
    "type": "dump member",
    "info": "SYS1.PARMLIB(IEADMCxx)\r\nJOBNAME=(TCPIP,OMPROUTE,NET),                             \r\nSDATA=(ALLNUC,SQA,LSQA,SWA,TRT,RGN,SUM,LPA,CSA,PSA,GRSQ) \r\n \r\nThen we can issue the command DUMP COMM=(*issue name*),PARMLIB=xx"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "maintenance",
    "info": "CIRATS stands for Compliance, Issue, Risk and APAR Tracking System where APAR means Authorised Program Analysis Report.\r\nRSU : Recommended service units. Released by IBM every month for reach product."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "OMPROute",
    "info": "EZZ9308E UNRESPONSIVE NAME SERVER DETECTED AT IP ADDRESS : Check if OMPROUTE is active or not and start the task."
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd ",
    "type": "delete",
    "info": "to delete a vsam dataset that has an expiration date set.. DELETE (/) PURGE"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "When I tried FTP/TLS from SYSXYZ client to SYSXYZ server (both AT-TLS), it failed. After I changed the AT-TLS policy to use different TTLSGroupAction names for FTP client and server, it worked, so probably we can’t share the same TTLSGroupAction configuration item between the FTP client and server in AT-TLS, you might want to change your policy before rolling it out to other LPARs.\r\n\r\nThis is how mine look like now (maybe I should have used the name gAct1~FTPTLS-Clieint instead of gAct~FTPTLS-Server):\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "identify",
    "info": "Functional Registry : helps to idenitify data about funcitons are being used.\r\nIBM Function Registry for z/OS provides a simple way to find and enable functions on a z/OS system. A function is anything provided by IBM or a vendor within any z/OS product (such as, for IBM, XCF or CICS). For example, a function registered with the IBM Function Registry for z/OS could be representing a particular service or an operational mode a product offers."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "Many programs and users are competing for the use of the system. So how does z/OS® preserves the integrity of each user's work? One technique is through the use of multiple storage protect keys.\r\n\r\nUnder z/OS, the information in central storage is protected from unauthorized use by means of multiple storage protect keys. A control field in storage called a key is associated with each 4K frame of central storage.\r\n\r\nWhen a request is made to modify the contents of a central storage location, the key associated with the request is compared to the storage protect key. If the keys match or the program is executing in key 0, the request is satisfied. If the key associated with the request does not match the storage key, the system rejects the request and issues a program exception interruption.\r\n\r\nhttps://www.ibm.com/docs/en/zos-basic-skills?topic=storage-what-is-protection"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "cfrm",
    "info": "Your understanding is correct. If you have activated a policy using CF216T and CF217T and CF116T and CF117T instead of activating CFRMPOL3 that removed CF116T and CF117T, the authority data in CFRM CDS for CFs CF116T and CF117T would remain the same authority data that was in CFs themselves. Then, when activating CFRMPOL1 you would not experience the TAKEOVER PROHIBITED issue. I understand you have activated CFRMPOL2 with all 4 CFs before activating CFRMPOL3. So if you activate CFRMPOL2 and it remains the current policy until your CFRMPOL1 is activated, you will have no issues with the CFs.  Or if you activate any CFRM policy other than CFRMPOL2 that contains definition for all 4 CFs, executes reallocation and then activates CFRMPOL1, you will be successful. "
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "cfrm",
    "info": "Authority data is used to establish CF ownership by a sysplex; it has a value containing the sysplex name and a timestamp and is stored in the CFRM couple data set as well as in the CF. When you started CFRMPOL3 to remove both CF116T and CF117T from active CFRM policy, authority data was removed from CFRM CDS for those CFs. However, since the CFs were still activated, the CFs themselves had their last authority data as non-zero. Then, when CFRMPOL1 was started, authority data in CF and in CFRM CDS were compared and there was a mismatch, so message IXC518I with TAKEOVER PROHIBITED was received, showing that those CFs were owned by another sysplex.  "
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "cfrm",
    "info": "In order to avoid this in future tests, you should either not start a policy that removes the production CFs or use CFRMTAKEOVERCF(PROMPT) in COUPLExx so operator is prompted and is allowed to authorize the sysplex to regain CF ownership when DR test is over. With any of the above actions, you won't need to shutdown the CFs in order to gain their ownership again. "
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "cfrm",
    "info": "IXC518I SYSTEM SYST NOT USING 615.  TAKEOVER PROHIBITED.\r\n\r\nTAKEOVER PROHIBITED means the owner authority stored in the coupling facility does not match the authority in the CFRM CDS and the\r\n\r\nCOUPLExx parmlib member indicates that the operator should not be prompted to use the coupling facility for an authority mismatch. \r\n\r\n When the first LPAR makes connection to the CF LPAR, it will read the ownership info from the CF (i.e TOD and plex name) and compare it with the data in the currenct CFRM CDS. When the info returned from the CF is non-zero (i.e implies it was OWNED by some plex already) and CFRMTAKEOVERCF(PROMPT) is not found in the COUPLExx member, then this CF cannot be used by this plex. Without the CFRMTAKEOVERCF(PROMPT) specified in your COUPLExx, the default action is to deny takeover which results to the IXC518I as you encountered.\r\n\r\n Once you deactivate/ activate the CF LPAR again, that ownership TOD in the CF which was previously matching what was in the old CFRM CDS is cleared up and CF ownership could be claimed. \r\n\r\n You will need to add CFTAKEOVERCF(PROMPT) in your COUPLExx so operator will be prompted to allow the CF to be taken over when you do a DR test with the same CFs from production."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "ipl- Address space",
    "info": "Let's discuss the Dynamic Address Translation process. Recall there is a Segment Table per Address Space.  There is one Program Status Word (PSW). The 31 Bit PSW is 8 bytes in length. The address of the next instruction occupies the second 4 bytes of the PSW. So let's assume that the next Virtual address is : 002FE110.  The 002 is the Index into the Segment Table, the FE is the pointer into the Page Frame table and the 110 is the Displacement. So recall that the Segment Table is broken up into 1 meg chunks. CR1 points to the current Segment Table for the current Address Space. DAT takes the 002 and finds that in the 3rd entry. 000, 001, 002...7FF. There is one Page Frame table for each Segment Table entry. The next part of the Virtual Address is FE, this is the displacement entry down this table from 00, 01, 02...FE, FF. Entries in this table are 4K each. So DAT counts down to entry number FE and finds address 0FCFD. This is a 4k Frame so the full address is 0FCFD000. \r\nDat returns to the PSW and takes the Displacement 110 and adds that to the Frame address 0FCFD000 this gives us Real Storage Address of 0FCFD110. To complete the final part of this article is how to discover where the CSA ends and the size of the 24bit Private Area"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "ipl- Address space",
    "info": "IEFBR14 is a nothing utility supplied by IBM. It doesn't perform any function and has only 2 instructions, a clearing of Register 15 and branch on Register 14. However as it does nothing it can be used safely for the following purpose. An Abend Code S822 is returned when the specified region size is not available. So in this you can find out the \r\nsize of the 24bit Private Area and therefore how the Common areas are designated, to make them more tangible for you.\r\n//JOBCARD...\r\n//STEP1 EXEC PGM=IEFBR14,REGION=6M \r\nSpecify this region size in a Job, and you should get a return code 0f 0 which says that this region size is available. Now run again with 8M and again you should get return code 0. Now try 9m and you should receive a return code of S822, if not try 10M. This will surely give you S822, keep going 12M, 14M and 16M. Every time you will receive a Return code \r\nof S822. Now try 17M and you will receive a Return code of 0. So z/OS will give you 17M but not 16M and therein lies the Structure of an Address Space. You cannot allocate any Private Area size in 24bit that includes the Common Areas. I like to teach trainee Mainframe Systems Programmers this, in order for them to understand how an Address Space is defined and built from the Master and how the Segment table for each Address Space has the system areas defined in the same place."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AUTLOG",
    "info": "mention AUTLOG keyword in TCPIP PROFILE file so the child process started."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "CFRM",
    "info": "If the policy that is active before you activate a policy with all 4CFs already contains CFs CF116T and CF117T, their authority data will match the authority data in the CFRM couple data set. However if before the policy with all 4 CFs, you activate a policy removing CFs CF116T and CF117T, the authority data will be zeroed from the CFRM couple data set and then authority data will not match. "
  },
  {
    "Vendor": "ibm",
    "component/product": "modernization",
    "type": "GIT",
    "info": "Hybrid Git Experience:\r\nFor Endevor users wanting to introduce a Git experience without the risks of migrating code and disrupting existing workflows, Bridge for Git is the solution. It accomplishes this by synchronizing a ‘source control mirror’ on the Git enterprise server to enable both Git access and native-Endevor access at the same time (see Bridge for Git whitepaper for a thorough explanation). A robust VS Code extension for Bridge for Git is also available.\r\n\r\nhttps://medium.com/modern-mainframe/ca-endevor/home"
  },
  {
    "Vendor": "ibm",
    "component/product": "modernization",
    "type": "GIT",
    "info": "GIT native approach\r\nFor Git-native AppDev, Broadcom introduced Team Build, a super-lightweight, processor-based build engine that enables teams to collaborate natively using enterprise Git repositories while building on the z/OS platform. Team Build is independent of Endevor and can be used for any build and ship needs for z/OS. A simple and easy-to-use tool, it converts build logic in JCL and makes it maintainable off-platform with the most popular scripting language, JavaScript. Here’s an introduction of Team Build for Endevor users."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "jobdef",
    "info": "If you specify DUPL_JOB=DELAY on the JOBDEF statement or DUPL_JOB=DELAY is the default, no two batch jobs with the same name will execute at the same time in the MAS, except when DUPL_JOB=NODELAY is specified on the JOBCLASS(x) statement.\r\nIf you specify DUPL_JOB=NODELAY on the JOBDEF statement, jobs with the same name can run at the same time, no matter what DUPL_JOB= is specified on the JOBCLASS(x) statement."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "jobclass",
    "info": "/d wlm,schenv=xx"
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "command",
    "info": "/d wlm,schenv=xx -- listing the scheduling environment\r\n/F WLM,RESOURCE=resource_name,setting (setting is ON/OFF/RESET)"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "history",
    "info": "JES implemented early “client server”\r\n• RJE/RJP – Remote Job Entry\r\n• Allows jobs from client computers to be run on MVT and get\r\noutput back (1967)\r\n• Uses BSC and SNA protocols"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "tasks",
    "info": "JES2 : Local JES2 requests Input Converter BSC NJE SNA NJE\r\nJES2AUX : Remote buffer retrieval Owns Resource\r\nJES2MON : Jes2 Monitor\r\nJESXCF  : XCF interface\r\nUser : interpretor input extended status\r\nPrinterFSS : FSS printer\r\nNETSERV : NJE over TCP/IP\r\nJES2CI : Converter interpretor"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "command",
    "info": "$D jobclass(x),LONG -- to list all the parms."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "init",
    "info": "$HASP373 A93LNZZA STARTED - WLM INIT  - SRVCLASS BATCH    - SYS SYST\r\n$HASP373 A93LNZZA STARTED - INIT 14   - CLASS Q        - SYS SYSQ \r\n\r\nIf we have MODE as JES2 and also specified SCHENV=xxxxx then the job will go into AWAITING status and we need to manually issue the /$S jobnumber command to start the jobs execution.\r\n\r\nWLM class init are not specified in the JES2 parm. WLM will start new initiators, as needed, to meet the performance goals of the work.\r\n\r\nIf no SCHENV is specfied then WLM will execute the jobs on any of the systems in XEQMEMBER\r\nif the mode is JES then any no. of jobs submitted to class will only execute on the submitted system.\r\n\r\n$P XEQ -- stops execution of jobs in any class\r\nwe can either issue /$S XEQ to release all job classes or we can issue the command /$S JOBxxxxx to start a specific job.\r\n\r\nThe $P XEQ command causes all WLM initiators on that system to be “flagged” to terminate. The $S XEQ command enables WLM to start new initiators (without needing to wait for the old initiators to end)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "topsecret",
    "type": "command",
    "info": "TSS PE(IT010481) DSN(I010481) ACC(ALL). to permit dataset access to create, update, read to userid in PE and HLQ in DSN.\r\nThe access levels for TSS commands for datasets are read,update,create,scratch. ALL doesn't work to give all accesses."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "ispf invocation",
    "info": "ex ’SYS1.SBLSCLI0(IWMARIN0)’ -- to invoke ISPF wlm panels."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "command",
    "info": "SETXCF COUPLE,TYPE=WLM,ACOUPLE=(SYS1.WLMP,SYS001) : Make SYS1.WLMP the alternate using the command:\r\nSETXCF COUPLE,TYPE=WLM,PSWITCH :  Switch SYS1.WLMP to primary using the command:\r\nSETXCF COUPLE,TYPE=WLM,ACOUPLE=(SYS1.WLMA,SYS002) : \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "security",
    "info": "RDEFINE FACILITY MVSADMIN.WLM.POLICY UACC(NONE) NOTIFY(user) -- class to restrict access to wlm."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "training",
    "info": "https://www.ibm.com/training/search?query=IBM%20Z"
  },
  {
    "Vendor": "ibm",
    "component/product": "cdp",
    "type": "regex",
    "info": "regex filter\r\nConstruct a regular expression        \r\nConstruct the following regular expression to match information starting with $HASP373 and containing the task name SMF30 \"$HASP373 SMF30 STARTED - INIT A - CLASS A\"\r\n\r\n^\\$HASP373.+SMF30.+$\r\n\r\nYou can verify it with online regular expression tester. regex101.com "
  },
  {
    "Vendor": "ibm",
    "component/product": "zcx",
    "type": "",
    "info": "IBM zOS container externsions"
  },
  {
    "Vendor": "ibm",
    "component/product": "zcx",
    "type": "theory",
    "info": "it will work with z14 or later with Container Hosting foundation feature enabled. Featuer code 0104.\r\nDeploy linux on  z software components as docker container in a z/OS system, in direct support of z/OS worklaods.\r\nNo requirement of seperate linux server.\r\nzCX instance runs in a seperate address space . Docker container running inside a zCx instance have noway to access teh memory or data contained in any other address space running.\r\nzcx workloads are zIIP eligible.\r\nzCX - A turn key virtual docker server software appliance.\r\n   prepackaged linux docker appliance.\r\n   Supports deployment of any software available as a docker image for linux on z\r\n   No direct access to underlying linux kerner."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "theory",
    "info": "SYS1.SAMPLIB(IWMINSTL) -- is the job to install a serivce definition if not doing with panels."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "zOS V2.5 -- planning checks",
    "info": "1. Are all the ISV and IBM products upgraded to z/OS V2.5 compatible versions?\r\n2. Is z/OSMF configured and in use? we would need this as z/OS would be delvierd as Workflow install method? \r\n3. Have we converted all the HFS file systems to zFS systems?\r\n4. HAve you checked the usage of UCSA on the systems and addressed to remove its usage or buy the RUCSA feature?\r\n5. AT-TLS would be requried for z/OS V2.5 are your systems updated to use AT-TLS?\r\n6. Infoprint Server intends to enable dynamic configuration as the default behavior. This change in default\r\nbehavior will be mandatory and not reversible? \r\n7. z/OS V2.4 is the last release to support the ISPF Workstation Agent (WSA), also known as the ISPF\r\nClient/Server Componen\r\n8. If using JES3 then it would not be supported after z/OS V2.5. Are you running JES3?\r\n9. Only z/OS V2.3 or V2.4 and z/OS V2.5 can be in sysplex. Co-exsistence / Fallback / upgrade can be done between these 3 versons only. are any of your systems running z/OS V2.2 or older?\r\n10. z/OS V2.5 is supported on z13s and later machines. Are you running zMachine older than z13S?"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "planning  ",
    "info": "https://www.newera.com/INFO/090821_V2R5_Part_1.pdf"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "website",
    "info": "http://www.ibm.com/software/support/lifecycle/   --- Lifecycle"
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "policy update",
    "info": "1. Logon on to WLM panels and select option2 to open the policy using couple dataset.\r\n2. select 1 - policy and then option 3 to copy the policy that you would be working with.\r\n3. You can also select option SAVE in FILE menu in the first panel and Copy the policy to a dataset.\r\n4. You can select the new POLICY that you create/copied and updated the required. \r\n5. selected option 10 : scheduling environment\r\n6. line commad 1 to create a new scheduling environment\r\n7. provided a name as SYSTSYSQ\r\n8. line command A to add resources and selected the resources from available list.\r\n9. updated the status as ON for the resources\r\n10. from utilities option install the updated WLM policy -- new definition is installed into the couple dataset.\r\n11. from utilities option activate the updated wlm policy\r\n12. from SDSF issued the command D WLM,SCHENV=SYSTSYSQ,SYSTEM\r\n13. If we are activating new resources when creating a new Scheduling Environments then we need to set the STATUS of the resource as ON to make the scheduling environment available on the system. It has to be done on each of the systems in the sysplex where the SCHENV is required."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "website",
    "info": "basics of Mainframe\r\nhttps://www.ibm.com/docs/en/zos-basic-skills?topic=zos-concepts"
  },
  {
    "Vendor": "Open systems",
    "component/product": "containers",
    "type": "theory",
    "info": "a form of OS-virtualization has risen that we refer to as containerization technology\r\nVirtual System -- BASE system --> Hypervisor --> Guest OS --> APP\r\nContainer      -- Base system --> Host operationg system -- > Container Runtime --> App\r\n\r\nDocker company pioneered in the concept of Container runtime and the concept of container format (image).. so mostly we call docker containerizaiton / docker imager and so on. Both together are called as OCI.\r\n\r\nThe Runtime Specification dealing with how to unpack a downloaded image into a runtime filesystem bundle that any OCI-compliant container runtime can run.\r\nThe Image Specification that describes how the content is structured, what immutable layers exist, where to find them and how to unpack them, how the application is started and what arguments and environment variables are used, to name a few."
  },
  {
    "Vendor": "ibm",
    "component/product": "hmc",
    "type": "setup",
    "info": "to make chpid offline for CF lpars between 2 systems:\r\nIssue the command /D CF on the system and make note of the CHPID that it is connected to for another CF lpar.\r\nLogon to HMC \r\nselect the MAINFRAME system under SYSTEMS MANAGEMENT\r\nselect the lpar(image) for CF\r\ngo to operating system messages\r\nissue the command D CHPID ALL -- to check the status of CHPID\r\nthen to bring it online or offline  CON xx ONL / CON xx OFF\r\n\r\nwe can issue the HELP command in OPERATING SYSTEM MESSAGE panel to check the commands that we can issue for the CF LPAR."
  },
  {
    "Vendor": "ibm",
    "component/product": "hmc",
    "type": "setup",
    "info": "to change the CF TIMER status  (Coordinated timing network)\r\nSelect the SYSTEMS MANAGEMENT\r\nselect Manage Systems TIme\r\nselect Modify timer allocation\r\nselect the box and set it to CTP or STP\r\nselect APPLY after the changes are done.\r\ncheck the pictorial representation to understand the status."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "resolver",
    "info": "in BPXPRMxx RESOLVER_PROC(procname|DEFAULT|NONE)\r\nSpecifies how the resolver address space is processed during z/OS UNIX initialization. The resolver is used by TCP/IP applications for name-to-address or address-to-name resolution. In order to create a resolver address space, a system must be configured with an AF_INET or AF_INET6 domain.\r\nDEFAULT Causes an address space named RESOLVER to start, using the system default procedure of IEESYSAS. The address space is started with SUB=MSTR so that it runs under the MASTER address space instead of the JES address space.\r\nNONE: Specifies that no address space is to be started. If you are using z/OS Communications Server IP, the resolver must be started before TCP/IP can be started. TCP/IP does not initialize until the resolver address space is started.\r\nprocname : The name of the address space for the resolver and the procedure member name in the appropriate proclib. procname is one to eight characters long. The procedure must reside in a data set that is specified by the MSTJCLxx parmlib member's IEFPDSI DD card specification."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "setup",
    "info": "JES2 interface for FTP using PUT and GET command to submit and retreive the output of jobs.\r\n\r\nAPAR PH42618, available for z/OS 2.3 to 2.5, introduces new SERVAUTH class resource EZB.FTP.sysname.ftpdaemonname.ACCESS.JES to control which users are permitted to use FTP in JES mode. When the SERVAUTH class is active and a profile is defined for this resource, only users with READ access to the profile are allowed to use JES mode."
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "syslog",
    "info": "tcrrrrrrr sysname yyddd hh:mm:ss.th ident msgflags < message >\r\n\r\nReading a syslog:\r\nt - The first character indicates the record type: \r\n     D - Data line of a multiple-line message; this line may be the last line of the message. \r\n     E - End line or data-end line of a multiple-line message. \r\n     L - Label line of a multiple-line message. \r\n     M - First line of a multiple-line message. \r\n     N - Single-line message that does not require a reply. \r\n     O - Operator LOG command. \r\n     S - Continuation of a single-line message or a continuation of the first line of a \r\n           multi-line message. This continuation may be required because of the record \r\n           length for the output device. \r\n    W - A message that requires a reply. \r\n    X - A log entry that did not originate with a LOG command or a system message. \r\nc - The second character indicates whether the line was generated because of a command: \r\n     C - Command input. \r\n     R - Command response. \r\n      I - Command issued internally. The job identifier contains the name of the internal issuer. \r\n     blank - Neither command input nor command response. \r\n\r\nrrrrrrr - routing codes\r\n"
  },
  {
    "Vendor": "Open systems",
    "component/product": "network",
    "type": "IP address",
    "info": "IP address IPV4 is divided into 2 segemetns:  Network ID and HOST ID. Ex. 192.168.0.1\r\nto Identify the NEtwork ID. Check the SUBNET MASK. if subnet mask is 255.255.255.0 then Network ID is 192.168.0 and host id is 1."
  },
  {
    "Vendor": "open systems",
    "component/product": "network",
    "type": "IP address",
    "info": "IP address and SubnetMask values are the 8bits represented in decimal value of the resultanant binary value.\r\n255.255.255.0  --- 11111111 11111111 1111111 00000000\r\n192.168.0.1    --- 11000000 10101000 0000000 00000001\r\n\r\nAn IP address as 192.168.0.1/24 -- says IP is 192.168.0.1 and subnet mask is 255.255.255.0"
  },
  {
    "Vendor": "open systems",
    "component/product": "network",
    "type": "IP address",
    "info": "CLASS A -- subnet mask is 255.0.0.0\r\nCLASS B -- Subnet mask is 255.255.0.0\r\nCLASS C -- Subnet mask is 255.255.255.0"
  },
  {
    "Vendor": "open systems",
    "component/product": "network",
    "type": "IP address",
    "info": "Router -- of the other functins a router is mainly used to connect 2 systems with diff IP address range."
  },
  {
    "Vendor": "ibm",
    "component/product": "GRS",
    "type": "grs",
    "info": "command to check the contenctions\r\n\r\nD GRS,ANALYZE,WAITER \r\nD GRS,ANALYZE,BLOCKER"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "website",
    "info": "https://www.mail-archive.com/ibm-main@listserv.ua.edu/index.html  --- check this link for any issue that we are facing we may have a thread on the same issue"
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "theory",
    "info": "First create a workload -- grouping of work\r\nselect the service class for each workload group. Each service class  needs a time period with a goal updated."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "commands",
    "info": "V WLM,POLICY=policy -- to acivate a new policy."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "theory",
    "info": "Service Class -- specifies goals of worklaods /can have one or more periods\r\nClassification rule -- a subsystem type, such as cics, db2 / must have a default service class / matches worklaod to service classes.\r\nWorklaod --- groups one or more services calsses\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "theory",
    "info": "z/OS records information about each service class and period in SMF type 72 records"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "theory",
    "info": "PROGRAM DIRECTORY : This program directory is intended for system programmers who are responsible for program installation and maintenance. It contains information about the material and procedures associated with the installation of IBM Migration Utility"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "website",
    "info": "PSP : Preventive Service plannning\r\nhttp://www14.software.ibm.com/webapp/set2/psearch/search?domain=psp"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "theory",
    "info": "Service level information:\r\n\u0002 SMCyyww identifies the service level in terms of CBPDO cycles, where yy is the year and ww is the\r\nCBPDO week. For example, 0842 is the forty-second CBPDO week in 2008.\r\n\u0002 PUTyymm identifies the monthly service level in terms of ESO cycles (formerly PUTs), where yy is the\r\nyear and mm is the ending month of the ESO cycle. For example, 0809 is service through September\r\n2008."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "installation",
    "info": "CBPDO : CBPDO (Custom-Built Product Delivery Option) is an entitled software delivery package consisting of uninstalled products and unintegrated service. There is no dialog program to help you install, as there is with ServerPac. You must use SMP/E to install the individual z/OS® elements and features, and their service, before you can IPL."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "installation",
    "info": "SERVERPAc : ServerPac is an entitled software delivery package consisting of products and service for which IBM® has performed the SMP/E installation steps and some of the post-SMP/E installation steps. To install the package on your system and complete the installation of the software it includes, you use the CustomPac Installation Dialog."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos ",
    "type": "website",
    "info": "Link to all zOS documentation.\r\nhttps://www-40.ibm.com/servers/resourcelink/svc00100.nsf/pages/zosInternetLibrary?OpenDocument"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "training",
    "info": "https://ibmzxplore.influitive.com/users/sign_in  --- we can train using vscode with a real mainframe."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "theory",
    "info": "IMS transactions, Db2 workloads and batch jobs have been divided into groups called service classes. These service classes have been divided into periods, and each has been set performance goals. For example, 90% of our billing CICS transactions (those beginning with ‘A’ in CICS region PCICS1) should complete in 0.5 seconds. Our hot batch is very important, and should have a velocity (time executing vs time waiting) of 50. Each has also been set an importance number: we now know which are more important, and which aren’t."
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "theory",
    "info": "Performance Index\r\nWLM assigns a number to every service class and period: a Performance Index (PI). You can hop to the IBM manuals to get the details about PI, but the basics are:\r\n\r\nPI = 1: exactly achieving the performance objective\r\nPI > 1: not achieving the performance objective (the higher the number, the worse the performance)\r\nPI < 1: exceeding the performance objective\r\nHmmm. So WLM already has a number that tells us if our workloads are achieving their performance goals.\r\n\r\nEven better. WLM records this PI periodically in the SMF Type 72 records. You can also see the PI using monitors like RMF Monitor III, IBM Omegamon, Broadcom SYSVIEW and more. So, how does this help?"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "v2.5",
    "info": "https://github.com/IBM/IBM-Z-zOS/blob/main/SMF-Tools/SMF30_USERKEY_COMMONAREA/REXX_CODE.txt"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "webpage",
    "info": "Steps to cerate a apache webserver\r\n1) Create an installation directory for the server configuration files. For example:\r\ncd install_directory\r\nmkdir -p etc/websrv1\r\n\r\n2) Change the directory to the IBM HTTP Server - Powered by Apache product directory:\r\ncd /usr/lpp/ihsa_zos/.31bit\r\n\r\n3) Run the installer program, bin/install_ihs, to install the HTTP server product files in your installation directory\r\n./bin/install_ihs install_directory/etc/websrv1 8081   -- chekc for available port\r\n\r\n4) check of the installaiton is good\r\ncd install_directory/etc/websrv1\r\n\r\nbin/apachectl -v\r\nbin/apachectl configtest"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "webpage",
    "info": "steps to create a apacahe webserver - 2\r\n5) Use this command to start the IBM HTTP Server - Powered by Apache:\r\nbin/apachectl start\r\n\r\n6) invoke the webpage using the link  http://systemip:port used\r\n\r\n7) bin/apachectl stop -- to stop the apache web server\r\n\r\n8) we can change the default index page at  install_directory/etc/websrv1/htdocs and change the index_ihs.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "webpage",
    "info": "steps to create a apacahe webserver - 3\r\n\r\nWe can also start it as an STC using the below proc and we need to have a STARTED profile defined in RACF\r\n\r\n//*---------------------------------------------------------\r\n//IHSAE001 PROC ACTION='start',\r\n// DIR='install_directory/etc/websrv1',\r\n// CONF='conf/httpd.conf'\r\n//*---------------------------------------------------------\r\n//IHS EXEC PGM=BPXBATCH,\r\n// PARM='SH &DIR/bin/apachectl -k &ACTION -f &CONF -DNO_DETACH',\r\n// REGION=512M \r\n//STDOUT DD PATH='&DIR/logs/proc.output', \r\n// PATHOPTS=(OWRONLY,OCREAT,OTRUNC), \r\n// PATHMODE=(SIRUSR,SIWUSR,SIRGRP,SIWGRP) \r\n//STDERR DD PATH='&DIR/logs/proc.errors', \r\n// PATHOPTS=(OWRONLY,OCREAT,OTRUNC), \r\n// PATHMODE=(SIRUSR,SIWUSR,SIRGRP,SIWGRP) \r\n// PEND"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "webpage",
    "info": "Steps to create a apache webserver - 4\r\nThe configuration file for the IBM® HTTP Server - Powered by Apache, conf/httpd.conf, contains directives that customize the HTTP server. You must add directives to the configuration file so that the HTTP server can display Infoprint Central web pages."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos ",
    "type": "HCD/IODF",
    "info": "/activate iodfxx,test -- to test before activating a new IODF that is created.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "issues",
    "info": "GIM37904E ** APPLY PROCESSING FAILED FOR SYSMOD ROXXXXX BECAUSE OF AN ERROR DURING A PREVIOUS ATTEMPT TO RESTORE.\r\nTry the below steps to remove the RESTORE update on the PTF.\r\n1. First list the SYSMOD using the stat\r\n//STEP1 EXEC PGM=GIMSMP,PARM='DATE=U'   \r\n//SMPCSI  DD DISP=SHR,DSN=CSI.NAME   \r\n//SMPHOLD DD DUMMY                   \r\n//SMPPTFIN DD DUMMY                   \r\n//SMPLIST DD SYSOUT=*                 \r\n//SMPCNTL DD *                     \r\n SET BDY(targetzone).                    \r\n LIST SYSMODS(sysmod).                 \r\n//*                           \r\nMake a not of the time stamp from the list for REStore something like below from the list output.\r\nSTATUS = REC APP RES ERR \r\nRES = 16.000 10:00:00 \r\n2. Run the below jcl to remove the RES entry for the SYSMOD.\r\n//SMPCNTL DD * \r\nSET BOUNDARY(targetzone). \r\nUCLIN. \r\nDEL SYSMOD(sysmod) RESTIME(HH:MM:SS) RESDATE(yyddd) REST . \r\nENDUCL. \r\n//* \r\nthis will remove the RES entry for the sysmod when we run the LIST command again. Now we can run the APPLY REDO without any issues."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "du -sk *   -- to find the largest files in a directory with lot of sub directories."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "NFS",
    "info": "https://community.ibm.com/community/user/ibmz-and-linuxone/blogs/anthony-giorgio2/2020/04/02/shortcut-bringing-up-zos-nfs?lang=en\r\n\r\nStep 10 is missing the example filesystem syntax for the BPXPRMxx member:\r\nFILESYSTYPE\r\nTYPE(NFS)\r\nENTRYPOINT(GFSCINIT)\r\nPARM(’biod(8)’)\r\nASNAME(mvsnfsc)\r\n\r\nYou will need to configure an NFS export (if non-exist) on the server which you intend to use.\r\n\r\nYou can query the available exports on a server with:\r\n/usr/lpp/NFS/showmount -e <server>\r\n\r\nFrom OMVS you could mount AIX or Netapp with the following command:\r\n/usr/sbin/mount -t nfs -f NFS.V4.MOUNT -w 0 -o \"<server>:/<remote-path>,vers(4),xlat(y)\" /<localmnt-point>"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "dispatch",
    "type": "check",
    "info": "Steps to check  the PRIVATE STORAGE KEY\r\nOption 1 - To see what KEY the program is running in via DISPATCH:\r\n\r\n- Logon to Dispatch\r\n- At the Dispatch ENTER NEXT TASK CODE prompt...\r\n  Type: DCPROFILE  [enter]\r\n  On the resulting 1st screen look for:\r\n  PRIMARY STORAGE            \r\n  PROTECT KEY:             ??"
  },
  {
    "Vendor": "ibm",
    "component/product": "zomsf",
    "type": "installation",
    "info": "How to istall serverpac products using zOSMF.\r\n\r\nhttps://www.ibm.com/support/z-content-solutions/serverpac-install-zosmf/"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "RUCSA: Restricted use common storage area.\r\nhttps://www.ibm.com/docs/en/zos/2.4.0?topic=rucsa-migrating\r\n\r\nhttps://zos-hot-topics.com/2021/user-key-common-and-restricted-use-of-csa/"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "Each page frame (4k) is allocated a 4-bit Storage key + Fetch\r\nProtection bit at the CPU level\r\n16 possible Storage key values\r\n0 – 7 : system and middleware. 0 is the master key\r\n2 and 4 are reserved keys and can be used by ISV products.\r\n8 : mostly for users\r\n9 – 15 : used by programs that require virtual = real memory\r\nThe storage key of a memory page is compared with the\r\nprotection key in the PSW register"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "Real storage : frames (physical CPU memory)\r\nVirtual      : pages in multiple address spaces created through DAT)\r\nAuxiliary    : slots on (DASD) volumes (paging datasets) "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "ca-11",
    "type": "command ",
    "info": "to check hte values in OINQ panel:\r\n.   In order to see the display for the OINQ command you will need to provide a valid profile.   You can type (arts)mp as the profile value"
  },
  {
    "Vendor": "ibm",
    "component/product": "zomsf",
    "type": "software management",
    "info": "to software management tool and install products in zOSMF we need to get the dataset profiles CB.OS*.** and CB.ST*.** .  Read access to the  IZUADMIN and IZUUSER groups. or we will have issues when trying to download the product."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "The system uses a portion of both central storage and virtual storage. To determine how much central storage is available to the installation, the system's fixed storage requirements must be subtracted from the total central storage.\r\n\r\nauxiliary storage resources that are used for virtual storage paging, continue to be shared by all address spaces in the system\r\n\r\nAllocated and referenced virtual storage can be backed by either real storage or paged-out to auxiliary storage.\r\nWhile there is no theoretical limit to 64-bit virtual storage ranges, practical limits exist to the finite real storage frames (formally called central storage) and auxiliary storage pages (slots) that back the virtual storage.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "the amount of central memory defined to each system is defined in the Activation profile of type Image in HMC"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "concpets",
    "info": "https://www.ibm.com/docs/en/zosbasics/com.ibm.zos.zconcepts/zconcepts_book.pdf"
  },
  {
    "Vendor": "ibm",
    "component/product": "zOAU",
    "type": "theory",
    "info": "https://www.ibm.com/docs/en/zoau/1.2.0?topic=installing-configuring-zoau&"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "theory",
    "info": "to run 2 zOSMF environments in the same sysplex. \r\n If you are using more than one z/OSMF server, you will have to make sure they have different/separate server userdir pathfile directories, \r\nfor example both servers:  /SERVER1/global/zosmf  and  /SERVER2/global/zosmf, which also both should have different file system mounted so that there is no conflict. \r\n\r\n\r\nYes, you can run z/OSMF only on one of the systems/LPAR's in the sysplex and it could be shared the system server file path directory /usr/lpp/zosmf ...  Server running on a second LPAR in the sysplex can be reached using Workflows and and REST API services within z/OSMF to access/connect to the second z/OSMF server and perform specific operation or obtain data and etc."
  },
  {
    "Vendor": "ibm",
    "component/product": "zomsf",
    "type": "theory",
    "info": " AUTOSTART group start up process. \r\nhttps://www.ibm.com/docs/en/zos/2.4.0?topic=configurations-autostart-concepts-in-zosmf"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "TLS",
    "info": "All you need to do is paste the  IZU_SSL_PROTOCOL=TLSv1.2 line into local_override.cfg, no other additions are necessary. You can then use local_override.cfg to change active_configuarion.cfg settings in the future as well.\r\n\r\nIt is not necessary to let anywhere else in z/OSMF know about local_override.cfg as it is a z/OSMF concept that is automatically picked up by the server."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOAU",
    "type": "theory",
    "info": "The MVS datasets names have to be in caps only."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "command",
    "info": "-SETPROG LNKLST,TEST,NAME=CURRENT,MODNAME=IEFBR14 : to check for a member in linklist"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "profile",
    "info": "/etc/profile -- this is the default profile that we need to update for any products to work for all the users."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "api",
    "info": "https://system.com/zosmf/api/explorer/ -- shows the available api."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "AT-TLS",
    "info": "\r\nWe were wondering why the AT-TLS is working good without having the EZB.INISTACK.sysname.tcpname security profile when we did the update dynamically and failed when we did it with an IPL.\r\n\r\nI hope the below statement explain it.\r\n\r\n“The resource EZB.INITSTACK.sysname.tcpname in the SERVAUTH class controls the ability of applications to open a socket before the AT-TLS policy is loaded on the TCP/IP stack”\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "website",
    "info": "documentation\r\nhttps://www.ibm.com/docs/en\r\nhttps://www.ibm.com/docs/en/zos/2.5.0"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos ",
    "type": "website",
    "info": "IBM open products download\r\nhttps://ibm.github.io/mainframe-downloads/downloads.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "contention - storage",
    "info": "F CATALOG,LIST -- lists all the job waiting for contention.\r\nF catalog,end(id),redrive -- id is form the list command for the job that we want to cancel.\r\nF CATALOG,TAKEDUMP -- to take dump of catalog sTC."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "commands",
    "info": "d IPLINFO,sysparm --- syspram can be any parm that can be specified in IEASYSxx, it would give us the value as specified in IEASYSxx while ipling the system. We need to be careful whil using the values from the output as we may have changed the values dynamically.\r\nd iplinfo,boost,state -- to check if we are using the ziip/speed boost while ipling the system."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "commands",
    "info": "command to display the current running command and stop them if required.\r\nCMDS DISPLAy -- display's all the commands\r\nCMDS ABEND,CMD= -- to abend any running command\r\nCMDS REMOVE,CMD= -- to remove any commands that are waiting to be executed."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "automation",
    "info": "Pre-checks for cancel use case\r\nSo cancel use case pre checks would be, \r\n1.\tMultiple instances should be routed to BAA team\r\n2.\tREPT mode jobs should be routed to BAA team. \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos ",
    "type": "HCD/IODF",
    "info": "to invoke HCD panels in ISPF : please the following command \r\ntso ex 'SYS1.SCBDCLST(CBDCHCD)' -- ensure to have SYS1.SCBDCLST in  SYSPROC concatenation."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logrec",
    "info": "dump a logrec dataset\r\n//*------------------------------------------------------------------\r\n//* COPIES SYS1.LOGREC TO HISTORY FILE MVS.LOGREC.HISTORY            \r\n//*------------------------------------------------------------------\r\n//HISTORY EXEC PGM=IFCEREP1,REGION=1024K,                            \r\n// PARM='ACC,ZERO=N'                                                 \r\n//SERLOG DD DISP=(OLD,KEEP),DSN=SYS1.SYSR.LOGREC                     \r\n//ACCDEV DD DISP=(NEW,CATLG,DELETE),DSN=SYS3.SYSR.LOGREC.D081022,    \r\n// UNIT=3390,SPACE=(CYL,(12,2)),                                     \r\n// DCB=(RECFM=VB,BLKSIZE=6144)                                       \r\n//DIRECTWK DD DISP=(NEW,DELETE),UNIT=3390,SPACE=(CYL,12,,CONTIG)     \r\n//EREPPT DD SYSOUT=A,DCB=BLKSIZE=133                                 \r\n//TOURIST DD SYSOUT=A,DCB=BLKSIZE=133                                \r\n//SYSIN DD DUMMY                                                     \r\n/*                                                                   "
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "logrec",
    "info": "clear a logrec full dataset\r\n//IFCDIP00 JOB CLASS=A,MSGLEVEL=(1,1),MSGCLASS=X,NOTIFY=&SYSUID\r\n//********************************************************************\r\n//* CLEAR AND INITIALIZE HARDWARE EVENT RECORDER DATASET             *\r\n//********************************************************************\r\n//IFCDIP00 EXEC PGM=IFCDIP00\r\n//SERERDS  DD  DSN=SYS1.LOGREC,DISP=OLD,\r\n//             VOL=SER=MVSRES,\r\n//             UNIT=3390"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "TO write to a file using echo commmand\r\necho \"how are yoi\" > /u/a93lnzz/text.xtxt"
  },
  {
    "Vendor": "ibm",
    "component/product": "zOAU",
    "type": "command",
    "info": "decho -- to write data to ps from omvs."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "ccs",
    "type": "products",
    "info": "cairimu -- command to list all the products initialized during CAS9."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "MRI",
    "type": "theory",
    "info": "Mainframe Resource intelligence is a tool that can produce reports of the products running on the system and who is using it similar to IBM TADz. Along with reports it also provide options for a lot of detailed analysis."
  },
  {
    "Vendor": "ibm",
    "component/product": "SYSPLEX",
    "type": "define",
    "info": "Couple datasets : IXCL1DSU  is the utility to define, alter couple datasets."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "LOGRec",
    "info": "Setps to move a logr couple dataset to a different volume.\r\n1. issue the command /D XCF,COUPLE -- to make note of the current active couple datasets.\r\n1. Use the utility IXCMIAPU to list the current content of couple dataset for logr. DATA TYPE(LOGR) REPORT(YES)\r\n2. make note of the Format level, SMDUPLEX, LSR, LSTRR, DSEXTENT\r\n3. Use the sample job SYS1.SAMPLIB(IXGLOGRF and IXGLOGZF) to define a new couple dataset using the values noted from the listing.\r\n4. issue the command /SETXCF COUPLE,TYPE=LOGR,ACOUPLE=(new defined couple,volume). to update the alternate couple dataset to the new one created.\r\n5. wait for sometime for the duplexing to happen from primary to alternate\r\n6. issue the command to make the alternate as primary\r\n7. \r\n6. Update COUPLExx member to point to the new created datasets.\r\n\r\nif we get an error like ALLOWABLE NUMBER OF SYSTEM RECORDS IS LESS THAN CURRENT PRIMARY   then we need to add teh MAXSYSTEM parm in teh definition."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "Automation",
    "info": "Automation flow for Ca-7 restart request.\r\nFirst we get a restart ticket.\r\n\r\nLQ,JOB=jobname  -- check if the job is in REQ queue  -- if more than one job with the same name send it to BAA.\r\n\r\nOnly one job in queue – check the time and compare with the ticket time… less than 1 hr or 2 hr… you will proceed else send the ticket to BAA team,\r\n\r\nLQ,JOB=jobname – any conditions like “JCL OVERRIDE REQUIRED”  --- if true then issue command to cancel JCLOVERIDE and proceed else bypass cancel JCL OVERRIDE and proceed.\r\n\r\nIssue the restart command RESTAT JOB=JOBnumber (proc and procstep) …\r\n\r\nLQ,JOB=jobname – it has to be inactive queue or req queue.  if job is in REQ queue send to BAA team. \r\n\r\n     if job is active queue close the incident\r\n\r\nissue LPRRN JOB=jobnumber --- job completion log  and copy it to incident and close it … \r\n"
  },
  {
    "Vendor": "IBm",
    "component/product": "network",
    "type": "at-tls",
    "info": "1.\tNeed to make sure the keyrings are defined in the systems already – SYSxKEYRING,\r\n2.\tEZB.INITSTACK.xxxx.TCPIP permission across the systems,\r\n3.\tIssue related to reading the certificate on SYSR,\r\nICH408I USER(RACFSTC ) GROUP(C01#STC ) NAME(SVCACCT DEFAULT STC )  491     \r\nOPS4111O RULE GROUPF.PSFALRT HAS EXCEEDED THE AOF FIRING LIMIT OF 1        \r\n  IRR.DIGTCERT.GENCERT CL(FACILITY)                                        \r\n  INSUFFICIENT ACCESS AUTHORITY                                           \r\nACCESS INTENT(CONTROL)  ACCESS ALLOWED(READ   )                          \r\n4.\tAccess related issue for my id to issue vary command for TCPIP,\r\nV TCPIP,,SYNTAXCHECK,TCPIP.SYSR.TCPIP                                  \r\nIEE345I VARY     AUTHORITY INVALID, FAILED BY SECURITY PRODUCT         \r\nOPS4111O RULE GROUPF.PSFALRT HAS EXCEEDED THE AOF FIRING LIMIT OF 1    \r\nICH408I USER(ABVA9ZZ ) GROUP(D#826380) NAME(PRAWIN VENKATACHALAM) 820  \r\n  MVS.VARY.TCPIP CL(OPERCMDS)                                          \r\n  INSUFFICIENT ACCESS AUTHORITY                                        \r\n ACCESS INTENT(UPDATE )  ACCESS ALLOWED(NONE   )                      \r\n"
  },
  {
    "Vendor": "IBM",
    "component/product": "zCHATops",
    "type": "theory",
    "info": "Features of IBM zChat ops:\r\nAnalysis and operation of z environment : be able to get alerts from monitoring tools and take actions right from zchat ops for issuing mvs/automation commands as required. it would communicate with the tools through IBM service management unite tool.\r\nIntegration with event management :\r\nData Sharing:Z ChatOps supports Launch-in-Context links provided in IBM Service Management Unite. Users can copy those links with one click and paste the links into the channel of the chat platform to easily share the data from SMU dashboard\r\n"
  },
  {
    "Vendor": "IBM",
    "component/product": "zCHATops",
    "type": "theory",
    "info": "Diagnose → The chatbot can help you collaborate with your colleagues fo understand the cause and the solution.,\r\n\r\nDetect → The chatbot can notify you, the way you want, when there is a problem before your customers even notice!,\r\n\r\nFix → The chatbot can execute your commands (independently too) to repair problems-more automation, more quality.,\r\n\r\nIsolate → The chatbot will send detailed information to the collaboration channel to help you identify the problem."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "operlog",
    "info": "enabling operlog in a system.\r\nhttps://www.ibm.com/docs/en/zos/2.3.0?topic=in-enabling-operations-log-operlog#settingupoperlog\r\n1. Define a structure OPERLOG in the sysplex CFRM policy.\r\n2. Start the new policy that has the OPERLOG structure : SETXCF START,POLICY,TYPE=CFRM,POLNAME=polname\r\n2. Define a logstream in LOGR policy.\r\n3. Update the CONSOLxx member to have hardcopy \r\nHARDCOPY DEVNUM(SYSLOG,OPERLOG)\r\n        ROUTCODE(ALL)          \r\n        CMDLEVEL(CMDS)         \r\n4. issue the command /SET CON=xx to active the operlog hardcopy along with syslog.\r\n5. we can issue the command LOG O to get into operlog in sdsf and LOG S to see the syslog."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "pagent",
    "info": "pagent task ening in RC 0005 -- check if the /tmp/ directory is full that is where pagent.log file resides."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "at-tls",
    "info": "Ftp to ibm using AT-TLS\r\n//FTP     EXEC  PGM=FTP,PARM=('/-d -v -r tls 170.225.126.22 21 (EXIT')\r\n//SYSFTPD  DD DISP=SHR,DSN=SYS1.TCPPARMS(FTPDATA)                     \r\n//SYSPRINT  DD  SYSOUT=*                                              \r\n//OUTPUT    DD  SYSOUT=*                                              \r\n//INPUT     DD  *                                                     \r\nIBMID_userid                                                            \r\nIBMID_pw \r\nquote pasv                                                            \r\ncd '/toibm/mvs'                                                       \r\nbinary                                                                \r\nPUT ‘user.dump.trs'  pmrcaseno.dump.trs                            \r\nQUIT\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "security",
    "info": "if we need to use the the GPMSERVE task to collect the RMF DD vlaues.. we need the below security in place.\r\nPERMIT BPX.DAEMON CLASS(FACILITY) ID(GPMSERVE) ACCESS(READ)\r\n\r\n    PERMIT BPX.SERVER CLASS(FACILITY) ID(GPMSERVE) ACCESS(READ)\r\n    PERMIT BPX.STOR.SWAP CLASS(FACILITY) ID(GPMSERVE) ACCESS(READ)\r\n    RDEFINE PROGRAM GPM*     ADDMEM('SYS1.SERBLNKE'//NOPADCHK) UACC(READ)\r\n    RDEFINE PROGRAM ERB*     ADDMEM('SYS1.SERBLNKE'//NOPADCHK) UACC(READ)\r\n    RALTER  PROGRAM ERB*     ADDMEM('SYS1.SGRBLINK'//NOPADCHK) UACC(READ)\r\n    RDEFINE PROGRAM CEEBINIT ADDMEM('CEE.SCEERUN'//NOPADCHK)    UACC(READ)\r\n    RDEFINE PROGRAM IEEMB878 ADDMEM('SYS1.LINKLIB'//NOPADCHK)   UACC(READ)\r\n    RDEFINE PROGRAM CELHV003 ADDMEM('SYS1.SCEERUN2'//NOPADCHK) UACC(READ)\r\n    RDEFINE PROGRAM C128     ADDMEM('SYS1.SCEERUN2'//NOPADCHK) UACC(READ)\r\n    RDEFINE PROGRAM CELHDCPP ADDMEM('SYS1.SCEERUN2'//NOPADCHK) UACC(READ)\r\n    SETROPTS WHEN(PROGRAM) REFRESH\r\n    SETROPTS RACLIST(FACILITY) REFRESH"
  },
  {
    "Vendor": "ibm",
    "component/product": "mvs",
    "type": "command",
    "info": "//APFADD   EXEC PGM=IEBGENER                                       \r\n//SYSPRINT DD  DUMMY                                               \r\n//SYSUT2   DD  SYSOUT=(A,INTRDR)                                   \r\n//SYSIN    DD  DUMMY                                               \r\n//SYSUT1   DD  DATA,DLM=##                                         \r\n/*$VS,'SETPROG APF,ADD,DSNAME=XXXXXXXX.XXXXXXXX,VOLUME=XXXXXX'     \r\n##                                                                 "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "datacom",
    "type": "jhf",
    "info": "CA7 *U11D-8200-5  SSN=CAL7 DBID=0601 AREA=JHF AT 100% USED\r\nhttps://knowledge.broadcom.com/external/article/33161/when-running-ca-workload-automation-rest.html\r\n\r\nAs long as the JHF data set has not taken all 16 extents and there is still free space available on the volume , the Datacom MUF will perform a dynamic extend . Look at the Datacom MUF to see if you find any dynamic extend failures due to insufficient space . You will then find a B37 abend.\r\nIf dynamic extend failed then follow the instructions in this knowledge article:\r\nCA 11 Increase space on one file only in DBID 601\r\nhttps://knowledge.broadcom.com/external/article/123154/ca-11-increase-space-on-one-file-only-in.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "SDSF",
    "info": "SDSF does not comes as a default plugin. we need to import it.\r\nthe definition is available in /usr/lpp/sdsf/zosmf/sdsf.properties\r\n\r\nuse the import manager and import the file and we would be able to see the sdsf option in our desktop\r\nwe need to have some security done in place : \r\n\r\nwe need to provide the logonproc, account number and region size that can be used.\r\nwe need to ensure that we have S*.**.SISFEXEC as it has the member ISFWEB."
  },
  {
    "Vendor": "ibm",
    "component/product": "hmc",
    "type": "memory",
    "info": "we can have memory setting in the image profile and not the load profile for each lpar. Please ensure to activate the updated image profile before we ipl the lpar.\r\nwe need to first activate the image profile and then again assign the laod profile and then activate againt to start the lpar."
  },
  {
    "Vendor": "ibm",
    "component/product": "ansible",
    "type": "sample",
    "info": "https://community.ibm.com/community/user/ibmz-and-linuxone/blogs/daniel-jast1/2022/09/14/automation-to-provision-configure-start-liberty"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "certificate",
    "info": "In any environment where 2 digitial entities have to communicate as in a client server environment. Client : who requests the information and server: who share the requested information. The server need to authenticate the client to send the data and at the same time the client need to be able to autheticate the server to recieve the data. The authentication is done in the form of certificate. \r\n\r\nCertifiacate is a digital file that has the type and owner and other information along with Public and Private key pair.\r\nA public key is shared with the entities communicating with the certificate owning system. \r\n\r\nAny data to be sent is encrypted with the private key of the sender certificate and the reciever uses the public key of the sender certificate available with him to ensure that the data being received is from the right entity if the public and private key matches."
  },
  {
    "Vendor": "Open systems",
    "component/product": "Redhat open shift",
    "type": "theory",
    "info": "Openshift is redhat opensource container application platform for developing and hosting enterprise grade applications.\r\nOpenshift is a PaaS. Platform as a Service offering."
  },
  {
    "Vendor": "Open systems",
    "component/product": "Redhat open shift",
    "type": "theory",
    "info": "Openshift Origin is based on top of docker containers and kubernetes cluster manager with added developer and operational centric tools that enable rapid development, deployment and lifecycle management.\r\n\r\nComponents : Kubernetes as the primary infrastructure (can deploy container -- developed from images ) . We can use Open shit container registry.\r\n\r\nOpen shift has webconsole to access all the components. has inbuilt access to Source Code management tools and Open shit CI/CD tools."
  },
  {
    "Vendor": "Open systems",
    "component/product": "Orchestration",
    "type": "theory",
    "info": ""
  },
  {
    "Vendor": "Open systems",
    "component/product": "docker",
    "type": "theory",
    "info": "Linux is the base operating system that any container technology use. they have software(docker engine) above OS kernel that facilitates the needs. \r\nDocker can run any applicaiton that is dependent on the host OS here it is a linuk based.\r\n\r\nif you want to run a Windows based application then we need to have docker installed above a Windows OS."
  },
  {
    "Vendor": "Open systems",
    "component/product": "docker",
    "type": "theory",
    "info": "Difference between Container and Virtual Machine\r\nContainer = (HW) + (baseOS) + (Container engine) + (container(application(required os + database + tool))\r\n          = light weight   \r\n          = Less isolation as the kernel is shared and are dependent on BaseOS.\r\n          = Based on the BaseOS.\r\nVirtual Machine = (HW) + (BaseOS) + (hypervisor) + Virtual machine(OS + application))\r\nVirtual Machine = (HW) + (Hypervisor) + Virtual machine(OS + application))\r\n                = full OS for the virtaul machines\r\n                = More isolaiton as the OS is not shared and they dont rely on the BaseOS\r\n                = we can run both Windows and linux based applications."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "Theory",
    "info": "CA7 takes a copy of submitted job jcl and keeps it in a queue prior to running the job, so it can EDIT the jcl based on #JI/#JO/#JEND editing statements in the JCL source. These editing commands work in tandem with the schedule id the job is submitted with, which allows for different versions of the jcl to be submitted from the same job library member based on the CA7 schedule that the job is submitted with.  Anywhere from one line in the jcl to the entire job can differ automatically based on how the job member is written and the use of the JCL editing tool and the schedule that the job gets.   I believe some but not all CA7 customers would take advantage of this. \r\n \r\nARF: Automatic Recovery Facility.   This tool is a CA7 scripting tool that allows many operator-type CA7 commands to be scripted in advance and get executed based on a non-zero return-code or abend-code of a CA7 job run. Lots of automation is possible with this (Job cancels, force/completes, restarts, job DEMANDs, job Runs, emails, operator messages, job POSTS, etc.  .   I believe some but not all CA7 customers would take advantage of this. \r\n\r\nVRM: Virtual Resource Manager. This is another CA7 tool that can be used to limit the number of jobs running concurrently from 1 to many, force a job to wait for some other job or task to be running (like wait for a Database to be brought up, e.g.), or force a job to wait for some other job(s) or tasks to NOT be running (wait for a database to be brought down, e.g.) .  Again , I believe some but not all CA7 customers would take advantage of this. \r\n"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "ca-11",
    "type": "restart",
    "info": "We have AUTOS=YES specified in our CA11 options. So, we would be able to restart any job when its abend even though the jcl has TYPRUN=P parm in C11 statement without having to update it as TYPRUN=R.\r\n\r\nwe can check it with command /ca11commchar DIS OPTIONS. check for CA11 COMM CHAR in CA11 jcl, check for SYSIN pointed member."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "report",
    "info": "use the history reporting sample jcl and use the pgm=SASSHIS8 and control card as 02A93LNZZ NV* 13 *ALL* TRANSACTION DETAIL -- to get transaction details. Check the manual for the detals regrding the statment, they are based on positions."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "/OPERIDS,ID=MASTER -- to get the terminal attached to the user and other details."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "Ljcl,job=jobname -- gives the jcl from where the jobname is fetched."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "ljob,job=jobname -- gives the job scheduling"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "logoff",
    "info": "/logoff"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "lrlog,job=xxxxx,date=*yyddd -- to get log of when a job ran or * for all the job ran logs."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "requeue,job=xxxxx -- to move a failed job to ready queue."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "/display,st=jcl -- to display the ca7 libraries where the scheduled jobs are saved."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "jcl",
    "info": "//STEP1 EXEC CA7BTI \r\n //********************************************** \r\n //*TEST JOB THAT RUNS CA7 COMAND IN BATCH \r\n //********************************************** \r\n //ERRORS DD SYSOUT=* \r\n //SYSPRINT DD SYSOUT=* \r\n //SYSUDUMP DD SYSOUT=* \r\n //SYSIN DD * \r\n /LOGON \r\n DEMAND,JOB=CTSTEST,SCHID=001,SET=NTR \r\n LQ,JOB=CTSTEST \r\n /*"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "restart,job=5551,forcecomp=yes -- to force complete the job's previous run and restarts the 5551."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "JCLOVRD,JOB=jobnumber,SET={ON|OFF|WLM|NOWLM} -- to overcome a jcl oerride condition"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "job scheduling",
    "info": "1. Add the job in the jcllib\r\n 2. Then put the schedule with the option “yes” in the ca7 panel\r\n 3. Then ‘{LOAD|LOADH},JOB=jobname’ with this command we have to load the job. (this is what ca7 scheduling team is doing 3m)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "jcl tips",
    "info": "#SCC,COND=(768,LT,TRFU1101.RUNSHELL) -- specifies that CA-7 need to consider this step as success if RT from TRFU1101.RUNSHELL is less than 768.\r\n #SCC,COND=(4,LT,*-TRFU1101.RUNSHELL) -- success if all other steps are RC < 4."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "lrjob,job=jobname -- to check the jclid of each jobs"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "commands",
    "info": "lq,job=jobname -- to check the status of any job in REQ,ACTIVE, RDY"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "startup ",
    "info": "The recommended order for starting each CA Workload Automation component with CA 7 is as follows:\r\nCA Datacom/AD\r\nCA7ICOM\r\nCA7ONL\r\nCA7CPM\r\nCA7JFM\r\nCA7 Webclient\r\nCA7SRVR"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "CA7ICOM",
    "info": "CA WA CA 7 Edition Independent Communications Manager (ICOM) collects the execution feedback and forwards it to CA7ONL. An ICOM must run wherever a CA7ONL submitted job executes"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "database ",
    "info": "We got a message in CA7 *U11D-8200-5  SSN=CAL7 DBID=0601 AREA=JHF AT 100% USED. \r\n\r\nhttps://knowledge.broadcom.com/external/article/33161/when-running-ca-workload-automation-rest.html\r\n"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "restart",
    "info": "batch command for restart operations.\r\n//BTI EXEC PGM=SASSBSTR                             \r\n//STEPLIB  DD DISP=SHR,DSN=CAI.CA7.CAL2LOAD         \r\n//UCC7CMDS DD DISP=SHR,DSN=CAI.CA7.COMMDS           \r\n//SYSPRINT DD SYSOUT=*,DCB=BLKSIZE=133              \r\n//SYSUDUMP DD SYSOUT=*                              \r\n//BATCHIN  DD DISP=SHR,DSN=CAI.CA7.BATCHI#1         \r\n//BATCHOUT DD DISP=SHR,DSN=CAI.CA7.BATCHO#1         \r\n//SYSIN DD *                                        \r\n/LOGON userid,password                             \r\nJCLOVRD,JOB=6271,SET=OFF\r\nRESTART,JOB=3016,STPSTRT=STEP2,REASON=TEST          \r\n/* "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "command",
    "info": "need access to SU@MIT in RACF for the userid for /LOGON command..\r\nPE CA7USER CLASS(SU@MIT) ID(userid)  -- class can be SUBMIT or SU@MIT based on the CA7 setup in your system."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "communication",
    "info": "CA Workload Automation CA 7® Edition tracks the progress of jobs on the operating system using SMF for z/OS work and pseudo SMF for cross-platform work. Records are generated for the job start, step end, data set create, and job end. ICOM is the facility that picks up the feedback and communicates it to CA7ONL. \r\nBy default, all ICOMs write SMF feedback to the communications data set (COMMDS) ."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "stop schedule",
    "info": "The STOP,Q=ALL command can be used to halt CA 7 automatic submission of jobs. Any jobs already submitted continue to process on the operating system and go through CA 7 completion processing when finished but, no new work will be submitted to JES. You can stop schedule scan with a SSCAN,TIME=0"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "hold",
    "info": "steps to hold the schedule.\r\nhttps://knowledge.broadcom.com/external/article/20041/disaster-recovery-and-ca-workload-automa.html\r\nSTOP,Q=ALL command can be used to halt CA 7 automatic submission of jobs.\r\nSSCAN,TIME=0 caommand to stop scanning the list for new jobs.\r\nShutdown CA 7 with a /SHUTDOWN,Z5 command. This does a fast shutdown of CA 7 and writes a copy of the queue files to the UCC7QDMP data set.\r\nTo resume CA 7 job submission, enter a START,Q=ALL command."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "CA11",
    "info": "CA-7 communication with CA-11\r\nCA 7 has a dynamic interface to CA-11 and it uses the CA-11 subsystem name to determine CA-11. \r\nYou can run the pgm CAL2EVNR member from the CA 7 CAL2JCL library on each lpar and this report will show you all CA 7's and ICOM's running. \r\nCA 7 and its corresponding ICOM's share the same communications data set (UCC7CMDS) and that is how CA 7 gets information from the ICOMs running on different lpars.\r\n"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "Environment",
    "info": "//STEP0001  EXEC PGM=CAL2ENVR                                   \r\n//STEPLIB   DD  DISP=SHR,DSN=XXXXX.LOCAL.SYSTEM.UK01.LINKLIB     \r\n//          DD  DISP=SHR,DSN=XXXXX.CA7.CAL2LOAD                 \r\n//          DD  DISP=SHR,DSN=XXXXX.CA7.CIASLOAD                 \r\n//SYSPRINT  DD  SYSOUT=*                                        "
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "psw",
    "info": "Program Status Word (PSW), which contains the address of the next instruction to be executed. It also contains a bit that indicates whether the processor is in problem state or supervisor state."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "psw",
    "info": "PER Mask (R) : BIT 1 --  indicate whether an interruption can be caused by program event recording. When this bit is on, a program interruption can occur\r\nArch Level : Bit 12 -- 1 for ESA/390 and 0 for z/ARchi\r\nInstrucion Addr : 32 to 95 in z arch and 32 to 63 in ESA/390\r\nAn ESA/390 PSW has a 1 in bit 12. With 31 bits, it can address up to 2 GB.\r\nA z/Architecture PSW has a 0 in bit 12. With 64 bits, it can address up to 16 EB.\r\nAddr Mode : ESA - 32 bit - (0 indicates 24 bit and 1 indicates 31 bit)\r\n            z/Arch - 31(Extended addr bit),32 (Basic addressing bit) - ( 00-24bit,01-32bit,11-64bit)\r\n\r\ndivision of PSW for understanding : 0 - 31, 32 - 63, 64 - 95(instruciotn addr), 96 - 127(Instruc addr cont).\r\n\r\nPSW is presented in HEXA Decimal and we need to convert it to Binary.\r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "psw",
    "info": "problem program state(P)  -- 15 bit 1 - for running and 0 for processor is in supervisor state and may execute instructions that are not available to problem programs. Indicates whether some instructions can or cannot be used.\r\nDynamic Address Translation (DAT)(T) -- BIt 5 -- If this bit is on, DAT is used; if it is off, DAT is not used.\r\nI/O, EX and M -- 6,7,13 bits -- indicate whether an I/O, external, or machine-check interruption (respectively) can occur. These bits are normally turned off only while the supervisor is in the process of handling one of these interruptions. M is off a type of instruction cannot occur.\r\nKey -- 8,9,10,11 bits -- The PSW key is used to protect storage from being accessed by unauthorized routines\r\nwait state(W)bit -- 14 -- is on, the processor does not fetch and execute instructions but waits for an interruption to occur.\r\nAddress Space(AS) -- BIT 16,17 - control bits are used by programs that access more than one address space.\r\nCondition Code (CC) -- 18,19 are condition code bits.\r\nprogram mask -- BIT 20,21,22,23 -- controls whether certain arithmetic operations can cause program interruptions in case of overflow or underflow.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos ",
    "type": "psw",
    "info": "if I/O,EX,M (6,7,13) are off and Waitstate(14) is ON then it is a diabled wait -- is a condition that an operating system may use to indicate a fatal error or some other condition that makes instruction execution impossible"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos ",
    "type": "psw",
    "info": " Every 4 KB block of central storage is protected by a storage key that is comprised of:\r\n\r\nA 4-bit access control key\r\nA fetch-protection bit\r\nA reference bit\r\nA change bit"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "psw",
    "info": "Storage could be read if any one of the following conditions is met:\r\n\r\nThe PSW key is zero\r\nThe PSW key matches the access control key\r\nThe fetch-protection bit is off"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "psw",
    "info": "Privileged instructions can be executed only when the processor is in supervisor state."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "psw",
    "info": "As a recovery procedure, the PSW restart is usually a last resort to prevent the need for an IPL so it should be used with caution. The PSW restart is used in the following circumstances:\r\n\r\nTo restart the operating system when it has entered a restartable disabled wait state\r\nTo attempt to recover a system that is locked out in an enabled wait state\r\nTo restart the operating system after a QUIESCE command"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "psw",
    "info": "A PSW beginning with 0002 (000A in ESA/390 mode) indicates a disabled wait. A PSW containing 0706 (070E in ESA/390 mode) at the beginning with zeroes in the remaining digits indicates an enabled wait."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos ",
    "type": "psw",
    "info": "restartable Disabled Wait States\r\n01B\r\n04A\r\n09x (spin loop)\r\n202\r\nCCC (quiesced)\r\nD0D"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "psw",
    "info": ""
  },
  {
    "Vendor": "Ibm",
    "component/product": "mainframe",
    "type": "abbr",
    "info": "CIM-The Common Information Model"
  },
  {
    "Vendor": "Ibm",
    "component/product": "mainframe",
    "type": "abbr",
    "info": "DMTF -Distributed Management Task Force (group of software and hardware vendor)"
  },
  {
    "Vendor": "Ibm",
    "component/product": "mainframe",
    "type": "abbr",
    "info": "WBEM -Web Based Enterprise Management"
  },
  {
    "Vendor": "Ibm",
    "component/product": "mainframe",
    "type": "abbr",
    "info": "CEA - zOS COmmon Event Adapter"
  },
  {
    "Vendor": "Ibm",
    "component/product": "mainframe",
    "type": "abbr",
    "info": "REST -REpresentational State Transfer"
  },
  {
    "Vendor": "Ibm",
    "component/product": "mainframe",
    "type": "abbr",
    "info": "ADCD -Applicaiton developer controlled distribution"
  },
  {
    "Vendor": "Ibm",
    "component/product": "mainframe",
    "type": "abbr",
    "info": "SoE -Systems of Engagement (CICS, web pages for input)"
  },
  {
    "Vendor": "Ibm",
    "component/product": "mainframe",
    "type": "abbr",
    "info": "SoR -Systems of records(Db2, oracle) Databases"
  },
  {
    "Vendor": "Open systems",
    "component/product": "",
    "type": "abbr",
    "info": "LAMP - Linux Apache mysql PHP"
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "trace",
    "info": "to run a tracke in zos v2r5 if any issues with sdsf\r\nA SDSF sectrace is needed to see what type of resources are being checked and the associated return code.  The procedure for doing this on 2.5 requires the user allocate  ISFSECTW dummy:\r\n\r\nGo to =6 and issue     tso alloc fi(isfsectw) dummy   then   tso profile wtp\r\n\r\nCreate the problem\r\n\r\nAs long as TSO PROFILE WTP was issued , the results on his tso screen. \r\n\r\nCut/paste those message into the case for our examination,.\r\n\r\nAnd then go back to =6 and issue    free fi(isfsectw)  and  tso profile nowtp\r\n\r\nThanks,"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "website",
    "info": "Website that list all most of the record type and their usage.\r\n\r\nhttps://watsonwalker.com/wp-content/uploads/2020/11/SMF-Reference-20201107.pdf"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "dataset access",
    "info": "Scratches a non-VSAM data set (type 17).\r\nRenames a non-VSAM data set (type 18).\r\nUpdates a VSAM data set (type 60).\r\nDefines a catalog entry for the integrated catalog facility (type 61).\r\nAlters or renames a catalog entry for the integrated catalog facility (type 66).\r\nDefines or alters a VSAM catalog entry (type 63).\r\nDeletes a catalog entry for the integrated catalog facility (type 65).\r\nDeletes a VSAM catalog entry (type 67).\r\nRenames a VSAM catalog entry (type 68).\r\nRead a dataset for input (type 14)."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "sysview",
    "type": "command",
    "info": "CAILMP to check the code and corresponding product."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "to list a GID : issue the racf command\r\nRLIST UNIXMAP G237 ALL"
  },
  {
    "Vendor": "ibm",
    "component/product": "ims",
    "type": "command",
    "info": "to stop any transaction that is not coming down while IMS is shutting down.\r\nSTO REG 13 ABDUMP xxxxxxx"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "to list the current usage of OMVS resources.\r\nDISPLAY OMVS,L"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "Theory",
    "info": "What is SHRLIBRGNSIZE parm in OMVS:\r\nTuning the z/OS shared library region\r\n\r\nThe shared library region is a z/OS feature that enables address spaces |to share dynamic link library (DLL) files. This feature enables your CICS |regions to share the DLLs that are needed for JVMs,rather than each region |having to load them individually. This can greatly reduce the amount of real |storage used by MVS, and the time it takes for the regions to load the files.\r\n\r\nThe storage that is reserved for the shared library region is allocated |in each CICS region when the first JVM is started in the region. (This might |be the master JVM that initializes the shared class cache.) The amount of |storage that is allocated is controlled by the SHRLIBRGNSIZE parameter in |z/OS, which is in the BPXPRMxx member of SYS1.PARMLIB. The minimum is 16MB, |and the z/OS default is 64MB. You can tune the amount of storage that is allocated |for the shared library region by investigating how much space you actually |need, bearing in mind that other applications besides CICS might be using |the shared library region, and adjusting the SHRLIBRGNSIZE parameter accordingly."
  },
  {
    "Vendor": "ibm",
    "component/product": "ipcs",
    "type": "command",
    "info": "logoff -- logoff from ipcs command prompt"
  },
  {
    "Vendor": "ibm",
    "component/product": "ipcs",
    "type": "command",
    "info": "ip st\r\nip dropd\r\nip omvsdata summary userid(a93lnzz) "
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "setup",
    "info": "to send files to ibm we need to create a userid and password.\r\nIBM Support File Transfer ID (https://www.secure.ecurep.ibm.com/transferids/).\r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "ftp2ibm",
    "info": "job to ftp 2 ibm\r\n//FTP     EXEC  PGM=FTP,PARM=('/-d -v -r tls 170.225.126.22 21 (EXIT')\r\n//SYSFTPD  DD DISP=SHR,DSN=SYS1.TCPPARMS(FTPDATA)                     \r\n//SYSPRINT  DD  SYSOUT=*                                              \r\n//OUTPUT    DD  SYSOUT=*                                              \r\n//INPUT     DD  *                                                     \r\nE-TmGmpS1lLv                                                          \r\nTG1h-S0DM-VJ19-2G5j-HTSc                                              \r\nquote pasv                                                            \r\ncd '/toibm/mvs'                                                       \r\nbinary                                                                \r\nPUT 'SYS5.CTS.SYSG.SADMP.PACK' TS010943078.SADUMP.TERSE               \r\nQUIT                                                                  \r\n//                                                                    "
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm",
    "type": "command",
    "info": "e marcus,quiesce"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "SHRLIBRGNSIZE",
    "info": "SHRLIBRGNSIZE is a parameter found in BPXPRMxx that indicates how much of every dubbed address space's private region to hold aside in reserve. The shared library region is intended to hold .so files (i.e. programs or executables) that are used by a large number of address spaces in the z/OS image. This area is like LPALIB, but is for shared objects that are loaded by applications where the file is marked with the +l extended attribute."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "Theory",
    "info": "Privilege support and the emergency subsystem : configure to help us with Jes2 resoruce shortage issues and provide us a way to get into the system when the asids are exhausted."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2",
    "type": "command",
    "info": "command to add a spool volume dynamically\r\n\r\n$s spool(spool7),dsname=sys1.example,space=(cyl,100)"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "command",
    "info": "OSPF neighbour connections\r\nD TCPIP,,OMP,OSPF,NBR"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "Theory",
    "info": "When we have issues with logging onto system or issues with jes2 resoruces\r\nhttps://www.ibm.com/docs/en/zos/2.3.0?topic=facilities-privilege-support-emergency-subsystem"
  },
  {
    "Vendor": "ibm",
    "component/product": "dump",
    "type": "usage",
    "info": "What datasets are used for dump.\r\nIf we have specified DUMP=(DASD,XX-YY) in the IEASYSxx member then the preallocated SYS1.DUMPxx-SYS1.DUMPyy would be used to capture the dumps.\r\n\r\nWe can also allocate the dump datasets dynamically using the below commands in COMMNDxx or issuing them directly\r\n'DD NAME=IPCS.&SYSNAME..D&DATE..T&TIME..&JOBNAME..S&SEQ'    \r\n'DD ADD,SMS=()'                                             \r\n'DD ALLOC=ACTIVE'                                           \r\n\r\nthis will allocate dump datasets on dynamically when ever required. if these allocaiton fail then it would go for the pre-allocated SYS1.DUMPxx datasets."
  },
  {
    "Vendor": "ibm",
    "component/product": "tss",
    "type": "userid",
    "info": "Commands to create a userid in Topsecret\r\ntss cre(AD89TZZ) using(A93LNZZ) name('Ajay Ramankutty') pass(Start123) opid(A3R) dept(DUK5)\r\ntss add(AD89TZZ) inst(00000000000EE74)\r\ntss add(AD89TZZ) group(omvsgrp) dfltgrp(omvsgrp)\r\ntss add(AD89TZZ) home(/) omvspgm(/bin/sh)\r\ntss add(AD5M2ZZ) uid(960200)\r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "DASD",
    "type": "recall",
    "info": "Recover from a backup\r\nHSEND RECOVER 'Dataset name' -- recover the latest backup if it was done by HSM."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "base",
    "type": "zosmf",
    "info": "installing broadcom products using zOSMF\r\nhttps://techdocs.broadcom.com/us/en/ca-mainframe-software/traditional-management/mainframe-common-maintenance-procedures/1-0/getting-started/z-osmf-requirements.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "hmc",
    "type": "memory",
    "info": "how to check memory in HMC\r\nlogin / selelect the mainframe / operatinal customization /  storage information /\r\n\r\nwe can see all the storage availablea and the storage divided between lpars and hsa.\r\n\r\nHSA -- holds part of the total storage available -- iocds / channel control inst. / hardware control\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "hmc",
    "type": "system details",
    "info": "to check the model and capacity of the mainframe.\r\nlogin / selelect the mainframe / system details -- > type, model, capacity"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "gpmserve",
    "info": "logon page for DDR\r\n\r\nhttps://systemip:port/"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "software management",
    "info": "Portable software instance :  this is where we will define the software that we want to install and provide the location fo the unix zip that we have uploaded to install the product.\r\n\r\nDeployments : We will install the product from the uploaded unix zip file using the steps in deployment."
  },
  {
    "Vendor": "ibm ",
    "component/product": "omvs",
    "type": "batch",
    "info": "//MOUNT    EXEC PGM=IKJEFT1A,COND=((0,NE,DEFINE),(0,NE,FORMATFS))  \r\n//SYSTSPRT DD   SYSOUT=*                                           \r\n//SYSTSIN  DD   *                                                  \r\n    BPXBATCH SH mkdir -p /var/zosmf                                \r\n    MOUNT FILESYSTEM('OMVS.SYSD.IZU.SIZUUSRD') TYPE(ZFS) +         \r\n    MOUNTPOINT('/var/zosmf') MODE(RDWR) PARM('AGGRGROW') AUTOMOVE  \r\n    BPXBATCH SH mkdir -p /var/zosmf/data/home/izusvr               \r\n    BPXBATCH SH mkdir -p /var/zosmf/configuration/workflow         \r\n    BPXBATCH SH chown -R IZUSVR:IZUADMIN /var/zosmf                \r\n    BPXBATCH SH chmod -R 755 /var/zosmf                            \r\n/*                                                                 \r\n//                                                                 "
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "update",
    "info": "https://techdocs.broadcom.com/us/en/ca-mainframe-software/traditional-management/mainframe-common-maintenance-procedures/1-0/getting-started/z-osmf-requirements/mainframe-products-using-z-osmf-for-software-management.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "",
    "type": "ECP",
    "info": "How to understand your mainframe and the hardware components.\r\n\r\nHere is the list of IBM resources to be used to draft ECP (Enterprise computing platform)\r\n1.        PCHID reports of IBM mainframe\r\n2.        IBM z15 (8561) Technical Guide and IBM z15 (8562) Technical Guide, IBM redbooks\r\n3.        IBM Z LSPR ITR ratios for IBM processors, https://www-40.ibm.com/servers/resourcelink/lib03060.nsf/pages/lsprITRzOSv2r3?OpenDocument#z15"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "certificate",
    "info": "if we need to know where our certificate private key is stored. List the certificate and check for the keyword \"'PKDS Label' is indicated in the RACDCERT LIST output, it confirms that the private key is stored in the ICSF PKDS\""
  },
  {
    "Vendor": "ibm",
    "component/product": "wazi",
    "type": "Theory",
    "info": "https://www.ibm.com/cloud/wazi-as-a-service"
  },
  {
    "Vendor": "Rocket",
    "component/product": "EOS",
    "type": "Theory",
    "info": "PROF command to check for more options in the panels."
  },
  {
    "Vendor": "Open systems",
    "component/product": "virtulization",
    "type": "types-1",
    "info": "Desktop Virtualization : VDI and Local desktop virtualization\r\nNetwork Virtualizaiton : Network Virtualization uses software to create an overview of the network that an administrator can use to manage it without needing access to the physical components. Types : Software Defined Networking (SDN)-virtualizes hardware that controls network traffic routing. and Network function virtualization(NFV) - virtualizes hardware appliances that provide a network function, such as firewall, load balancer, or traffic analyzer thus, making it easier to configure and provision."
  },
  {
    "Vendor": "Open systems",
    "component/product": "virtulization",
    "type": "types-2",
    "info": "Application Virtualization : Application virtualization runs application software without needing it to be installed in the OS\r\nLocal application virtualization runs on the endpoint device but runs in a runtime environment instead of on the native hardware.\r\nApplication streaming lives on a server that sends small components of the software to run on the end user's device when needed. \r\nServer-based application virtualization runs entirely on a server that sends only its user interface to the client device."
  },
  {
    "Vendor": "Open systems",
    "component/product": "virtulization",
    "type": "types-3",
    "info": "Server virtualization allows multiple virtual 'guest' servers to share the same physical hardware. This works by installing software called a hypervisor, which then controls shared access for each virtual guest to the physical components of the server, including CPU, memory, disk, and networking. "
  },
  {
    "Vendor": "Open systems",
    "component/product": "Cloud computing",
    "type": "Serverless computing",
    "info": "As cloud computing evolves, new models of service delivery have evolved, particularly in the compute space. For example, Serverless is a cloud execution model that offloads management responsibility, such as patching, provisioning, scheduling, and scaling to cloud providers while developers can spend their time and effort on coding or building their applications. Serverless automatically provisions the computing resources required to run application code on-demand and automatically scales resources up or down in response to demand and scales resources to zero when the application stops running. "
  },
  {
    "Vendor": "Mainframe ",
    "component/product": "Sales",
    "type": "Sales",
    "info": "1.        Life cycle management (refresh/upgrades)?\r\na.        ISV Software life cycle at a customer starts with the requirement for a new software based on the solutions that we are planning to arrive.  After looking for available options the best product suited for the customer environment is chosen.  The product is acquired from the vendor after all the licensing terms are in place. \r\nThe product’s N or N-1 version is installed  based on when the N version is made available. Product is tested in test environment by all the respective users and then moved into production systems during an outage window and the availability of users for the required testing.\r\nb.        zOS upgrades are planned when a N+2 version is available. (Ex: if running V2.3 then we plan zOS upgrade to V2.5 as and when released.) To be able to be upto date when the customer size is large a maintenance is applied even before the new version of zOS is rolled out to all the lpars. For some customer we ensure we are always at N-1 version as per their requirement.\r\nc.        For subsystems the maintenance is applied every six months and upgrades are done to be at N-1 versions so we are running stable versions of the susbsystems.\r\nd.        For mainframe we suggest the customers to be at N-1 or N-2 hardware level for being able to use all the features of the software running on the systems effectively. (Current is z16, it would be good to be at z15 or z14 and not at z13). Storage boxes we prefer to be at the latest version of hardware to make use of the latest features\r\n"
  },
  {
    "Vendor": "Mainframe ",
    "component/product": "Sales",
    "type": "Sales",
    "info": "2.\tHow do you manage patching and vulnerability management?\r\na.\tWe check for all the products running on the systems every six months for the available maintenance and have them installed and tested in the test system and then rollout to production systems during production outage window and have it tested as required with the user teams. We have notifications in place for all the vendors and we look out for any hipers during this period that are released by the vendor. We check for the need to apply to the customers env. Based on the functionality that is affected and the maintenance is rolled out on need basis.\r\nb.\tFor all the supported levels of zOS and other sub systems we apply RSU maintenance if the customer allows outage window for every 3 months. For customers where the outage windows are not frequent then a  FIXCAT check is made to know all the available maintenance that is not applied and it is rolled out. The maintenance is first rolled out to the test lpars and after the required tests are done. The maintenance is moved to production during an outage window. HIPERS are checked as and when they are released as we have notifications enabled and they are rolled out based on the need for the environment being supported.\r\nc.\tFor zOS or ISV products we during a hardware upgrade we check and apply all the required maintenance as per the vendors update.\r\nd.\tAll ISV products are checked for compatibility maintenance before a zOS upgrade and are applied.\r\ne.\tHardware maintenance is mostly for the CFCC and that is applied every six months by IBM during and outage window. For hardware upgrade is dependent on customer requirements we do plan for hardware upgrades. Microcode Level upgrade for the storage boxes is maintained at N-1 levels as when and a new release is available or as recommended by the vendor.\r\n"
  },
  {
    "Vendor": "Rocket",
    "component/product": "EOS",
    "type": "Theory",
    "info": "the WTR* tasks (writer tasks) has the parm that has the class that would be archived into that spool. We can have multiple WTR* tasks running each for one class."
  },
  {
    "Vendor": "Rocket",
    "component/product": ".",
    "type": "Theory",
    "info": "check for spool usage\r\n1. TSO WSF2                                                          \r\n2. enter the number that corresponds to the spool you need to check  \r\n3. 7 (facilities)                                                    \r\n4. 1 (spool information)                                             \r\n5. check the left side of the screen for the spool utilization (data)\r\n   and the right side for the directory utilization                  "
  },
  {
    "Vendor": "BMC",
    "component/product": "FDR",
    "type": "report",
    "info": "Report to check all the successfull and failed backups\r\n//REPORT1  EXEC  PGM=USTRPORT,REGION=6M                            \r\n//STEPLIB   DD   DISP=SHR,DSN=UPSTRM.LOADLIB                       \r\n//SYSUDUMP  DD   SYSOUT=*                                          \r\n//SYSPRINT  DD   SYSOUT=*                                          \r\n//USTCATLG  DD   DISP=SHR,DSN=UPSTRM.CATALOG.$UST.CLUSTER  <<CHANGE\r\n//USTFILEI  DD   DISP=SHR,DSN=UPSTRM.FILEINFO.$UST.CLUSTER <<CHANGE\r\n//SYSIN     DD   *                                                 \r\n  SELECT PROFILE=*,DAYS<32,OPNAME=BACKUP*                                  \r\n  REPORT FIELD=(PROFILE,DATE,TIME,COND,OPNAME,OPTYPE,FILES,BYTES)  \r\n  PRINT RPTYPE=CUSTOM                                              \r\n/*\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "/f zfs,query,level                                                   \r\n/f zfs,query,status                                                  \r\n/f zfs,fsinfo                                                        \r\n- To display full file system status for all zFS aggregates that are \r\n  quiesced, damaged, or disabled:DA DI                               \r\n/f zfs,fsinfo,all,full,select=Q DA DI                                \r\n                                                                     \r\n- To display the filesystems which are in quiesced state             \r\n/f zfs,query,filesets,quiesced                                       "
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "commands",
    "info": "To determine all filesystems latches (Locks):                    \r\n/d omvs,w                                                        \r\nTo resolve a latch, you can try the following command:           \r\n/f bpxoinit,recover=latches                                      \r\n                                                                 \r\n/mount filesystem('omvs.plex2.gnu') mountpoint('/products/gnu')  \r\n mode(read) type(zfs)  - Mount the filesystem as READ attribute  "
  },
  {
    "Vendor": "Open systems",
    "component/product": "webserver",
    "type": "tomcat",
    "info": "https://tomcat.apache.org/tomcat-6.0-doc/manager-howto.html#Deploy_A_New_Application_Archive_(WAR)_Remotely"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "message",
    "info": "IOEZ00048I Detaching aggregate filesystem name -- this is the message that gets written to console when a file system is unmonted."
  },
  {
    "Vendor": "Open systems",
    "component/product": "gzip",
    "type": "downlaod",
    "info": "https://github.com/swetankkk/zos_tools -- download the gzip-1.9-edc_b002.180703.tar that works on zos to unzip .gz files."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "unzip",
    "info": "to unzip .tar and .tar.gz files we can use the below command\r\npax -rzf tar.gz\r\ntar -xvzf tar.gz\r\nthe 'z' option on the commands above would allow you to extract the archive that has been created using gzip. More information on pax and tar shell commands can be found at https://www-40.ibm.com/servers/resourcelink/svc00100.nsf/pages/zOSV2R4sa232280/$file/bpxa500_v2r4.pdf\r\n"
  },
  {
    "Vendor": "Open systems",
    "component/product": "webserver",
    "type": "Theory",
    "info": "Webserver : Any server that runs a tool/program that would fetch static/dynamic pages or static files from the database and format it to be viewed in a web browser (chrome, IE) and share it with the requester.\r\n                          As per my knowledge the open system severs are not of similar capacity of the mainframe, they use multiple servers for multiple purposes. One server to run only database, one server to run the application one server to manage network and so on. But with our IBM Mainframe, we run everything on the same lpar (Database, application, network). So in our case we install apache tomcat to enable a webserver in the same lpar and no need to run in a different lpar.\r\n\r\nServlet : a java program that helps with data collection from a webpage or updating a web page. They mostly respond to HTTP requests.\r\n"
  },
  {
    "Vendor": "Open systems",
    "component/product": "webserver",
    "type": "tomcat",
    "info": "Webserver technologies from Apache vendor:\r\nApache HTTP server : A file server that can efficiently deliver images, audios, videos and text files to web based clients. Cannot do any changes/logics around data and present them as is available.\r\nApache Tomcat server : Servlet engine that implements the servlet and JSP(java server pages) specification. Requires a JDK to run. Can run some logic before presenting the data. Like authenticating a user, query a database for information and so on."
  },
  {
    "Vendor": "Open systems",
    "component/product": "WEbserver",
    "type": "tomcat",
    "info": "Apache tomcat installation on zOS.\r\n \r\n1. Download the tool from vendor site - https://tomcat.apache.org/\r\n2. Upload it to the mainframe.\r\n3. Issue the command jar -xvf /fileloc./apache-tocat.zip /targetlocation/– this would create a folder\r\n4. Issue the com. chtag -t -c ISO8859-1 /apachefolder/bin/*.sh – to make all the .sh file as executable.\r\n5. If you want to change the default port CONNECTOR PORT 8080 then update server.xml in /apachefolder/conf\r\n6. Update the following statements in your /etc/.profile to make them permanent\r\n$CATALINA_HOME=tomcat_directory/apache-tomcat-5.5.x\r\nBPXK_AUTOCVT=ON\r\n7. execute the below commands for temporary allocation.\r\nexport CATALINA_HOME=$HOME/tomcat/apache-tomcat-5.5.x\r\nexport _BPXK_AUTOCVT=ON\r\n8. To start tomcat issue the command $CATALINA_HOME/bin/startup.sh – if an user issues the comm. from omvs an STC gets started as USERID*\r\n9. To stop tomcat issue the command $CATALINA_HOME/bin/shutdown.sh\r\n10. http://domain_name:8080 -- to see the start page of tomcat – 8080 is the default port\r\n\r\nWe can also create a STC for tomcat rather then starting the tomcat using omvs commands\r\n \r\n"
  },
  {
    "Vendor": "Open systems",
    "component/product": "WEbserver",
    "type": "TOMCAT",
    "info": "To deploy an web application in tomcat webserver :\r\n1. Upload the *.war files into /tomcatfolder/webapps\r\nAfter couple of seconds\r\n2. We can see that a folder gets created in webapps with the war file name. if the war file is abc.war then we get a directory created as abc.\r\n3. Restart the tomcat. $CATALINA_HOME/bin/shutdown.sh and $CATALINA_HOME/bin/startup.sh\r\n4. We can access the appl. using the weblink /host:port/foldername\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "issue",
    "info": "BPXF274I FILE SYSTEM OMVS.PLEX2.U.AUDITUSR 221\r\nFAILED TO MOUNT.\r\n\r\nwe need to check who is mounting this file system. and chekc the home directory defined in the racf for the userid. it should be defined without any space '/u/user' and not like  '/u/user    '.\r\n\r\nCheck APAR OA59336"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "command",
    "info": "Command to alter the size of structure dynamicaly.\r\nSETXCF ALTER,STRNAME=strname,SIZE=xxxx(y) xxxx - number, y-(K/M)"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "Theory",
    "info": "CLIST TRACE statement : \"CONTROL LIST SYMLIST\""
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "checkpoint",
    "info": "if running chekpoint as a structure we may get an error like\r\nIXC585E STRUCTURE MVSJES2_CKPT2 IN COUPLING FACILITY \r\n\r\nwe dont have to be much worried if we have not changed the JOBNUM / JOBBUF values.\r\nthe JES2 checkpoint size is a static value from which its usage will never exceed (considering you don't change JOBNUM, JOENUM, TGSPACE, etc.). For example, you may calculate a checkpoint size (or use the value listed in $HASP537 when JES2 comes up) of a given size and use it at 100%. This would be a perfect viable environment. Strictly from a JES2 perspective, the checkpoint is considered all in use (100% of it) even if you had overspecified its size for future expansion. Now, if you leave structure monitoring (using FULLTHRESHOLD), you will always get IXC585E because usage exceeds 80%. For such structure, such as JES2 checkpoint, we recommend turning off monitoring by setting a threshold of zero (FULLTHRESHOLD(0)). \r\n\r\nMonitoring is not necessary for JES2 checkpoint structure because its size is checked at JES2 startup based on the its parameter values. If the required storage from $HASP537 is less or equal than structure size, then JES2 will come up fine; if value of $HASP537 is more than actual size, JES2 will fail."
  },
  {
    "Vendor": "ibm ",
    "component/product": "jes2 ",
    "type": "checkpoint",
    "info": "Using FULLTHRESHOLD(0) for checkpoint structure is documented in Setting Up a Sysplex, In 12th paragraph in Section Monitoring Structure utilization on link https://www.ibm.com/docs/en/zos/2.5.0?topic=structures-monitoring-structure-utilization . That paragraph documents: \"An application may “format” all of the structure objects within a structure before using them. This formatting makes it appear to structure full monitoring that 100% of the structure is in use, causing it to issue message IXC585E, even though there may be plenty of usable space in the formatted structure objects. An example of this kind of protocol is the coupling facility list structure JES2 uses for its checkpoint data. For a structure like this, we would recommend that structure full monitoring be suppressed by setting a FULLTHRESHOLD value of 0.\" \r\n\r\nThere is no risk as JES2 is running and checkpoint size will not grow. The threshold monitoring can be ignored or turned off for this structure. However, if you want to leave the threshold monitoring and alleviate the message, then you need to move checkpoint to DASD via checkpoint reconfig, then reallocate the structure with a larger policy (initsize), and finally return checkpoint back to the structure."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "Theory",
    "info": "z/OS, by default, routes requests (for example START commands) to the primary subsystem."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "Theory",
    "info": "JES2 JOB CORRELATOR\r\nJes2 job correlator is parm that we can specify in our job card using the keyword UJOBCORR='text'.\r\nThis helps us to have jobs related with each other.\r\nIf we are installing a product and we have 10 jobs to do the required smp/e or inital steps.. we generally name them as ABCxxxx1 / ABCxxxx2 / ABCxxxx3 / ABCxxxx4 or we may not do it.. and just go with random job names. How do we know from the list of jobs that we have submitted are related to a specific task that we are working with.\r\nWe can use the parm UJOBCORR='product_inst' or UJOBCORR='app_testing' and so on and submit our jobs.\r\nWe can use the display command\r\n/$D JOBQ,UJOBCORR=*product_inst*\r\nand it would list all the jobs with that mathcing JOBCORDD value.\r\nWe can pass the UJOBCORR as a symbolic too and get an application name updated when submitted through an internal reader by a user application"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "access",
    "info": "to be access to issue the LU command we need the have access to IRR.LISTUSER\r\nIn order to do a LISTUSER command OPSOSF needed to have read access to a resource profile named IRR.LISTUSER so OPSOSF was connected to profile SET@PW which has that access. "
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "contacts",
    "info": "Hiren Shah <hiren@us.ibm.com>, Kurt J. Quackenbush <kurtq@us.ibm.com>\r\nCollin Lester <Collin.Lester@ibm.com>; Kurt J. Quackenbush <kurtq@us.ibm.com>; Marna Walle <mwalle@us.ibm.com>"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "Theory",
    "info": "List the sysmods that are not applied but recived.\r\nNOAPPLY : indicates that SMP/E should list SYSMOD entries from the current zone that are not applied to a particular target zone. You can use NOAPPLY to:\r\n        \r\nSee which SYSMODs have been received but have not yet been applied to the specified target zone.\r\n                \r\nTo do this, specify the global zone on the SET command and the target zone you want to check on the NOAPPLY operand.\r\nSET BOUNDARY(GLOBAL)\r\nLIST SYSMOD NOAPPLY(targetZoneName)"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "gpmserve",
    "info": "we need to define the following for the GPMSERVE DDS to work in zOS V2R5\r\nThe keyring on SYSE has to be similar to DDSSERVERKEYRING in SYST system.\r\n\r\nPlease add the below setting to SYSE.\r\n\r\nRACDCERT ID(GPMSERVE) ADDRING(DDSSERVERKEYRING)\r\nRACDCERT ID(GPMSERVE) CONNECT(SITE LABEL(’SYSE SITE CERT’) RING(DDSSERVERKEYRING) USAGE(PERSONAL) DEFAULT)\r\nRACDCERT ID(GPMSERVE) CONNECT(SITE LABEL(’3M Root CA Sha2’) RING(DDSSERVERKEYRING) USAGE(CERTAUTH)\r\nRACDCERT ID(GPMSERVE) CONNECT(SITE LABEL(’3M Policy CA Sha2’) RING(DDSSERVERKEYRING) USAGE(CERTAUTH)\r\nRACDCERT ID(GPMSERVE) CONNECT(SITE LABEL(’3M Issue 1 Sha2’) RING(DDSSERVERKEYRING) USAGE(CERTAUTH)\r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "gpmserve",
    "info": "In zOS V2R5\r\n\r\nMake sure that SYS1.SERBLPA is not present on the LPA list.\r\nIf present, remove SYS1.SERBLINK from the active LINKLIST set and from the APF list."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "gpmserve",
    "info": "we need to have the following resoruces in progam class\r\nERB* \r\nSYS1.SERBLNKE//NOPADCHK\r\nSYS1.SGRBLINK//NOPADCHK\r\n\r\nGPM*\r\nSYS1.SERBLNKE//NOPADCHK"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "command",
    "info": "to list the entries of certian dir / files using ls command \r\nls -ld /path/a*  -- list only the entries starting with name a* in the path."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "Theory",
    "info": "OMVS ACL? access control list. \r\nTo create and administer an ACL for a file, you must either be the file owner or you must have superuser authority by having UID(0) or READ access to SUPERUSER.FILESYS.CHANGEPERMS in the UNIXPRIV class. Additionally, you must also activate the FSSEC class before ACLs can be used in access decisions.\r\n\r\nDid you activate the FSSEC class? If the FSSEC class is not active, you can still see the ACLs you defined in the getfacl command, however, only the standard permission bit check is done."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "Theory",
    "info": "default permission bits for folder. umask : user file-creation mode mask\r\nissue the command umask to know the default permissions for a folder.\r\nisseh the command umask -S to see the default permissions for a folder for owner, group and users"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "ispf invocation",
    "info": "to invoke rmf in ispf.\r\nadd the following to a sysproc concatentain member. and issue TSO %member\r\nPROC 0 UTILITY\r\nCONTROL MAIN MSG LIST CONLIST\r\nIF &SYSISPF ¬= ACTIVE THEN DO\r\n   ISPSTART CMD(%RMFSTART &UTILITY)\r\n   SET RC = &LASTCC\r\nEND\r\nELSE DO\r\n   ALTLIB ACT APPL(CLIST) DA('SYS1.SERBCLS')\r\n   IF &STR(&UTILITY) = &STR(UTILITY) THEN %ERBRMFU\r\n      ELSE RMF\r\n   SET RC = &LASTCC\r\n   ALTLIB DEACTIVATE APPL(CLIST)\r\nEND"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "xcom",
    "type": "command",
    "info": "/F XCOM,MODULES  -- to list the ptfs that has affeceted the modules.. will let us know the latest modules."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "xcom",
    "type": "command",
    "info": "/F XCOM,DIS -- to dispaly all the connections\r\n/F XCOM,SHOW -- to show all the transfers in flight."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "issue",
    "info": "if we are not able to access any files in batch then while doing ftp, then we need to check for access to the resource\r\nread access to all users/tasks to EZB.FTP.**. ‘ "
  },
  {
    "Vendor": "Macro4",
    "component/product": "tubes",
    "type": "Theory",
    "info": "INSTDATA in top secret data for the user– has the tubes profile to be used for the user and the authorization level."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "symbols",
    "info": "if tyring to use &SYSNAME.. that are part of the system sysmbols and jcl errors with incorrect use of &.\r\nIf the statement contains any incorrect characters, correct it. Submit the job again. The possibility exists that a variable cannot be substituted because the scope of its assignment has been exceeded. If the statement contains ampersands as part of a system symbol such as &SYSNAME., the job is running in a jobclass that does not include SYSSYM=ALLOW. Select a different jobclass or contact the system programmer and ask for SYSSYM=ALLOW to be added to the jobclass definition."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "learning",
    "info": "videos https://www.redbooks.ibm.com/redbooks.nsf/redbookabstracts/crse0304.html?Open"
  },
  {
    "Vendor": "ibm",
    "component/product": "zomsf",
    "type": "website",
    "info": "https://ipaddress of system/zosmf/LogOnPanel.jsp"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "command ",
    "info": "Copy with overlay. if we want to copy lines but have content in other lines that are to be overlaid.\r\nuse the block command  CC CC to copy the lines and then use OO OO on the lines that we need to overlay."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "command ",
    "info": "zEXpand to get a extra space to issue long ISPF command.\r\ncmde : to get a extra space to issue long ISPF command.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "OPTION",
    "info": "issue the command RECOVERY ON in a member that you are editing and you would be able to havet he unsaved content that you were editing it there is a connection failure and the member is not saved."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "option ",
    "info": "we can use the command UNDO to remove any changes done while editing a member, we can do multiple undo too.. till it hoes to the changes that are made after last save was done."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "command",
    "info": "EDSET -- to edit the nature of cut, paste, search."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "command",
    "info": "BNDS -- On the first line in the member, in the prefix area, enter the BNDS line command and\r\npress Enter. You will see a line appear which marks the bounds of the line by a < and\r\n> markers. These are in columns 1 and 80.\r\n• All operations, such as many of the line commands we will try, and primary\r\ncommands, such as Find, only work within the BNDS.\r\n\r\n We can also issue the command BNDS 10 20"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "command",
    "info": "f P’.‘ –  find any non-displayable character"
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "command",
    "info": "We use the block command CC CC and cut command to copy a certain no. of line. \r\nwe can us the command CUT string  and again we can use CC CC block command to copy more lines from this member or a different member and use the CUT string to append the lines to the earlier cut lines.\r\n\r\nOnce we have all the required lines cut. We can use PASTE to copy over the lines to a desired member.\r\nNote : use the EDSET command to chekc if you have append for the cut setting."
  },
  {
    "Vendor": "ibm ",
    "component/product": "omvs",
    "type": "tool",
    "info": "to find the fid of a path or a directory/file with a file id then we can use the rexx at\r\nhttps://github.com/IBM/IBM-Z-zOS/blob/main/zOS-Tools-and-Toys/auditid/auditid.rexx \r\n\r\ncopy it to you unix file and issue the command \r\n==> /path/auditid /pathname or fid"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "java",
    "info": "https://community.ibm.com/community/user/ibmz-and-linuxone/blogs/bill-keller2/2023/03/17/getting-started-with-java-applications-on-zos"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "Theory",
    "info": "Job submission and job output processing.\r\n1. RJE : Remote job entry . Multiple consoles or end nodes can submit a jcl to be run on a JES2.\r\n         allows for the extension of your local processing configuration by defining remote locations that can consist of job input terminals and output devices at a different physical site connected to the z/OS-JES2 processor through telecommunication links such as telephone lines and satellites. In this manner, a z/OS-JES2 system can provide input and output support across various geographic locations. But all the remote sites and their attached devices are defined to a\r\nsingle z/OS-JES2 configuration\r\n2. NJE : Network job entry:  here jobs are submitted to Jes2 from multiple jes2 members that in a MAS. takes this concept further by allowing individual z/OS–JES2 processors, that are geographically dispersed, to be connected in a network of JES2 and non-JES2 systems that can communicate, pass jobs, and route output to any attached output devices."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "command",
    "info": "$D JOBQ,SPOOL=(PERCENT>10)  -- to find jobs using more spool%"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "command",
    "info": "SETR NORACLIST(JESSPOOL) \r\nSETR NOCLASSACT(JESSPOOL)  -- to deactivate a class"
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "log",
    "info": "LOG O -- to look at operlog if activated.\r\nLOG S -- to look at system specific syslog."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "command",
    "info": "refresh a class -- SETR RACLIST(JESSPOOL) REFRESH "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "endevor",
    "type": "webservices",
    "info": "1.        Configure the CCI and ENF stc to support web services\r\na.        Ensure to have J2Z CFF6F00 – USS based common services(Includes CCS Tomcat).\r\nb.        CAW0LINK in LINKLST\r\nc.        CAW0LOAD/CAW0PLD/CAW0DCM in Linklist or Steplib of CCI and ENF tasks\r\nd.        CCSZFS dataset has the USS based components\r\ne.        CEG1ZFS1 datasets had the CCS tomcat file sysetms.\r\n2.        Configure CA Endevor settings to support web services\r\n3.        Enable security access to web services\r\n4.        Deploy an instance  of the CCS Tomcat with the CA Endevor web services\r\n5.        Start and test TOMCAT\r\n"
  },
  {
    "Vendor": "IBm",
    "component/product": "DASD",
    "type": "space management",
    "info": "If we are using a management class with \"Partial Release . . . . . . : COND_IMMED\"  parameter then \r\nCOND IMMED   Unused space for data sets with secondary allocation is released either when a data set is closed or during  the Space Management cycle, whichever comes first.      \r\n\r\nwe need to allocate datasets only with primary allocation so the space is not released each time the dataset is edited and saved."
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "omvs smf",
    "info": "The resource rule FACILITY-BPX.SMF controls the ability to write SMF records from UNIX (OMVS) processes. \r\nif you want to write SMF 121 records for java useage, then we need access to this resource."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "to dispaly virtual storage details\r\nd virtstor,hvcommon/hvshare/lfarea\r\nd M=stor -- total real memory allocated to the system."
  },
  {
    "Vendor": "ibm",
    "component/product": "java",
    "type": "jzos",
    "info": "we are running the JCL that would start the application under JZOS and on one(SYST) system it is running without any issues and another system(SYSD) it is failing with  \"JVMJZBL1042E JZOS batch launcher failed, return code=101\"\r\n\r\nEnsure the user runnign the jzos has access to /etc/profile.\r\n\r\n(EDC5205S DLL module not found.)\r\nIf the JVM is using 31-bit Java, you need  to use our 31-bit JVM agent which is \"libgsvoagt1.so\". \r\nlibgsvoagt4.so is our 64-bit Java agent. "
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "syntax",
    "info": "if we want to pass a lengthy variable in //sTDENV then we can follow the below steps.\r\ninstead of \r\nIJO=\"$IJO -agentpath:/products/sysview/R16/run/jvmdata/binpc/libgsvoagt4.so\r\nexport IBM_JAVA_OPTIONS=\"$IJO\"                                          \r\n\r\nwe can have it written as\r\nAGT=\"/products/sysview/R16/run/jvmdata\"          --- creating a variable for of the lenght\r\nIJO=\"$IJO -agentpath:$AGT/bin/libgsvoagt1.so\"    --- using the varibale to build the final path.\r\nexport IBM_JAVA_OPTIONS=\"$IJO\"                   \r\n\r\nWe can also use the option \"\\\" at the end of command line and we can write the remaining command in next line."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "proclib",
    "info": "if new proclib added to the concatenation is not being picked up.\r\nProclib information is maintained in the DEB control block and when you add a new procedure, the information in the DEB is not automatically refreshed. To refresh the DEB and make JES2 aware of these changes, you can issue one of these commands below:\r\n\r\nIf you are using dynamic proclibs, then issue $TPROCLIB(*)\r\n\r\nIf you run with static proclibs, a hot start ($PJES2,ABEND followed by 'S JES2', no IPL), will refresh the DEB.\r\n\r\nIf you cannot afford a hotstart and you run static proclibs, you can issue $TPROCLIB(PROC00). This will create a dynamic proclib copy of your static proclib with an updated DEB. The dynamic proclib will remain for the life of JES2 and on next JES2 restart, it will fall back to the static proclib."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "proclib",
    "info": "dynamic proclib concatenations are defined in JES2PARM, whereby static proclib concatenations are defined in the JES2 start up procedure. So I think the $TPROCLIB(*) command recommended by my colleague is appropriated.\r\n\r\nwhy some proclibs may be affected while others are not affected relates to the fact that a JES2 converter will keep a proclib open for as long as jobs are being submitted into that converter that are using it.  It is only when a job hits the converter that needs an entirely different proc that the converter will implicitly close the existing proclib and reopen/refresh the subsequent proclib.  But this depends on the mixture of your jobs and what respective procs that you use. "
  },
  {
    "Vendor": "ibm",
    "component/product": "java",
    "type": "issue",
    "info": "WHen one of our user is trying to issue java -version. the is receiving error.  \r\n\r\nGot an update from VM team that the JVM was performing a garbage collection, and was doing classunloading subcycle at time of failure . While doing classunload, it encountered a corrupt class structure resulting in the crash.\r\n\r\nAs the crash happened at 'java -version' command, this was just loading the packaged java classes and nothing external. This could mean the java build itself is corrupt. Or the class cache is corrupt.\r\n\r\nSo , Could you please try running this command by disabling shared class cache as :\r\n\r\njava -Xshareclasses:none -version\r\n\r\nIf this crashes, please get the tdump from this crash, along with javacore, and the console log . Also upload the Java build (the entire jre directory) so that we can check in our system if the build is corrupt.\r\n\r\nIf disabling shared class works , then the shared class cache needs to be cleared using \r\n\r\n-Xshareclasses:destroyAll\r\n\r\nReference: https://www.ibm.com/docs/en/sdk-java-technology/8?topic=options-xshareclasses\r\n\r\nFinally it is the region size that was less for hte users and after it was increased all went fine."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos ",
    "type": "memory",
    "info": "\"The amount of virtual storage that an address space can use for private memory objects at any given time is controlled by the MEMLIMIT (memory limit) specification.\" so at a max of 4G can be used for prvt. sorage..\r\n\r\nSMFLIMxx introduced with V2.2"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "memory",
    "info": "SMFLIMxx -- Kind of replacement for IEFUSI exit for maintininag memory. It can be activate, updated and deactivate using SET command. step memory management.\r\nD SMFLIM\r\n\r\nIEFUSI and SMFLIMxx can co-exsist. Begining of a step IEFUSI is pulled in and then SMFLIM comes in .. if any values is being changed in SMFLIxx then SMFLIMxx value overrides the IEFUSI.\r\n\r\nSMFLIMxx can do message suppression that IEFUSI may write.\r\n\r\nNo.of shared pages that can be used can be specified in SMFLIMxx"
  },
  {
    "Vendor": "ibm",
    "component/product": "Network",
    "type": "check",
    "info": "d net,uservar\r\nAllows us to check if any specific updates for the tasks to be run on specific systems."
  },
  {
    "Vendor": "ibm",
    "component/product": "netview",
    "type": "move",
    "info": "F CNMNET,USERVAR,ID=xxxxxx,VALUE=xxxxxx,OPTION=UPDATE --  check the output from teh d net,uservar command"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmf",
    "type": "cpc capacity",
    "info": "we check the full cec deatails using RMF option\r\n3;1;3  -- CPC CAPACITY"
  },
  {
    "Vendor": "ibm",
    "component/product": "hmc",
    "type": "cpc capacity",
    "info": "HMC – soft capping\r\n\r\n1.\tSelect the processor\r\na.\tOepratinal customization\r\ni.\tChange lpar group controls\r\n"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "optimizer",
    "type": "check",
    "info": "With the Management Reporting System (MRS) utility you can identify the programs in a load library that have been processed by Optimizer/II tools. \r\n  \r\nIn Article Id: 68481 there is a sample JCL and report created.   \r\n  \r\nHow to check whether a load module is optimized by the Optimizer/II tools?\r\n  \r\nThere is information in Optimizer/II manuals that you can find in the following link.\r\n\r\nhttps://techdocs.broadcom.com/us/en/ca-miscellaneous/legacy_bookshelves_and_pdfs/bookshelves_and_pdfs/bookshelves/ca-optimizer-ii.html\r\n  \r\nYou have to download the ZIP file in 'All guides with Searchable Index    8.5', then after the unzip of the file the information about MRS utility is in PDF manual OptimizerII_User_Guide_ENU.pdf file. "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "deliver/view",
    "type": "report",
    "info": "There are examples in the CVDEJCL library of both SARGRW and RMOGRW \r\nPlease see CVDEJCL(SARGRW*) and CVDEJCL(RMOGRW*)\r\n\r\nHere are some articles that can help you:\r\nArticle Id:48044 Article Title: Sample RMOGRW utility to print out the JOBNAMES\r\nArticle Id:195482 Article Title: CA View - SARGRW Syntax Inquiry\r\nArticle Id:217840 Article Title: View - Can SARGRW be used to create a report displaying particular job run information?"
  },
  {
    "Vendor": "ibm",
    "component/product": "Network",
    "type": "at-tls",
    "info": "Check the TELNET(TN3270) task and look for configuraiton file. Look for port conneciton in TELNETPARMS section. \r\n\r\nIf we have the below options then it is using TLS setup\r\nTelnetParms       \r\n   ttlsport   2323   --- all the requests send to TCPIP and the encryption & Authentication is handled by tcpip.\r\n   Conntype secure\r\nTelnetParms       \r\n   secureport   2323  --- requests are handled at tn3270 port itself. Encryption & authentication characteristics are handled by the appilcaiton or port policy.\r\n   Conntype secure"
  },
  {
    "Vendor": "ibm",
    "component/product": "ftp",
    "type": "ftps ",
    "info": "FTPS is enabled on port 21 itself I believe in US but as we have \"SECURE_FTP  --   ALLOWED  \" in FTPDATA we are able to get to ftp using command prompt."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "console",
    "info": "ICC - COnsole \r\nIntegrated Console Controller"
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "feature",
    "info": "SDSF 3.1 seems to have a nice feature that will provide insights into VLF/LLA performance - see below:\r\n\r\nModule Fetch Monitor Another interesting addition to SDSF in the z/OS 3.1 Preview is a new Module Fetch Monitor. You might be familiar with an existing tool called Module Fetch Monitor (MFM) that has been distributed on request by Peter Relson (we mentioned this briefly in ‘Optimizing Efficiency of COBOL V5 Load Processing’ in Tuning Letter 2015 No. 1). The new MFM function in SDSF is a ‘new and improved’ version of Peter’s MFM tool. The SDSF MFM gathers information about program fetches from CSVFETCH and CSVLLIX1 dynamic exits. You can display information by load library data set name, by program name, or by job name. The information that is provided includes the number of fetches, and the average and maximum response time for loading the module from disk, and from VLF. For customers concerned about the potential overhead of collecting this information for every program load, you can limit the information gathering based on jobname, load library name, or program name. We think this could be a powerful tuning tool, especially if you are not getting the maximum value from VLF. Depending on interest from our readers, we might provide a short article on using this capability after z/OS 3.1 becomes generally available\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware ",
    "type": "processor",
    "info": "The Telum is a microprocessor made by IBM for the IBM Z mainframe computers, announced at the Hot Chips 2021 conference on August 23, 2021. Telum is IBM's first processor that contains on-chip acceleration for AI inferencing while a transaction is taking place."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "deliver/view",
    "type": "list",
    "info": "listing the initializaiton parms\r\n//SARDT EXEC PGM=SARINIT,PARM='database'\r\n//SYSPRINT DD SYSOUT=*\r\n//SYSIN DD *\r\nNAME=database.\r\n\r\nwe can check for database name from STC or panels.\r\nwe can also use the command F sarstc,DISPLAY "
  },
  {
    "Vendor": "OMC - Tone",
    "component/product": "flasher",
    "type": "job ouput",
    "info": "give CO next to a job to copy the output to a dataset"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "checkpoint-1",
    "info": "JES2 checkpoint dataset enlargement\r\nThere are two ways to extend the size of the CKPT dataset. The first, and easiest, method is to use $TCKPTDEF,CKPT1=SPACE=() command. The SPACE=() operand can either be set to MAX or a specific size in tracks or cylinders. You can see more information about the command here:\r\n\r\nhttps://www.ibm.com/docs/en/zos/2.5.0?topic=section-t-ckptdef-set-checkpoint-definition\r\n\r\nYou can use this command to extend the size of CKPT1 and CKPT2 but it depends on there being free space adjacent to the CKPT extent on the current volume. The command invokes the checkpoint reconfiguration under the covers to increase the ckpt size.\r\n\r\nIf that does not work, you will need to allocate new, larger CKPT1 and CKPT2 datasets manually, and then use the checkpoint reconfiguration dialog to forward the current CKPT1 and CKPT2 to the new, larger NEWCKPT1 and NEWCKPT2. I will outline the procedure below.\r\n\r\nTo set this up, use the $TCKPTDEF command to set NEWCKPT1 and NEWCKPT2 to the values to which you want CKPT1 and CKPT2 changed to.\r\n\r\n$T CKPTDEF,NEWCKPT1=(DSN=sys1.some.new.larger.ckpt1,VOL=newvol1)\r\n$T CKPTDEF,NEWCKPT2=(DSN=sys1.some.new.larger.ckpt2,VOL=newvol2)\r\n\r\nThen, enter the reconfiguration dialog manually with $TCKPTDEF,RECONFIG=YES\r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "checkpoint-2",
    "info": "You will be presented with several options. You want to choose the options that will forward the CKPT1 to NEWCKPT1 and forward CKPT2 to NEWCKPT2:\r\n\r\n$HASP271 CHECKPOINT RECONFIGURATION OPTIONS 751\r\nVALID RESPONSES ARE:\r\n'1' - FORWARD CKPT1 TO NEWCKPT1\r\n'2' - FORWARD CKPT2 TO NEWCKPT2\r\n'5' - SUSPEND THE USE OF CKPT1\r\n'6' - SUSPEND THE USE OF CKPT2\r\n'CANCEL' - EXIT FROM RECONFIGURATION\r\n\r\nCKPTDEF (NO OPERANDS) - DISPLAY MODIFIABLE\r\nSPECIFICATIONS\r\nCKPTDEF (WITH OPERANDS) - ALTER MODIFIABLE\r\nSPECIFICATIONS\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "checkpoint-3",
    "info": "\r\nSo, we choose option 1 for now. The dataset and volume that are set up as NEWCKPT1 will then become the current, in-use CKPT1. Repeat for option 2. The dataset and volume that are set up as NEWCKPT2 will then become the in-use CKPT2.\r\n\r\nAfter the reconfigurations are complete, the previous NEWCKPT1 and NEWCKPT2 will now be CKPT1 and CKPT2 respectively. NEWCKPT1 and NEWCKPT2 will be no longer configured (you can check using $DCKPTDEF).\r\n\r\nAt this point, you can just use commands\r\n$T CKPTDEF,NEWCKPT1=(DSN=sys1.some.other.new.ckpt1,VOL=othernewvol1)\r\n$T CKPTDEF,NEWCKPT2=(DSN=sys1.some.other.new.ckpt2,VOL=othernewvol2)\r\nto set the values for NEWCKPT1 and NEWCKPT2. The NEWCKPTs are never in use...they are just predefined backups in case CKPT1 or CKPT2 fails for some reason. So, these can be modified using $TCKPTDEF command without needing their own reconfiguration.\r\nNote that while in the dialog, JES2 will not actively be modifying the CKPT datasets, aka, work will not be progressi"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "spool",
    "info": "Simultaneous Peripheral Operations Online. The mechanism by which card and print records can be stored on disk, allowing jobs to be run or listings to be printed at times chosen by an operator."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "spooling",
    "info": "The job is submitted and sent to the spooling program\r\nThe job is stored in the DASD input queue\r\nThe job is sent to the spooling program and then to JES\r\nFollowing job execution, data is sent to the spooling program\r\nData is saved to the DASD output queue\r\nWhen a printer becomes available, the output is printed\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "policies",
    "info": "JES2 policies have been introduced which provide alternate ways to customize JES2 processing. JES2 policy definitions can be viewed as a condition that is a logical expression that can be tested and will determine if a policy is applicable during JES2 processing to a specific JES2 object. If the conditions of the policy are satisfied, then one or more actions can be performed.\r\n\r\nPolicy definitions are defined using JSON object text and EBCIDIC encoding (IBM1047) and can be stored either in a z/OS partitioned data set (PDS) or in a file in a directory within a zFS file system.\r\n\r\nJES2 policies are stored in the JES2 configuration directory of the JES2 checkpoint and are only available on z22 activation level (z22 mode)"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "Disk reader support(DSP)",
    "info": "The $SUBMIT command has been added to the list of JES2 commands and can be used to copy a member from the SUBMITLIB data asset to the SUBMIT reader and acts like a JES3 disk reader. This feature allows users to submit JCL to JES2 from a concatenation without the need to log on to TSO, submit a job, or run a started task.\r\n\r\nTo create a submit library, use the $ADD SUBMITLIB(xxxxxxx) command and provide concatenation data sets. The concatenation data sets can be a combination of any partition data sets (PDSs) or zFS file system paths. Up to 255 concatenation data sets can be defined for each SUBMITLIB."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "commands",
    "info": "$ADD SUBMITLIB(TEST),DD1=DSN=ABC.XYZ,DD2=DSN=SYS1.PROCLIB,DD3=PATH=/u/a93lnzz  -- creates a userdefined contacatention to submit jobs.\r\n$SUBMIT,M=J1234,DD=TEST -- submits job J1234 from the TEST dd concatenation. "
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "jcl",
    "info": "/* statements in jcl lets us know they are jes2 related statements."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "phases-1",
    "info": "input-->conversion-->processing-->output-->hardcopy-->purge\r\nIn the input phase, a job consisting of JCL statements and possibly in-stream data is read onto DASD. Here, the job awaits selection for processing by JES2.\r\nIn the conversion phase, the JCL of a job is merged with the JCL from any procedures to be included from a procedure library. The JCL is then checked for any syntax or format errors. If errors are found in the JCL, JES2 issues messages and the job is queued for output rather than execution.If there are no JCL errors, the job is queued for execution in the order of priority within its job class."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "phases-2",
    "info": "In the processing phase, the job is selected for execution in accordance with its priority and class. In the case of WLM initiators, the initiators select jobs based on their service class and the order in which they were made available for execution. During processing, the main steps that occur are:\r\n\r\nThe job is given to an initiator and program execution begins\r\nSYSIN data is passed to the executing program\r\nSYSOUT data is written to DASD spool devices\r\n\r\nIn the output phase, data sets are grouped according to output characteristics, such as the:\r\n\r\nType of forms to be used\r\nUniversal Character Set (UCS) to be used during printing\r\nForms Control Buffer (FCB) to be used during printing\r\nThe job's output data sets are then queued according to the output class assigned to the job and the priority assigned to the job."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "phases-3",
    "info": "During the hard copy phase, the output for a job is printed on local or remote printers or is sent to another JES2 system through the Network Job Entry (NJE) network.\r\n\r\nThe operator decides which class is to be printed and the jobs will print according to the priority assigned to them.\r\n\r\nIf two jobs have the same priority and class, the job that has been waiting the longest will be selected first. This is called First In First Out (FIFO)."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "class",
    "info": "CLASS=x -- is the jobclass defined to execute the jobs and initial processing of the job. (jobclass(*))\r\nSYSOUT=x -- is the outclass for the step.. Specifies the output class and optionally, the form name for the print data set.\r\nSYSOUT=(x,,aaaa) -- outcalss of P with form definiton of aaaa.\r\nMSGCLASS=x -- To specify the output destination for the system and Job messages when the job is complete (OUTCLASS(*)) -- this is for job log."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "phases",
    "info": "Output is printed on local or remote printers or sent to another JES2 system via NJE: HARD COPY\r\nAll traces of the job are removed from the system: PURGE\r\nOutput is sorted into groups of class, priority, and device setup requirements: OUTPUT\r\nThe job is passed to an initiator and then processed. The output is produced: PROCESSING\r\nThe JCL is checked and procedures are merged from the procedure library: CONVERSION\r\nThe job is read into the system and onto a DASD spool device: INPUT"
  },
  {
    "Vendor": "IBM",
    "component/product": "OMVS",
    "type": "userid",
    "info": "To update the user home locaiton access.\r\n\r\n1.\tgo into ishell - issue ISH from TSO 6.\r\n2.\twith your personal directory in the display space, go to option SETUP top line, and select 7 (SU)\r\n3.\tthen go to first tab (FILE) and select ATTRIBUTES/\r\n4.\tthere should be an EDIT button now available - select that.\r\n5.\tchange the owner to your ID, from ROOT/\r\n6.\tchange the mod bits to 775.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "JQE",
    "info": "The JQE components are:\r\n\r\nJob name\r\nJob priority\r\nDetails of the entry node\r\nID of the execution node\r\nOccurrence or non-occurrence of the hold state\r\nTrack address of the Job Control Table (JCT) on the spool data set\r\nInformation on the next JES2 phase the job is eligible for"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "init",
    "info": "WLM - Initiaotors\r\nWhere Workload Management (WLM) controls the initiators, they are started automatically by the system based on:\r\n\r\nperformance goals\r\nimportance of the batch workload\r\nsystem capability\r\nOnce started, the initiators select jobs based on service class and the order they were made available for execution."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "checkpoint",
    "info": "$HAPS478 message will let us know which checkpoint has been used to bring up jes2."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "startup ",
    "info": "NOFMT - No spool volume is to be formatted unless JES2 determines that formatting is necessary.\r\n\r\nJes2 startup options:\r\n\r\nFORMAT - All spool volumes are to be formatted. This request is honored only if all other processors in a JES2 MAS configuration are inactive. If this option is taken, everything currently on the spool file will be lost. If you specify the FORMAT option, a cold start of JES2 will result.\r\nWARM - JES2 is to continue processing where it left off. This is the normal and preferred startup.\r\nCOLD - All job data on the spool volumes will be lost. This is usually only at the request of the systems programmer. Some changes to JES2 need a cold start.\r\nREQ - JES2 is to stop and request a $S command before beginning job processing.\r\nNOREQ - Specifies that JES2 start processing once JES2 is initialized. This saves the operator having to type $S every time JES2 is initiated."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes2 ",
    "type": "shutdown",
    "info": "commands to shutdown jes2\r\n$P JES2\r\n$P\r\n$PJES2,QUICK -- QUICK command is used to terminate JES without regard to cross-system activity.\r\n$PJES2,TERM -- This allows JES2 to terminate with active tasks, but no hot start of JES2 can be performed so this method should only be used where the system is to be re-IPLed.\r\n$PJES2,ABEND -- This command terminates JES2 immediately, regardless of any activity and can be used to terminate JES2 and perform a hot start without an intervening IPL when the need arises. The only activity that this command will wait for the completion of is a write to a checkpoint, where this is based on a coupling facility. In this example, a $PJES2,ABEND command has been entered and an abend code of $PJ2 has been issued. As a result of this command being entered, a WTOR has been issued.\r\n$PJES2,ABEND,FORCE --command should only be used as a last resort. It has the usual IBM warning that the results are unpredictable. It should not be used without knowing that an IPL will almost certainly be required, and that it could damage JES2 resources, such as checkpoints. This command must be entered as a string of characters; no blanks are allowed."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "command",
    "info": "this command that would’ve assisted in ensuring that all jobs that used any ARFSETS had been identified:\r\n\r\nLJOB,ARFSET=@ANY,LIST=NODD "
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "throry",
    "info": "Record Buffering: SMF records are first written to an in-memory buffer called the SMF buffer. The buffer holds the records temporarily until they can be written to the SMF data set."
  },
  {
    "Vendor": "Ibm",
    "component/product": "racf",
    "type": "userid",
    "info": "if you do not specify the PASSWORD parameter when creating a userid generally used with STC userids, then no password is assigned by default. There is also an informational information display after running the command if there is no password or phrase specified:\r\n\r\nADDUSER LANCELOT\r\nICH01024I User LANCELOT is defined as PROTECTED"
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "logs",
    "info": "There are no facilities in USS that provides a log for scripts executed in the USS environment."
  },
  {
    "Vendor": "bmc",
    "component/product": "fileaid",
    "type": "utility",
    "info": "//*    ***********************************************************\r\n//*    ****  STEPL1  FILEAID                                  ****\r\n//*    ****          COPY PDS TO A FLAT FILE              ****\r\n//*    ***********************************************************\r\n//STEPL1       EXEC PGM=FILEAID\r\n//SYSPRINT     DD SYSOUT=*\r\n//SYSLIST      DD DSN=XXXXXXX.TEMP.J6445598.JCLMAST,\r\n//  DISP=(NEW,CATLG,DELETE),\r\n//  UNIT=TMPSTR,\r\n//  SPACE=(CYL,(150,150),RLSE)\r\n//DD01         DD DSN=SYS2.PDS,\r\n//  DISP=SHR\r\n//SYSIN        DD *\r\n$$DD01 LM\r\n/*"
  },
  {
    "Vendor": "bmc",
    "component/product": "fileaid",
    "type": "utility-2",
    "info": "//*       EXAMPLE OF JOB TO LIST A DIRECTORY OF USERS\r\n//*       DEFINED IN THE FORM INDEX, AND THE FORM\r\n//*       ENTRIES FOR WHICH EACH USER IS DEFINED.\r\n//*       THIS JOB INCLUDES THREE STEPS TO OBTAIN\r\n//*       OUTPUT ALPHABETICALLY SORTED BY USER NAME.\r\n//******************************************************************\r\n//XREF     EXEC PGM=EOSMUT00\r\n//STEPLIB  DD  DISP=SHR,DSN=\r\n//RSDPROF  DD  DISP=SHR,DSN=\r\n//RSDPARM  DD  DISP=SHR,DSN=\r\n//FINDX    DD  DISP=SHR,DSN=\r\n//RSDWK01  DD  UNIT=STORVL,SPACE=(TRK,1),DISP=(,PASS)\r\n//RSDLOG   DD  SYSOUT=*\r\n//SYSPRINT DD  SYSOUT=(7,,DEB1)\r\n//SYSUDUMP DD  SYSOUT=Y\r\n//RSDOUT   DD  DSN=&XREF,DISP=(,PASS),UNIT=SYSDA,SPACE=(CYL,(1,1))\r\n//SYSIN    DD  *\r\nUID=RSD0\r\n XREF FORMINDEX,FI=FINDX,O=RSDOUT,\r\n  USER=(AAAAAAA, BBBBBBB)\r\n/*\r\n//*"
  },
  {
    "Vendor": "Rocket",
    "component/product": "wsf2",
    "type": "jobs -2",
    "info": "//SORT     EXEC PGM=IERRCO00,COND=(0,NE,XREF)\r\n//SORTWK01 DD  UNIT=SYSDA,SPACE=(CYL,1)\r\n//SORTWK02 DD  UNIT=(SYSDA,SEP=SORTWK01),SPACE=(CYL,1)\r\n//SORTWK03 DD  UNIT=(SYSDA,SEP=(SORTWK01,SORTWK02)),SPACE=(CYL,1)\r\n//SORTIN   DD  DSN=&XREF,DISP=OLD\r\n//SORTOUT  DD  DSN=&SORT,DISP=(,PASS),SPACE=(CYL,(1,1)),UNIT=SYSDA\r\n//SYSOUT   DD  SYSOUT=*\r\n//SYSLISTE DD  SYSOUT=*\r\n//SYSIN    DD  *\r\n  SORT FIELDS=(1,16,BI,A)\r\n/*\r\n//LIST    EXEC PGM=EOSMUT0C,COND=((0,NE,XREF),(0,NE,SORT))\r\n//STEPLIB  DD  DISP=SHR,DSN=\r\n//RSDPROF  DD  DISP=SHR,DSN=\r\n//RSDPARM  DD  DISP=SHR,dsn=\r\n//SYSIN    DD  DSN=&SORT,DISP=OLD\r\n//SYSOUT   DD  SYSOUT=*,DCB=RECFM=VBM\r\n//RSDWK01  DD  UNIT=STORVL,SPACE=(TRK,1),DISP=(,PASS)\r\n//RSDLOG   DD  SYSOUT=*\r\n//SYSPRINT DD  SYSOUT=*\r\n//SYSUDUMP DD  SYSOUT=Y"
  },
  {
    "Vendor": "bROADCOM",
    "component/product": "XCOM",
    "type": "SEND FILE",
    "info": "//*   ****************************************************              00100003\r\n//*   *** VERIFY XCOM CONNECTIVITY IN EUROPEAN SYSTEMS ***              00110003\r\n//*   ****************************************************              00120003\r\n//*                                                                     00130003\r\n//* LFILE IS THE LOCAL FILE (SENDING FILE)                              00140003\r\n//* FILE IS THE TARGET FILE (RECEIVING FILE)                            00150003\r\n//*                                                                     00160003\r\n//* USE FILEOPT=CREATE IF THE TARGET FILE DOES NOT EXIST                00170003\r\n//* USE FILEOPT=REPLACE IF THE TARGET FILE DOES EXIST                   00180003\r\n//*                                                                     00190003\r\n//*                                                                     00200003\r\n//STEP10  EXEC PGM=XCOMJOB,PARM='TYPE=EXECUTE'                          00210003\r\n//XCOMCNTL DD DSN=xxxxxxXCOM.aaaaa.CONTROL,DISP=SHR                     00220003\r\n//SYSIN01 DD *                                                          00230003\r\nIPNAME=XXXXX.XXXX.X.X                                                   00240003\r\nTYPE=SEND                                                               00250003\r\nFILETYPE=FILE                                                           00260003\r\nFILEOPT=REPLACE                                                         00270004\r\nLFILE= aaa.XCOM.TEST.DATA(TEST1)                                        00280003\r\nFILE=ZZ.XCOM.TEST2.D050621                                         00290003\r\n//                                                                      00300003\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "utility",
    "info": "//STEP         EXEC        PGM=AMASPZAP                              \r\n//SYSPRINT     DD          SYSOUT=A                                  \r\n//SYSLIB       DD          DSNAME=SYS1.LINKLIB,DISP=OLD              \r\n//SYSIN        DD          *                                         \r\n NAME        IEEVLNKT                                                \r\n VERIFY      0018      C9C8,D2D9,D1C2,C7D5                           \r\n REP         0018      E5C6,D3D6,E6F0,4040                           \r\n SETSSI      01211234                                                \r\n IDRDATA     71144                                                   \r\n DUMP        IEEVLNKT                                                \r\n/*                                                                   "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "common services",
    "type": "license",
    "info": "Check the Broadcom licenses that are active.\r\n//CAIRIMU EXEC PGM=CAIRIMU,PARM='PROD'    \r\n//SYSPRINT DD SYSOUT=*                    \r\n//SYSIN DD *                              "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "PDSMAN",
    "type": "utility",
    "info": "Utility to check if a dataset is monitored by PDSMAN or not.\r\n\r\n//PDSM34   EXEC  PGM=PDSM34,PARM='SYS1.PARMLIB'   \r\n//PDSMRPT  DD  SYSOUT=*                           \r\n//SYSIN    DD                                     "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "datacom",
    "type": "utility",
    "info": "//* RUN THIS TO RESOLVE A LOG FULL CONDITION IN THE DATACOM MUF         \r\n//*                                                                     \r\n//SPILL        EXEC        PGM=DBUTLTY,REGION=4M                        \r\n//STEPLIB      DD   DISP=SHR,DSN=XXXXX.CA7.MUF.V15R1.CUSLIB     \r\n//             DD   DISP=SHR,DSN=XXXXX.MSM.DATACOM.AD.V15R1.CAAXLOAD    \r\n//SYSPRINT     DD          SYSOUT=*                                     \r\n//CXX          DD          DISP=SHR,DSN=XXXXXX.CA7.CXX           \r\n//RXX DD DISP=(NEW,CATLG),DSN=XXXXXXX.CA7.RXX(+1),                \r\n//    UNIT=TAPE                                                         \r\n//SYSIN        DD   *                                                   \r\n SPILLOPT  SPILL=MAX                                                    \r\n/*                                                                      "
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "utility",
    "info": "//* JCL THAT KEEPS THE JOB IN WAIT STATUS.                             \r\n//* REXSLEEP MEMBER HAS THE REXX THAT WAITS FOR 60 SECS BEFORE ENDING. \r\n//STEP1 EXEC PGM=IKJEFT1B,PARM='REXSLEEP'                              \r\n//SYSTSPRT DD SYSOUT=Z                                                 \r\n//SYSEXEC DD DSN=XXXXX.JCL.CNTL,DISP=SHR                             \r\n//SYSUDUMP DD SYSOUT=*                                                 \r\n//SYSTSIN DD DUMMY                                                     \r\n//                                                                     \r\n//*\r\n\r\nRExx member\r\n/* REXX */                               \r\nSAY \"I HAVE ENTERED THE REXX\"            \r\nCALL SYSCALLS 'ON'                       \r\nADDRESS SYSCALL                          \r\n\"SLEEP\" 60                               \r\nCALL SYSCALLS 'OFF'                      \r\nSAY \"I'M EXITING THE REXX\"               \r\nEXIT 0                                                                                                       "
  },
  {
    "Vendor": "ibm",
    "component/product": "cobol",
    "type": "jcl",
    "info": "Sample job to run COBOL \r\n\r\n//STEP1 EXEC IGYWCLG                                \r\n//STEPLIB DD DISP=SHR,DSN=SYS2.SVC.LOAD             \r\n//SYSPRINT DD SYSOUT=*                              \r\n//SYSIN DD *                                        \r\n         IDENTIFICATION DIVISION.                   \r\n         PROGRAM-ID. HELLO.                         \r\n         DATA DIVISION.                             \r\n         PROCEDURE DIVISION.                        \r\n         MAIN-PARA.                                 \r\n           DISPLAY \" HELLO WORLD\".                  \r\n           STOP RUN.                                \r\n/*                                                  "
  },
  {
    "Vendor": "bmc",
    "component/product": "common services",
    "type": "utility",
    "info": "Utility to list PTF applied to the load library.\r\n//MAINT EXEC PGM=LMMNTUTL                                   \r\n//STEPLIB DD DISP=SHR,DSN=XXXXX.COMPWARE.ECC.V17.SLCXAUTH    \r\n//SYSPRINT DD SYSOUT=*                                      \r\n//REPORT DD SYSOUT=*                                        \r\n//ALLPTFS DD SYSOUT=*                                       \r\n//SYSIN DD *                                                \r\nXXXX.FILEAID.V17R02.SXVJAUTH                                \r\n/*                                                          \r\n//                                                          "
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "defrag",
    "info": "Job to defrag volumes.\r\n\r\n//STEP1 EXEC PGM=ADRDSSU,REGION=0M                        \r\n//SYSPRINT DD SYSOUT=*                                    \r\n//SYSIN DD *\r\nDEFRAG DYNAM(ZSTR64) FASTREP(PREF) WAIT(2,2)  ADMINISTRATOR\r\nDEFRAG DYNAM(ZSTR71) FASTREP(PREF) WAIT(2,2)  ADMINISTRATOR\r\nDEFRAG DYNAM(ZSTR63) FASTREP(PREF) WAIT(2,2)  ADMINISTRATOR\r\n/*"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "datacom",
    "type": "defrag",
    "info": "//* Job to defrag datacom index file.                               \r\n//* ensure to provide the CUSLIB and CXX for the CA7/CA11 product   \r\n//*                                                                 \r\n//DEFRAG   EXEC PGM=DBUTLTY,REGION=4M                               \r\n//STEPLIB  DD   DISP=SHR,DSN=XXXXX.DATACOM.AD14.CUSLIB              \r\n//         DD   DISP=SHR,DSN=XXXXX.DATACOM.AD.CAAXLOAD              \r\n//SYSPRINT DD   SYSOUT=*                                            \r\n//CXX      DD   DISP=SHR,DSN=XXXXX.DATACOM.AD14.CXX                 \r\n//SYSIN    DD   *                                                   \r\n COMM   DBID=603,OPTION=STATS                                       \r\n REPORT DBID=603,AREA=CXX,TYPE=A                                    \r\n DEFRAG DBID=603                                                    \r\n COMM   DBID=603,OPTION=STATS                                       \r\n REPORT DBID=603,AREA=CXX,TYPE=A                                    \r\n/*                                                                  "
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "CFSIZER",
    "info": "https://www.ibm.com/support/pages/cfsizer"
  },
  {
    "Vendor": "rocket",
    "component/product": "eos",
    "type": "user additon",
    "info": "logon to WSF2\r\nissue the command PROF\r\n3: user profile\r\n2: Create user profile\r\nchekc the access or use the copy command to copy a profile."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmm",
    "type": "command",
    "info": "ENABLE of the IFAPRD0T entry for RMM during IPL.\r\nA “S DFRMM,OPT=RESET” was used to cause the interface stub to be INACTIVATED."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "command",
    "info": "LJOB,JOB=* -- lists only the jobs index with the schid, last run, no. of runs and so on.\r\nLJOB,JOB=*,LIST=NODD -- to list all jobs in the schedule and the schedule.\r\nljob,job=*,list=rqjob -- prereq  -- give only job requiremetns\r\nLjob,job=*,LIST=RQMT -- prereq -- jobs an datasets.\r\nLjob,job=*,LIST=RQUSR -- user requirements for jobs that needs to be posted to get the job running.\r\nljob,job=*,list=depj -- successor job info\r\nLSCHD,JOB=*,LIST=CALS -- to list calenders\r\nLAGENT,AGENT=*,LIST=SHORT -- to list all agents working with CA-7 from other platforms.\r\nLJCL,JOB=ABC -- list the source jcl which is defined for the job in schedule.\r\nLJOB,JOB=*,EXEC=N -- to produce a list of jobs that are in NOEXEC staus.\r\nFSTRUC,JOB=xxxxxxxx,LVL=999,SCHID=YYY -- to lis the forward structure of a job.\r\nFRJOB,JOB=xxxxxxxx  -- List all the starting jobs of the job xxxxxxx\r\nLPRRN,JOB=*\r\nFJOB,SYS=CICS*,SPAN=24 --  provide a listing a forcast of jobs with system name as CICS*\r\n\r\nJOb\r\nUPD,jobname,EXEC=N/Y --- we need to change the EXEC status of a job.\r\nUPD,jobname,EXEC=N/Y \r\n\r\nLPROS,JOB=xxxx -- will provide the dataset name and the pros.\r\nLPROS,DSN=XX.  -- will provide all the jobs that has prose. XX is the HLQ from LPROS.JOB=xxxx command"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Topsecret",
    "type": "command",
    "info": "TSS ADMIN(acid)  ACID(INFO,REPORT) - REPORT allows running the utilities for ACID reporting. INFO is for executing a WHOHAS to list ACIDs for job submission.\r\nTSS ADMIN(acid) RESOURCE(INFO,REPORT) - INFO is for executing a TSS WHOHAS or TSS WHOOWNS against a resource. REPORT allows running the utilities for resource reporting  \r\nTSS ADMIN(acid) DATA(ALL) - List everything except PASSWORD, PROFILE, and SESSKEY\r\nTSS ADMIN(acid) MISC1(TSSSIM) - TSSSIM authorizes administrators to use the TSSSIM utility.\r\nTSS ADMIN(acid) MISC4(CERTLIST,CERTCHK) - CERTLIST allows the security administrator to list digital certificate information. CERTCHEK allows the security administrator to display information about digital certificates.\r\nTSS ADMIN(acid) MISC8(LISTRDT,LISTSTC,LISTSDT) - LISTRDT authorizes an administrator to list the RDT and FDT Records but not to change them. MISC1(RDT) authority is required to maintain the RDT and FDT Records.  LISTSTC authorizes the administrator to list the contents of the Started Task Table but not to change it. MISC9(STC) authority is required to define started tasks to the Started Task Table.LISTSDT authorizes the administrator to list the contents of the Static Data Table (SDT) but not to change it. MISC3(SDT) authority is required to maintain the SDT records.\r\nTSS ADMIN(acid) MISC9(GENERIC) - GENERIC authorizes the administrator to use the WHOOWNS function to obtain a list of all resources owned within their administrative scope."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "parmlib",
    "info": "Update in BPXPRMxx to have different file systems mounts for /etc or /var when the file systems are shared in a sysplex environment.\r\n\r\nROOT FILESYSTEM('OMVS.xxxx.ROOT.xxxxxx')                           \r\n        TYPE(ZFS)                                                    \r\n        MODE(RDWR)                                                   \r\n        AUTOMOVE                                                     \r\n                                /*                                */ \r\nMOUNT FILESYSTEM('OMVS.&SYSNAME..ETC')                               \r\n      MOUNTPOINT('/&SYSNAME./etc')                                   \r\n         TYPE(HFS)                                                   \r\n         MODE(RDWR)                                                  \r\n         NOAUTOMOVE                                                  \r\n         SYSNAME(&SYSNAME.)                                          \r\n                                 /*                                */\r\nMOUNT FILESYSTEM('OMVS.&SYSNAME..TMP')                               \r\n      MOUNTPOINT('/&SYSNAME./tmp')                                   \r\n         TYPE(HFS)                                                   \r\n         MODE(RDWR)                                                  \r\n         NOAUTOMOVE                                                  \r\n         SYSNAME(&SYSNAME.)                                          \r\n                                 /*                                */"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "manuals",
    "info": "https://www-40.ibm.com/servers/resourcelink/svc00100.nsf/pages/zOSV2R4SecurityServerRacfPublications?OpenDocument"
  },
  {
    "Vendor": "IBm",
    "component/product": "Worklaod schedular",
    "type": "migration",
    "info": "Migrating for CA-7 to TWS\r\nin ca7 you can have jobs that dont actually have jcl but point to other jcl\r\nin tws the jobname must match the jobcard so this wont work\r\n\r\nin ca7 ca11 will clean up temporary files, for tws every job requires a scartch step or the next time it runs it will fall over with a duplicate dataset error\r\n\r\nOne thing to watch out for during the conversion is when generating applications if a job is used in more than one application and defined as a predeccesor it might incorrectly reference it for every application it occurs in, giving you multiple predeccors."
  },
  {
    "Vendor": "ibm",
    "component/product": "netview",
    "type": "manuals",
    "info": "https://www.ibm.com/docs/en/z-netview/6.4.0?topic=640-installation-getting-started"
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "options",
    "info": "SMSG     SMS storage groups      --- lists all the stoage groups defined in ISMF and their usage data.\r\nSMSV     SMS volumes             --- lists all the volume status, usage"
  },
  {
    "Vendor": "ibm",
    "component/product": "dasd",
    "type": "options",
    "info": "SDSF option SMSG and SMSV\r\nSMSG     SMS storage groups      --- lists all the stoage groups defined in ISMF and their usage data.\r\nSMSV     SMS volumes             --- lists all the volume status, usage"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "deliver/view",
    "type": "report",
    "info": "in View the new reports are collected via the SARSTC task, a SARFSS task or via CA Deliver. You can make out the difference by looking at the ORIGIN parameter in the View database. In the View database where all the reports are listed you can check if the ORIG has value EXP that means the report was processed via CA Deliver and if it's SAR then the Report was collected by CA View.\r\n\r\nYou may find members RMOGRW01-RMOGRW08 in the default CVDEJCL library provided along with the product these members contain sample jobs having control statements to generate a report using RMOGRW utility which is a general purpose reporting utility to provide information from Deliver database.Likewise you can find sample reports in SARGRW01-SARGRW09 for CA view database for your reference."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "deliver/view",
    "type": "report",
    "info": "Report Definitions can be added via :\r\n\r\nRMODBB database updates.\r\nDefinition copying done by utility RMOUTIL.\r\nUse of RMOJCL to build entities from a job's jcl.These members can also be found in the CVDEJCL library."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "deliver/view",
    "type": "report",
    "info": "Deliver has canned reports with RMORPT.\r\nFor that information please run the following JCL:\r\n//JOBCARD                     \r\n//*  RMORPT - GENERAL PURPOSE REPORT UTILITY             \r\n//REPORT   EXEC PGM=RMORPT                               \r\n//STEPLIB  DD DSN=CAI.CVDELOAD,DISP=SHR        <== MODIFY WITH YOUR CVDELOAD LIBRARY\r\n//SYSPRINT DD SYSOUT=*,                                 \r\n//SYSOUT   DD SYSOUT=*                                  \r\n//SYSIN    DD *                                          \r\nNAME DELIVER.SYSTEM1 <- MODIFY WITH YOUR DELIVER DB NAME\r\nREPORT 1/2/3/4/5/6/7/8/9/10\r\n/*        \r\nYou may find this sample JCL in the RMORPT member of your default CVDEJCL library.\r\nOnce you run the JCL you may find the required output in the SYSPRINT . What you are looking for will be under the REPORT3 and REPORT4."
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "report",
    "info": "Deliver option in the RMOINIT DD pointing parm.\r\nARCH1=F//SAR/D -- says archive SYSOUT CLASS F to CA-View database. Any output with FORM named SAR and to DASD\r\nARCH1=F//SARP/T -- says archive SSYOUT CLASS F to CA-VIEW database.Any output with FORM named SARP and to TAPE\r\n\r\nWe also have the FORM parameter in SAR initialization and each database will have its own FORM parameter."
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "parms",
    "info": "CA-VIEW archive based on 3 parms in the initialization statements.\r\nCL\r\nFORM"
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "connection ",
    "info": "Using the SARININT to define a setuo for a view database we also provide EXPRESS parm to specify the deliver database that it is connected with.\r\n/F SARstc,DISPLAY -- to check the definition.\r\n/F DeliverSTC,DISPLAY -- to check the definiton of the database.\r\n/F XMSStc,list  (Database,all / SATUS,all /USERS / USERID=]/[UID#=]/[CONID=]/[SARDB=]/[RMODB=]/[INBDB=] -- list the Cross Memory serives init parms."
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "Theory",
    "info": "SAR/VIEW -- picking up the database for STC.\r\nthe SARDB to be acted against for STC is provided as a parm in the EXEC stat.\r\n//STEP1 EXEC PGM=SARSTC,PARM='SAR.DATABASE'"
  },
  {
    "Vendor": "CISCO/XEROX",
    "component/product": "XPAF",
    "type": "DJDE",
    "info": "Dynamic Job Descriptor Entry (DJDE)\r\nCommands within an input file for a Xerox LPS(Laser printing serives) printer. The Xerox printer uses these commands to dynamically modify the printing environment. DJDEs can be page-oriented or record-oriented, which determines when they take effect. For example, DUPLEX, COPIES, COLLATE, FORMS, and SHIFT are representative of page-oriented commands."
  },
  {
    "Vendor": "CISCO/XEROX",
    "component/product": "XPAF",
    "type": "throry",
    "info": "XPAF -- Xerox Print Access Facility.\r\nXerox's flagship software solution software solution that uses the power and security of IBM’s z/OS Mainframes.\r\nIn the IBM z/OS Mainframe environment, XPAF enables the printing of high resolution, personalized documents that combine variable text and full color support, as well as precision forms, fonts, and logos"
  },
  {
    "Vendor": "CISCO/XEROX",
    "component/product": "XPAF",
    "type": "Theory",
    "info": "XPAF provides a single, unified interface for:\r\n\r\nPrinter resource management\r\nData stream conversion and formatting: AFP, LCDS (Metacode and DJDE), and Linemode (SYSOUT) to PCL, PDF, and/or PostScript\r\nJob accounting\r\nRemote and local printer access"
  },
  {
    "Vendor": "CISCO/XEROX",
    "component/product": "XPAF",
    "type": "Theory",
    "info": "XPAF also supports AFP, LCDS (DJDE), line mode, and Xerox-formatted data streams on a wide spectrum of feature-rich, local, and remote Xerox Intelligent Laser Printing systems. Print data is taken directly from the JES spool, converted/transformed when necessary, then sent directly to the printer of choice: it's that simple. Users can even convert their documents to PDF which can be emailed to directly to the end user or stored for subsequent archiving, viewing or emailing."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOAU",
    "type": "Theory",
    "info": "https://www.linkedin.com/posts/yugesh-pothuru-76671836_ibm-docs-activity-6954756188144041984-MJzj?utm_source=linkedin_share&utm_medium=member_desktop_web"
  },
  {
    "Vendor": "IBM",
    "component/product": "TWS",
    "type": "Theory",
    "info": "Applications : "
  },
  {
    "Vendor": "ibm",
    "component/product": "DR",
    "type": "GDPS",
    "info": " IBM GDPS is family of disaster recovery and resiliency software for zSystems introduced in 1998. It manages the storage subsystem and remote copy configuration across heterogeneous platforms, automates IBM Parallel Sysplex operational tasks and performs failure recovery from a single point of control.\r\n a collection of offerings that uses clustering, server management, storage replication and automation to minimize downtime of the IBM zSystems® platform.\r\n\r\nProvides GUI interface to manage the system, sysplex components, automatic recovery from primary disk and box failures, health checks, monitoring, HYPER SWAP : When a disk failure occurs at the primary site then the GPDS immediately switches to seconday disk ensuring elimination of single point of failure.\r\n\r\nPeer-to-Peer Remote Copy (PPRC) PPRC is a hardware solution which provides rapid and accurate disaster recovery as well as a solution to workload movement and device migration. Updates made on the primary DASD volumes are synchronously shadowed to the secondary DASD volumes."
  },
  {
    "Vendor": "ibm",
    "component/product": "dr",
    "type": "gdps",
    "info": "key features:\r\n1. Simplification : Simple panels and GUI screens to manage complex environments.\r\n2. Systems Management : Allows systems to be brought up and down in multiple locations to facilitate systems recovery.\r\n3. Autonomic Operatons : Allows for automatic recovery from disk failures and BOX failuers without manual interaction.\r\n4. Automation : Customizable scripts to perform customer specific operations.\r\n5. Sysplex resource managment : Management of CDS configuraiton, coupling facilty configuration and STP(server time protocol).\r\n6. Moniotoring and Health Checks: Reports on events that could delay the recovery.\r\n7. Freeze capability : FREEZE function-in case of a disruption the data write to secondary disks to maintain consistency across secondary write disks the I/O is stopped on them and the data are preserved, allows for start using the secondary devices. All the disks go into an ELB(extended long busy) state.\r\n8. Hyperswap : Ability to quickly switch to the secondary when the primary fails."
  },
  {
    "Vendor": "ibm",
    "component/product": "DR",
    "type": "GDPS",
    "info": "GDPS Metro Hyper SWAP : GDPS HM : entry level solution. Extends the parallel sysplex availability ot disk sub systems.Only disk replicaiton including hyperswap(High availability feature that provides dual-site, active-active access to a volume). Single replicaiton. Continous availability within a DC. Manage flash copy relationships, FREEZE processing to ensure data consistency. Moniotoring and health checks to ensure the process and FREEZE capability. No automation capability using GDPS scripting.\r\nGDPS Metro (single leg and dual leg) : Provides automation, synchronous replication (Metro Mirror), HyperSwap and is tightly integrated with Parallel Sysplex. also known as PPRC. Syplex management, automation using scripts. LCP- locical corruption protection (cyber resiliency support). Ability to maintain 3 copies of data synchronously replicated. in one center or 2 center within metro distances. Support RTO of less than an hour and RPO of 0. Has the capability to add or reduce capacity. Introduce new couple datasets into sysplex, activating and deactivating lpars, loading and stopping systems. Supports multi vendor storage products (IBM, EMC and HDC).\r\nIBM Z Cyber Vault : Enables secure point-in-time copies of the critical source data and helps restore corrupted or deleted data."
  },
  {
    "Vendor": "ibm",
    "component/product": "DR",
    "type": "GDPS",
    "info": "GDPS Global - GM : Orchestrates the recovery of systems that are using asynchronous disk replication (Global Mirror). Between xtended disatances. Supports GDPS LCP feature. provides support for both IBM zCKD (count key data) data and distributed data. RTO of less than an hr and RPO of less than 2Seconds (depends on the workload and bandwidth between the sites). Primary and secondary disk systems needs to be from the same vendor. GM Global Mirror is an asynchronous remote copy technology. Operates over Fibre channel Protocol communications links and maintains a consistent and restartable copy. Recovery between 2 sites only. Maintains consistent and restartable copy of data at the recovery site. Three sets of disks are used GM primary, GM secondary and Flashcopy target disks. GM uses Global copy which is an asynchronous form of PPRC for extended distances.\r\nSetup : PROD region : prod systems in sysplex. one of them running GPDS control(NetView)to manage global mirror. primary disk. Primary point of Control, Manages the remote copy environment and\r\n        Recovery region : recovery systems in sysplex. one of them running GPDS control(NetView)to manage recovery. 2 set of disk for recovery. (GM secondary disk and GMFalshcopy target used by GM) and an additional Flashcopy disk can be created at the recovery for recovery testing. The Netview in recovery site is responsible validating the configuration, for monitoring the GDPS resources, carrying our all recovery actions for (test and real dr). NetView on both sides communicate with each other.  Automate reconfiguration of the recovery site. Generates SMF data with detailed historical GM performance and behavioral data for problem solving. performance reporting. When the FC disk is on the same disk subsystems as the GM secondary disk then we may issues. So, we can generate a test copy of secondary disk called X-Disk and is connected by PPRC-XD.\r\n1. The ability to automate global mirror technology\r\n2. Manages multiple consistency groups\r\n3. GDPS GM used FlashCopy management for data protection and to facilitate data recovery testing with minimal impact.\r\n4. Automates management of temporary capcity on demand.\r\n5. Monitors and reports on events that would prevent rapid recovery."
  },
  {
    "Vendor": "ibm",
    "component/product": "dr",
    "type": "GDPS",
    "info": "GDPS Metro Global – MGM : Combines the local near-continuous availability of GDPS Metro with the unlimited distance recovery options provided by GDPS Global. can support 3 site or 4 site topology. it could be in a 2 DC, 3 DC and or a 4 DC environment. One Key Benefit of GDPS Metro Global is Incremental Resync capability.\r\n\r\nUses metro mirror to copy between the disk within the DC or Metro area and uses GDPS GM technology to asynchronously copy data between sites.  We can have a copy of the recovery data at the DR site using metro mirror to manage global copy i.e PPRC-XD that can be switched to synchronous mode while moving production to the recovery region. Uses HYPERSWAp in the same DC during a DR and GDPS MGM multi site managment will Incremental resync the GLOBAL mirror to the DR site. \r\nprovides protection against Storage failures, site failures and major disasters. \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "dr",
    "type": "GDPS",
    "info": "GDPS Continuous Availability : is a software based solution. Near real-time replication to update data to a second instance of a workload and to manage the distribution of work across both. harnesses software replicaiton and not hardware replication. Work load and datatype specific (IBM DB2, IMS, VSAM using IBM Infosphere replication for z/OS). Switch applications between sites. The ability to switch between sites only in few seconds for the specified workload. Multiple work sites, multiple sysplexes. both run the smae work load and smae data. those copies of data is kept in sync using software replication and it is asynchronous. Loadbalances manages the work to be executed in sysplex a or b.\r\nSupports Acitve/Query configuration which can read the data when it being updated. Threshold policies can be setup to stope the queries being sent to the copy that is not yet replicated.\r\n\r\n\r\nGDPS CA functins : Control plane to manage, we can monitor workload routing, workload components, replication activity. Interface to manage the solution and also capability for RESTful api's\r\n\r\nIBM SA(system automation) : provides automation policy repository, automated startup and shutdown of workloads  and system elements. provides an interface for GDPS to manage and monitor systems in multiple sysplex's. coexist with other automation products.\r\n\r\nIBM infospehere Data replicaiton : captures changes records from source DMS logs, replicates transactions by workload, forwarding only the commited changes. near real time sync using multiple channels and multi traget DBMS connections for parallel transaction replay. Controlled from GDPS CA control panel.\r\n\r\nMulti-site workload lifeline : adjust routing based on the availability works with load balancer, monitor diff. types of applications (tcp, sna, mq cluster), different routing configurations based on workload requirements (active/query, active/standby). Single point of control.\r\n\r\nz Netview for continous availability : "
  },
  {
    "Vendor": "ibm",
    "component/product": "DR",
    "type": "Theory",
    "info": "RPO : Till what time the data would be available if a disaster occurs. Based on the Data level at PROD and recovery site. to achive a RPO of ZERO we need to have synchronous replication between PROD and RECOVERY sites.\r\nRTO : How much time it would take to bring the systems at recovery site up and running so users can access them."
  },
  {
    "Vendor": "ibm",
    "component/product": "dr",
    "type": "GDPS",
    "info": "Metro Mirror : Single leg/Dual leg"
  },
  {
    "Vendor": "ibm",
    "component/product": "education",
    "type": "webiste",
    "info": "https://github.com/IBM/IBM-Z-zOS/tree/main/zOS-Education/"
  },
  {
    "Vendor": "ibm",
    "component/product": "education",
    "type": "webiste",
    "info": "https://github.com/IBM/IBM-Z-zOS/tree/main/zOS-Education/"
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "command",
    "info": "/F stc,list database,all \r\n\r\nLists all the databases that the SAR/DELVIER STC is communicating with."
  },
  {
    "Vendor": "BMC/Compuware",
    "component/product": "Xpediter",
    "type": "command",
    "info": "XENV  -- to list the environment details.\r\nTSO EX 'rexx libdef to invoke' INSTALL --  to copy over the old defaults."
  },
  {
    "Vendor": "BMC/Compuware",
    "component/product": "Xpediter",
    "type": "theory",
    "info": "Three steps are necessary to change the Code Debug TSO default setting:\r\n\r\n1) Change the parameter BASE_PRODUCT_DATASETS_HELPLIB_1 in the relevant Code Debug TSO parmlib member (default name XTSO00).\r\n\r\n2) Refresh the parmlib member in CMSC ('f cmsc,parmlib refresh XTSOxx', where CMSC is the CMSC started task name (if modified) and xx is the suffix for the PARMLIB member(default is XTSO00))\r\n\r\n3) execute either Code Debug TSO XPLIBDEF with parm INSTALL or ISPF clist XPCINST to commit the changes made to the CMSC PARMLIB member into member XPTDFLTS in the Code Debug TSO Table Library SLXTTABL (as described in Task 2.10 'Configure Code Debug ISPF Support' in the Code Debug TSO installation guide or in chapter 'Establishing ISPF Installation Parameter Defaults in the Code Debug TSO Advanced Configuration guide). After a successful commit of the table change, and a new logon to Code Debug TSO you should verify, if the parm has been changed. By entering 'xenv;15' on the the Code Debug TSO\r\nprimary menu, followed by a find command (i.e. 'f help') and you should see the new value(s)."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "v3r1",
    "info": "Java support : https://www.marnasmusings.com/2023/08/having-your-java-and-drinking-it-too.html"
  },
  {
    "Vendor": "ibm",
    "component/product": "smpe",
    "type": "receive",
    "info": "Setting up internet service retrieval\r\nhttps://www.ibm.com/docs/en/zos/2.5.0?topic=guide-preparing-use-internet-service-retrieval"
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "job-1A",
    "info": "job to list the jobs using XCL parm.\r\n//RMOGRW   EXEC PGM=RMOGRW                                           \r\n/*JOBPARM SYSAFF=NSC1                                                \r\n//STEPLIB  DD DSN=SYS5.VIEWDLVR.CVDELOAD,DISP=SHR                    \r\n//SYSPRINT DD SYSOUT=*                                               \r\n//SYSOUT   DD SYSOUT=*                                               \r\n//PRTFILE  DD SYSOUT=*                                               \r\n//*                                                                  \r\n//* SAMPLE CONTROL STATEMENTS TO GENERATE A REPORT CONTAINING        \r\n//*        JOB NAME, STEP NAME, PROCEDURE STEP NAME, DD NAME, REPORT \r\n//*        IDENTIFIER, REPORT TYPE AND ACTIVE STATUS. EACH JOB IS ON \r\n//*        A NEW PAGE AND TITLE AND HEADINGS ARE PRODUCED.           \r\n//*                                                                  \r\n//SYSIN    DD *                                                      \r\n/CONTROL SEQ=JOB DATABASE=SYS5.DLVR.EXPRPT                           \r\n/TITLE 'PAG WITH END STATEMENT'                                      \r\n/SELECT TYPE='S'                                                     \r\n/DEFINE I BIN                                                        \r\n/DEFINE CNT BIN                                                      \r\n/DEFINE BEG BIN                                "
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "job-1B",
    "info": "/DEFINE END BIN                              \r\n/DEFINE PAG BIN                              \r\n/SET BEG = 0                                 \r\n/SET END = 0                                 \r\n/SET PAG = 0                                 \r\n/DO I = 1 TO NTEXT BY 1                      \r\n/  IF TEXTTYPE = 'X' THEN                    \r\n/    SET PAG = I                             \r\n/  END                                       \r\n/  IF TEXTTYPE = 'B' THEN                    \r\n/    SET BEG = I                             \r\n/  END                                       \r\n/  IF TEXTTYPE = 'E' THEN                    \r\n/    SET END = I                             \r\n/  END                                       \r\n/  NEXT TEXT                                 \r\n/END                                         \r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "job-1C",
    "info": "/IF PAG <> 0 AND END <> 0 AND BEG = 0        \r\n/PRINT JOB 'JOBNAME'                         \r\n/PRINT RID 'REPORT ID'                       \r\n/PRINT END 'TEXT STMT'                       \r\n/PRINT END 'TEXT STMT'                                            \r\n/PRINT ACTIVE 'ACTIVE'                                            \r\n/SET CNT=CNT+1                                                    \r\n/END                                                              \r\n/ON ENDDATA                                                       \r\n/  PRINT 'NUMBER OF REPORTS WITH PAG AND END STATEMENT IS '||CNT  \r\n/END                                                        \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zsam",
    "type": "userid/pwd",
    "info": "The default userid and password are set in\r\nHQL.REPSQLDB.PARMLIB(HSISANP1)"
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "groups",
    "info": "The IXCJOIN macro defines a member to an XCF group so the member can use the XCF signaling and status monitoring services.\r\nThe IXCCREAT macro defines a member to XCF to be used later during execution.\r\nThe IXCLEAVE, IXCQUIES, IXCDELET, and IXCTERM macros disassociate members from XCF services. (IXCLEAVE and IXCDELET also disassociate a member from its group.)\r\nThe IXCSETUS macro changes a member's user state value (to be explained in the topic \"Using the Cross-System Coupling Facility (XCF)\").\r\nThe IXCMOD macro changes a member's status-checking interval (to be explained in this the topic \"Using the Cross-System Coupling Facility (XCF)\").\r\nThe IXCQUERY macro provides you with information about groups, members, and systems in the sysplex."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "groups",
    "info": "When you define a member to XCF through IXCCREAT or IXCJOIN, XCF assigns a member token to the member that is unique within the sysplex\r\na member token remains the same for the duration of the sysplex. Authorized routines use the member token when requesting XCF services on behalf of a member."
  },
  {
    "Vendor": "ibm",
    "component/product": "zsam (tadz)",
    "type": "reports",
    "info": "Steps to generate IBM TADz reports.\r\n\r\n1.        We need to know if the customer is running the IBM TADz tool (current name is IBM z Software asset management tool).\r\n2.        To you know you are running it or not check for task HSI* (default name) on the system.\r\n3.        If you are running you can access the tool using http://ipaddress of the system running the tool:9000 (9000 port is by default).\r\n4.        Once you launch the website you need userid and password to get in. Check the dataset HQL.REPSQLDB.PARMLIB(HSISANP1) for userids and passwords that are defined to the tool.\r\n5.        Once you login, we can generate different reports for product usage, products installed.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "jobs",
    "info": "job to allocate, catalog, and format a RACF database : SYS1.SAMPLIB member RACJCL\r\nWith V2R5 we can use VSAM datasets"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos ",
    "type": "proclib ",
    "info": "A started procedure is normally started by an operator, but can be associated with a functional subsystem. For example, DFSMS is treated as a started task even though it does not need to be specifically started with a START command.\r\nstarted procedures have system-generated JOB statements that do not contain the USER, GROUP, or PASSWORD parameter.\r\nThe started procedures table can contain one generic entry, indicated by an asterisk (*) in the procedure-name field. The generic entry enables you to add started procedures to your system without requiring an IPL to update ICHRIN03. For this reason, you should include a generic entry."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "ICHRIN03",
    "info": "Before the introduction of the RACF STARTED class, table ICHRIN03 was the way RACF had to control started tasks. However, and contrary to what we may believe, ICHRIN03 still plays an important role.\r\nICHRIN03 is still used when:\r\n\r\nNo STARTED class profile covering a resource exists\r\nA STARTED class profile exists but does not have an STDATA segment\r\nA STARTED class profile exists with an STDATA segment, but the segment lacks a USER field\r\nThe RACF STARTED class is not active"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "conversion ",
    "info": "Topsecret to RACF conversion\r\nhttps://www.redbooks.ibm.com/redbooks/pdfs/sg245677.pdf"
  },
  {
    "Vendor": "ibm",
    "component/product": "modernization",
    "type": "Watson",
    "info": "WatsonX code assistant for z.\r\n1. Understand   : Application discovery\r\n2. Refactor     : Auto refactoring of COBOL \r\n3. Transform    : Code conversion with Generative AI\r\n4. Validate     : AI generated Test automation\r\n5. Recommend    : Deploy and best fit infrastructure (CI/CD Pipeline Turbonomic) \r\n6. Observe      : Application observability (Instana for zOS and Omegamons"
  },
  {
    "Vendor": "ibm",
    "component/product": "modernization",
    "type": "Watson",
    "info": "WatsonX code assistant for z : \r\n\r\nGenerative AI services for CODE.\r\nCOBOL to Java-Turned model\r\nIBM-trained Watsonx.ai code large language model (LLM).\r\n\r\n• Well architected object oriented AI generated Java\r\n• Optimize for mainframe middleware and z/OS Java APIs \r\n• Customize for your standards and best practices"
  },
  {
    "Vendor": "ibm",
    "component/product": "git-dbb",
    "type": "notes",
    "info": "PROs\r\n• IBM DBB provides an end-to-end solution for managing and automating the build, deployment and management of mainframe applications.\r\n• We can use the existing Gitlab @LFG for managing the Mainframe Application component Repositories.\r\n• IBM DBB helps developers to easily manage source code, version control and maintain a track of changes. \r\n• On top of it, DBB provides automated dependency based builds. i.e., any new developers can quickly capture the dependencies and build using DBB, automating testing, and integrating with other tools such as Jenkins / Gitlab-ci\r\n• It is feasible to implement IBM DBB with GIT, and definitely it will add value to the business by improving the productivity of Developers and increases the frequency of deployments. IBM DBB, itself designed for continuous improvement. \r\n• This is not just about migration, adopting to IBM DBB will provide many intuitive DevOps capabilities and solutions for longer run."
  },
  {
    "Vendor": "ibm",
    "component/product": "git-dbb",
    "type": "notes",
    "info": "CONS:\r\n• The main considerations are Products Licensing Cost and the Time it consumes for the implementation.\r\n• Product License – includes IBM IDz integrated with IBM DBB, Urban Code Deploy(UCD) and the associated components(optionally like zUnit Testing Tool)\r\n• IBM DBB considered as a highly process oriented tool for Mainframe Apps in this DevOps era. The detailed assessment, strategies and tools are to be defined at the very earlier stage of implementation. \r\n• This requires considerable amount of time and effort. \r\n• The successful implementation of IBM DBB is based on the time we spend. In a short span of time, we cannot achieve this. Because IBM DBB is not a kind of plug and play tool. This requires detailed analysis, process change, tools change, trainings to the users and implementation.\r\n• It is not recommended to directly implement IBM DBB with the critical applications. In order to cover all type of components, the POC should be performed.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "git-dbb",
    "type": "notes",
    "info": "• POC includes:\r\no  Detailed assessment of Mainframe Application components against its types, compiler options and dependencies\r\no  Tools procurement, Installation, configuration and enablement.\r\no  Source Code Repository Management\r\no  Create custom IBM DBB Build Scripts to perform automated build and deployments.\r\no  Validate the dependency based builds and deployments.\r\n• It is necessary to provide Training to all the Mainframe AD Teams, Test Teams, RLM, Support Team on following areas:\r\no  IBM IDz\r\n  Integrated with IBM DBB, GIT, Automated Testing, Sonarlint, Dependency based build features and cli commands\r\no  IBM DBB\r\no  Git\r\no  Git Branching Strategies\r\no  Git Repository and Mainframe application source code Management\r\no  Componentization and Shared Repositories Management \r\no  Rollback and recovery strategies\r\no  Urban Code deploy-UCD\r\no  Jenkins/Gitlab-ci Automated Build and Deployment Pipelines"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "commands",
    "info": "https://www-40.ibm.com/servers/resourcelink/svc00100.nsf/pages/zOSV2R3sa321008/$file/iatb300_v2r3.pdf"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "commands",
    "info": "*inquiry,proclib -- to list the proclib concatenation.\r\n*Cancel,setup,jobnumber -- to cancel a job -*C,s,jn"
  },
  {
    "Vendor": "ibm",
    "component/product": "storage",
    "type": "tape",
    "info": "To create a tape on a drive that has the IDRC hardware feature and  \r\nBYPASS IDRC add this to the output dd: DCB=TRTCH=NOCOMP             "
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "utility",
    "info": "IBMCOPY similiar to IEBCOPY"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "macro",
    "info": "ISREDIT MACRO      /* CLEAN COLUMNS 73 -80   */     \r\n                                                    \r\n  ISPEXEC CONTROL ERRORS RETURN                     \r\n  ISPEXEC CONTROL CONLIST SYMLIST                   \r\n  ISREDIT C ALL P'¬' \" \" 73 80                      \r\n                                                    \r\nEXIT CODE(0)                                        \r\n                                                    "
  },
  {
    "Vendor": "broadcom",
    "component/product": "tss",
    "type": "theory",
    "info": "A profile is an ACID containing resource permissions that allows users who can share access authorizations for protected resources to be grouped."
  },
  {
    "Vendor": "broadcom",
    "component/product": "tss",
    "type": "commands",
    "info": "//CFILE  EXEC PGM=TSSCFILE\r\n//PRINT  DD SYSOUT=*\r\n//OUT    DD DSN=&SYSUID..TSSCFILE,\r\n//       DISP=(,CATLG,DELETE),UNIT=SYSALLDA,\r\n//       SPACE=(CYL,(20,20),RLSE),\r\n//       DCB=(RECFM=FB,LRECL=300)\r\n//IN     DD *\r\n\r\nTSS LIST(ACIDS) TYPE(USER) DATA(NAME)        --- general users\r\nTSS LIST(ACIDS) TYPE(PROFILE) DATA(NAME)     --- PROFILE acids hold the access to the resources so multiple users can be attached to the ACIDS that are TYPE of PROFILE.\r\nTSS LIST(ACIDS) TYPE(USER) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(PROFILE) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(GROUP) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(DCA) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(VCA) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(DEPT) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(DIV) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(SCA) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(LSCA) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(ZONE) DATA(ALL)\r\nTSS LIST(ACIDS) TYPE(ZCA) DATA(ALL)\r\nTSS LIST(ALL) DATA(ALL)\r\nTSS LIST(STC) DATA(ALL)\r\nTSS LIST(RDT) DATA(ALL)\r\nTSS LIST(DLF) DATA(ALL)\r\nTSS LIST(FDT) DATA(ALL)\r\nTSS LIST(NDT) DATA(ALL)\r\nTSS LIST(APPCLU) DATA(ALL)\r\nTSS LIST(AUDIT) DATA(ALL)\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "storage",
    "type": "theory",
    "info": "3390 disk, a track is 56664 bytes. One cylinder includes 15 tracks, which are 849960 bytes"
  },
  {
    "Vendor": "broadcom",
    "component/product": "tss",
    "type": "exit",
    "info": "TSSINSTX -- is the default exit name."
  },
  {
    "Vendor": "ibm",
    "component/product": "modernization",
    "type": "dasd",
    "info": "Object storage is a data storage architecture for storing unstructured data, which sections data into units—objects—and stores them in a structurally flat data environment. Each object includes the data, metadata, and a unique identifier that applications can use for easy access and retrieval.\r\n\r\nMore and more z/OS clients are integrating cloud object storage into traditional disk and tape environments to create a hybrid storage architecture. These hybrid solutions are able to leverage the strengths of on-premises disk and tape storage while adding the intrinsic strengths of cloud solutions for backup, archive, and unstructured data.\r\n\r\nnew -- Cloud Data Access (CDA) -- Base component -- provides a simple way to store any z/OS data directly onto cloud object storage.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "modernization",
    "type": "dasd",
    "info": "CDA provides simple API access to objects in cloud object stores. Not only are there GET, WRITE, LIST, and DELETE actions, CDA also handles all of the painful, nitty gritty details for authenticating and communicating with the target cloud. CDA provides APIs and an ISPF application to securely store the cloud credentials needed to access the cloud object store; this means that the user will not have to enter the credentials during execution of the application, further simplifying the process.\r\n\r\nCDA supports the use of S3 compatible IBM Cloud Object Storage, Amazon Simple Storage Service (Amazon S3), Azure Blob storage, and Google Cloud Storage as well as BASIC, TEMPAUTH, and KEYSTONE authentication methods."
  },
  {
    "Vendor": "ibm",
    "component/product": "storage",
    "type": "dasd",
    "info": "CDA provides simple API access to objects in cloud object stores. Not only are there GET, WRITE, LIST, and DELETE actions, CDA also handles all of the painful, nitty gritty details for authenticating and communicating with the target cloud. CDA provides APIs and an ISPF application to securely store the cloud credentials needed to access the cloud object store; this means that the user will not have to enter the credentials during execution of the application, further simplifying the process.\r\n\r\nCDA supports the use of S3 compatible IBM Cloud Object Storage, Amazon Simple Storage Service (Amazon S3), Azure Blob storage, and Google Cloud Storage as well as BASIC, TEMPAUTH, and KEYSTONE authentication methods."
  },
  {
    "Vendor": "ibm",
    "component/product": "storage",
    "type": "utility",
    "info": "GDKUtil*:\r\nz/OS DFSMS also offers a JCL utility called GDKUtil that enables batch access to cloud objects. GDKUtil can be used to download or upload sequential data sets to the cloud."
  },
  {
    "Vendor": "broadcom",
    "component/product": "tss",
    "type": "theory",
    "info": "Access to a resoruce is checked in top down order. If a ACID has access to read a dataset using profile ABC and update access using profile DEF and if he is added to the profiles in the order ABC and DEF then he would only have read access to the dataset. We can use the below command to move the profiles added to the ACID and provide him the required access.\r\nTSS REM(ES001316) PROFILE(xxxxxxDBA)\r\nTSS ADD(ES001316) PROFILE(xxxxxxDBA) BEFORE(xxxDEVP)\r\n\r\nThe problem is our installation options are AUTH=(MERGE/ALLOVER) - that means TSS will scan thru the entire ACID and all dataset defs are processed and merged so the longest rule will be the one used. "
  },
  {
    "Vendor": "broadcom",
    "component/product": "tss",
    "type": "simulate",
    "info": "//STEP1    EXEC PGM=TSSSIM                    \r\n//* This job helps to check the rule created and how it is working.\r\n//* FAC(xxxxx) -- can be TSO, BATCH, CICS and so on.\r\n//* The documentation for user defined resource class use @ and $ for predefined(JESSPOOL resoruce class.\r\n//*                                                                              dataset or Otran)\r\n//SYSTSPRT DD SYSOUT=*                        \r\n//SIM$$LOG DD SYSOUT=*                        \r\n//SIM$$IN  DD *                               \r\nLOGON ACID(AAYJ9ZZ) FAC(GRPRCICS) TRACE       \r\n$OTRAN(DQRY) ACCESS(EXECUTE)                  \r\nEJECT                                         \r\nEND                                           \r\n\r\nLOGON ACID(IT010481) FAC(TSO) TRACE       \r\n$JESSPOOL(*.) ACCESS(READ)                \r\nEJECT                                     \r\nEND                                       \r\n\r\nLOGON ACID(A92TQZZ) FAC(TSO) TRACE                                \r\n$DSN('ESL1.LOCAL')    ACC(UPDATE)  \r\nEJECT                                                             \r\nEND                                                               "
  },
  {
    "Vendor": "broadcom",
    "component/product": "tss",
    "type": "commands",
    "info": "//TSSCMD1 EXEC PGM=IKJEFT01       \r\n//SYSTSPRT DD SYSOUT=*            \r\n//SYSTSIN  DD *                   \r\nTSS WHOOWNS JESSPOOL(*)           \r\nTSS WHOOWNS JESSPOOL(SYS1.SPOOLA)\r\nTSS WHOHAS DSN(ABC.XYZ)"
  },
  {
    "Vendor": "ibm",
    "component/product": "logr",
    "type": "command",
    "info": "command to list all the active logstream on the system : D LOGGER,L\r\nCommand to list all the logstreams defined to any structure : D LOGGER,STR"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "commands",
    "info": "http://www.yves-colliard-software.homepage.t-online.de/YCOS%20-%20JES2-JES3%20Compare%20Commands.pdf"
  },
  {
    "Vendor": "ibm ",
    "component/product": "omvs",
    "type": "pathmode",
    "info": "pathmode is used in batchjcl to specifcy the permissions for a file\r\nSIRUSR  Specifies permission for a file owner to read the file.                                                \r\nSIWUSR  Specifies permission for a file owner to write to the file.                                                \r\nSIRGRP  Specifies permission for users in the file group class to read the file.                             \r\nSIROTH  Specifies permission for all users to read the file."
  },
  {
    "Vendor": "ibm",
    "component/product": "omvs",
    "type": "PATHOPTS",
    "info": "The PATHOPTS parameter of a DD statement specifies how an HFS file can be accessed and, depending upon whether it's new or existing, how it should be processed.                         \r\n                                                              \r\nOWRONLY Specifies that the program can open the file in write-only mode.                                      \r\nOCREAT  Specifies that the system is to create the file if it doesn't already exist.                                \r\nOTRUNC  Specifies that the system is to truncate the file length to zero if the file already exists and it was\r\n        successfully opened with ORDWR or OWRONLY (in other words, the file is reusable).                       "
  },
  {
    "Vendor": "IBM",
    "component/product": "CICS",
    "type": "command",
    "info": "/F CICSxxx,CEMT Set File(xxxx) open ena  \r\n/F CICSxxx,CEMT Set File(xxxx) close dis   \r\n\r\n/F CICSxxx,CEMT P Shut   -- Shutdown CICS."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "swapbar",
    "info": "/* REXX */\r\naddress ipsexec\r\n\"select pgm(isptl) parm(&zparm)\" "
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca-7",
    "type": "report cleanup",
    "info": "for LJOB,JOB=*\r\nX ALL\r\nF 'LJOB,JOB=*' 2 all\r\nF JOB=* 2 all\r\nf '----JCL----' 11 all\r\nf 'ID  MEMBER' 12 all\r\nf '                                             ' 1 all\r\nDEL NX ALL\r\n\r\nISREDTI MACRO for cleanup\r\n/* REXX */\r\nISREDIT MACRO\r\nISREDIT \"F 'LJOB,JOB=*' 2 all\" and so on"
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca-7",
    "type": "report cleanup",
    "info": "for LJOB,EXEC=N\r\nX ALL\r\nF '1LJOB,JOB=*,EXEC=N' 1 all\r\nF JOB=* 2 all\r\nf '----JCL----' 11 all\r\nf 'ID  MEMBER' 12 all\r\nf '                                             ' 1 all\r\nDEL NX ALL"
  },
  {
    "Vendor": "broadcom",
    "component/product": "MAI",
    "type": "report",
    "info": "Is there a place in MAI that we define all the available APPLID on the system for the users to see the options when they logon to TPX?\r\nWe use DEFLOGON/REPLOGON  commands to define applications. \r\n\r\nYou can issue the 'SH DEFLOGON\" to display what is defined.We can issue this command in cmd panel of MAI panel. issue CMD and invoke the command panel. Or issue /F solvestc,sh deflogon.\r\nhttps://techdocs.broadcom.com/us/en/ca-mainframe-software/intelligent-operations/ca-solve-access-session-management/5-0/administering/defining-and-administering-applications.html"
  },
  {
    "Vendor": "broadcom",
    "component/product": "MAI",
    "type": "report",
    "info": "How are applications defined to each user, it it in MAI or is it security? If it is security how does MAI know what is defined for each user?\r\nMost customers have the applications defined to the user via MAI.\r\nhttps://techdocs.broadcom.com/us/en/ca-mainframe-software/intelligent-operations/ca-solve-access-session-management/5-0/administering/how-you-implement-and-administer-mai/maintain-mai-session-lists.html"
  },
  {
    "Vendor": "broadcom",
    "component/product": "MAI",
    "type": "commands",
    "info": ""
  },
  {
    "Vendor": "ibm",
    "component/product": "sdsf",
    "type": "commands",
    "info": ":  SET DISPLAY LONG.  Using SET DISPLAY LONG causes a status line to be added that help you know what your prefix, filters, etc. are set to and looks like:"
  },
  {
    "Vendor": "Macro4",
    "component/product": "tubes",
    "type": "theory",
    "info": "1.\tHow does Tubes identify all the applid’s on the system, should we be letting the product know of all the applid? M4 - You will need to define each applid in the Tubes configuration. The product manuals will make it clear how to do this and we can supply sample parameter members for you to work with."
  },
  {
    "Vendor": "Macro4",
    "component/product": "tubes",
    "type": "theory",
    "info": "2.\tWhen a user logs on, he would have all the apps that he can access? Is the access to apps controlled within the TUBES product are is security involved? M4 - Tubes is highly configurable at quite a granular level. There are concepts of user profiles, group profiles, default profiles etc to determine what applications each user will see. Essentially though, a user will only see applications that they are authorised to have access to. Tubes has its own inbuilt security but also integrates with external security managers such as RACF, TOP SECRET and ACF2 so there is plenty of flexibility depending on how you want the system to be set up."
  },
  {
    "Vendor": "Macro4",
    "component/product": "tubes",
    "type": "theory",
    "info": "3.\tIn general what extent do we need support from our security team? M4 - It depends on what security you want to use. If you are already using RACF then a new security group would be set up that users would be allocated to. There are comprehensive product manuals and we can help guide you through the process depending on what security options you want to use."
  },
  {
    "Vendor": "Macro4",
    "component/product": "tubes",
    "type": "theory",
    "info": "4.\tWhat kind of support is provided by Macro-4 for Migration from MAI to Tubes? Do we get professional help to understand the current environment and help in planning and execution of the migration? M4 - Macro 4 are Tubes experts but have had no exposure to MAI. However, if Cognizant can describe how they need the Tubes system to be set up (including look and feel) then we can work with the team to achieve this. Cognizant would handle the analysis of the current MAI system and planning of the migration but Macro 4 will support you from the Tubes side of things."
  },
  {
    "Vendor": "ibm",
    "component/product": "netview",
    "type": "access",
    "info": "The NetView program provides the option of specifying whether password checking is performed by the NetView program or by an SAF security product such as RACF®. The method of checking is specified by the SECOPTS.OPERSEC statement in the CNMSTYLE member"
  },
  {
    "Vendor": "ibm",
    "component/product": "netview",
    "type": "access",
    "info": "If TSS security is being used then we need to get NCCF facility access for userid to access Netview.\r\nNCCF facility is IBM that comes included in Topsecret."
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "batch",
    "info": "When used IEKEFT01 and trying to execute batch jobs in SYSTSIN use\r\n EXECUTIL SEARCHDD(YES)\r\n%ABCD\r\nThis would try to search for ABCD to be searched in SYSEXEC first."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "theory",
    "info": "CA-11 equivalent : https://www.ibm.com/support/pages/should-eqqdelds-only-be-used-one-time-job\r\nEQQDELDS utility. If restarting second time from the RESTART panle EQQDELDS become obsolete."
  },
  {
    "Vendor": "ibm",
    "component/product": "sysplex",
    "type": "setup",
    "info": "batch job to setup a sysplex.\r\n//PARMSYSP JOB (ACCT),'PARALLEL SYSPLEX',CLASS=A,\r\n//             MSGCLASS=X,MSGLEVEL=(1,1),NOTIFY=&SYSUID\r\n//*\r\n//STEP1    EXEC PGM=IFASP1,REGION=2M\r\n//SYSPRINT DD SYSOUT=*\r\n//*\r\n//SYSIN    DD *\r\nSYSPLEXNAME SYS1\r\nMEMBERNAME MEMBER1\r\nCDS"
  },
  {
    "Vendor": "IBM",
    "component/product": "ansible",
    "type": "collections",
    "info": "Ansible Collections for \r\n\r\nUsing rest API\r\nHMC\r\nConsole\r\nzOSMF\r\nCICS\r\n\r\nUsing open ssh\r\nzOS core\r\nIMS\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "theory",
    "info": "To create a database when running other security products.\r\nhave IRRMIN00 in your SYS.LINKLIB as the JCL states? If so, I believe you can run IRRMIN00 from your TSS LPAR. \r\n\r\nThe newly created RACF database will be inactive, and you cannot run RACF commands against it on the TSS LPAR. If you boot up a RACF LPAR and use the new RACF database as the active database, then you can issue RACF commands to modify it."
  },
  {
    "Vendor": "Oracle",
    "component/product": "java",
    "type": "json",
    "info": "java script object notation. response from REst (representationl state transfer) API. Structured KEY VALUE pair.\r\nEx:\r\nNAME : Yugesh\r\nEducation : BE"
  },
  {
    "Vendor": "ibm",
    "component/product": "zERT",
    "type": "theory",
    "info": "z/OS encryption readiness technology.\r\na capability provided by the z/OS V2R3 Communications Server.\r\nUsing zERT, you have a single source of information to determine which traffic is cryptographically protected by TLS/SSL, IPSec and SSH, and which is not. This information is valuable for determining regulatory compliance and for identifying connections that might need stronger cryptographic protection."
  },
  {
    "Vendor": "ibm",
    "component/product": "dr",
    "type": "resilience",
    "info": "is the ability to Reapidly adapt the IT infrastructure for Planned and unplanned events during business operations. Which when not repsonded would cause a lot of damage to the company.\r\nThings to conisder while building a IT resilience Solution: \r\n1. How much time the business can wait before the IT operations are resumed? (RTO -- Recovery time objective).\r\n2. How long was my last unplanned outage? (DR -- Disater recovery)\r\n3. How much is the business willing to recreate? (RPO -- Recovery point objective)\r\n4. How much downtime for palnned outage can be managed? (CA -- Continous availabilit = High availability + Continous operatins)\r\n5. CYBER resilience -- protection against insider attacks +cyber attacks + other logical operations."
  },
  {
    "Vendor": "ibm",
    "component/product": "dr",
    "type": "theory",
    "info": "questions to be answered before a DR setup plan\r\n1. Will there be a big financial or revenue loss?\r\n2. Impact on company's reputation.\r\n3. What are regulatory requirements that the company have to comply with?\r\n4. "
  },
  {
    "Vendor": "ibm",
    "component/product": "dr",
    "type": "gdps",
    "info": "Freeze is the solution for - mirroring failure\r\nGM Journal Volumes provide a consistent restart point in case of a disaster?\r\nIn the event that the replication leg RS1 is lost : MITR and RL3 provides the high availability.\r\nI/O does nto occur on any devices while ELB is in affect\r\nHighly customizable GDPS Scripts is not available in GDPS HM\r\nCyber Resiliency is a part of IT resiliency\r\nHyperSwap is the capability to non-disruptively swap from primary to secondary copy in a Metro Mirror environment\r\n responsibility of the Kr -- Monitors the GDPS-managed resources in the recovery site, Automate reconfiguration of the recovery site"
  },
  {
    "Vendor": "ibm",
    "component/product": "CICS",
    "type": "startup",
    "info": "Check for DFHTABL in the JCL -- has the members for startup and shutdown of products that could run in CICS.\r\nCheck for PLTPI=xx value is the suffix for startup pgms. check for member DFHPLTxx in DFHTABL DD dataset.\r\nCheck for PLTSD=xx value is teh suffic for shutdown pgms. Check for member DFHPLTxx in DFHTABL DD dataset."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Topsecret",
    "type": "command",
    "info": "To delete a dataset access def: TSS REVOKE(ACID) DSN(A.B.C) ACC(x), where x is the type of access to delete, read/update/create/scratch/all. If a FAC is included in the \r\ndataset def it must be included in the REVOKE , E.G. TSS REVOKE(ACID) DSN(A.B.C) FAC(BEPRCICS) ACC(READ)."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Topsecret",
    "type": "command",
    "info": "TSS LIST(UPIN) DATA(ALL) – see if user is PSUSPENDED \r\nTSS REMOVE(UPIN) PSUSPEND – remove the PSUSPEND \r\nTSS REPLACE(UPIN) PASSWORD(newpw,,expire) – it will prompt user to enter a new pw "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Topsecret",
    "type": "command",
    "info": "To refresh an ACID do this: \r\n \r\n 1. TSS MODI CACHE(CLEAR) \r\n 2. TSS REFRESH(ACID) JOBNAME(*) ------refresh the Top Secret in memory cache after TSS updates. (X = jobname or * for all jobs)."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Topsecret",
    "type": "command",
    "info": "TSS WHOHAS CLASS(RESOURCE) - what ACIDS are connected to a resource - e.g. TSS WHOHAS OTRAN(SYMD), TSS WHOHAS OPERCMDS(*) DATA MASK, TSS WHOHAS DSN(SYS1.MORY)\r\nTSS WHOOWNS CLASS(RESOURCE) - what dept owns a resource (must be owned first before it can be protected) - e.g. "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Topsecret",
    "type": "command",
    "info": "To define a resource and who can access it: \r\n\r\nTSS ADD(DSMS) LOGSTRM(SYSPLEX.OPERLOG)  ----->>>> DSMS is the resource owner (the DEPT), LOGSTRM is the resource class, SYSPLEX.OPERLOG is the resource name          \r\nTSS PE(A93LNZZ) LOGSTRM(SYSPLEX.OPERLOG) ACC(ALL)"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Topsecret",
    "type": "command",
    "info": "TSS PE(ACIDNAME) DSN(SYS8.**) ACCESS(ALL)  - user can do anything\r\nTSS PE(ACIDNAME) DSN(SYS8.**) ACCESS(UPDATE)  - user can read and update \r\nTSS PE(ACIDNAME) DSN(SYS8.**) ACCESS(READ) - the default if you don’t specify any access level \r\nTSS REVOKE(ACIDNAME) DSN(SYS8.**) ACCESS(UPDATE) – remove update access only \r\nTSS WHOHAS DSN(SYS8) – find out who has access to SYS8.* \r\nTSS WHOHAS OTRAN(SASE) - find out who has access to CICS transaction SASE \r\nTSS DELETE(ACID) – delete a user from TSS \r\nTSS REMOVE(ACID) PROFILE(NAME) – remove a user from access to a profile  \r\nTSS ADD(ACID) PROFILE(NAME) – add a user to a profile  \r\nTSS PE(ACID) OTRAN(CECI) ACC(ALL) - provide access to a CICS transaction \r\nTSS ADDTO(DTRANC) OTRAN(SYSV) - add a new CICS transaction to the Top Secret security file (protects it) \r\nTSS WHOOWNS SERVAUTH(EZB.) - see what DEPT owns EZB \r\nTSS WHOHAS SDSF(ISF.CONNECT.**) - see who has access to that resource in class SDSF \r\nTSS ADD(DSMS) SDSF(ISF.CONNECT.**) - create a resource called ISF.CONNECT.** in class SDSF - protects the resource and must be done before anyone can have access to it. \r\nTSS PE(A92TQZZ) SDSF(ISF.CONNECT.**) ACC(READ) - enable access to this resource for ACID A92TQZZ. "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "Topsecret",
    "type": "commands",
    "info": "How to define commands for SMP/E access: \r\ntss pe(a93lnzz) ibmfac(gim.cmd.applycheck) acc(read) \r\ntss pe(a93lnzz) ibmfac(gim.cmd.acceptcheck) acc(read)\r\ntss pe(a93lnzz) ibmfac(gim.cmd.restore) acc(read)    \r\ntss pe(a93lnzz) ibmfac(gim.cmd.accept) acc(read)     \r\ntss pe(a93lnzz) ibmfac(gim.cmd.reject) acc(read)     \r\ntss pe(a93lnzz) ibmfac(gim.cmd.apply) acc(read)      \r\ntss pe(a93lnzz) ibmfac(gim.cmd.receive) acc(read)    \r\ntss pe(a93lnzz) ibmfac(gim.cmd.set) acc(read)    \r\n\r\nThere is a an IBMFAC resource called GIM. It's owner is DIBMFAC. Within it is XAUTH=GIM.CMD. and ACID EUTSOEXP has read access to it. That means any user who is part of \r\nEUTSOEXP can do any SMP/E commands. EUTSOEXP also has resource GIM.PGM. in it. "
  },
  {
    "Vendor": "ibm ",
    "component/product": "SA+netview",
    "type": "setup",
    "info": "When migrating from any automation tool to SA+Netview. We need to ensure to disable the parms that would allow SA+Netview to write the message back to the log when the AUTOPROC task is stopped.\r\n(a)\tNeed to add the below code in INGMSGU1 member in DSIPARM, for automation not to wait for the action messages and not store them.\r\n\r\nIF ACTIONMG(1) = '1'                                                \r\nTHEN DOMACTION(NODELMSG) HOLD(DISABLE) CONTINUE(Y);    \r\n\r\n(b)\tAlerts at the termination of the task could be avoided if we set the value of the DEFAULT HOLD parameter in the CNMST* member in DSIPARM.\r\nauxInitcmd.HOLD = DEFAULTS HOLD = DISABLE\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "cbac",
    "type": "setup",
    "info": "CBAC does not have an MVS started task that runs in a separate address space. The CICSSTARTMODE parameter is used to tell CBAC that when it goes thru startup processing in the CICS region, it should either “SET” all the resources (files, etc.) to the last known/requested state (as recorded in the CBAC control file for the region), or “UPDATE” the CBAC control file for the region with the current state of known (to CBAC) resources. \r\n\r\nNormally, when CBAC is started via PLTPI, the “SET” value is used. This is the default when CBAC is started via PLTPI. If CBAC is being started later from a 3270 terminal using the KBKM transaction, after the region has been up a while, the “UPDATE” value is normally used. This is the default when CBAC is started via the KBKM transaction."
  },
  {
    "Vendor": "ibm",
    "component/product": "cbac",
    "type": "command",
    "info": "We believe that you can shut down the CICS region, via the CBAC RUNCEMT transaction.  CBAC passes an EXEC CICS LINK command to DFHEMTA and passes it the command.  This would look like: \r\n\r\nRUNCEMT,CICS(AHL24X7),COMMAND(CEMT PERFORM SHUTDOWN ), NOTACTIVATE(CONTINUE)"
  },
  {
    "Vendor": "compuware",
    "component/product": "fileaid",
    "type": "usage",
    "info": "Ah yes, File-Aid, which was very successful and so expensive that it inspired IBM's FIle Manager and CA's File Master.\r\n\r\nIf File-Aid is anything like File Master which I wrote a few lines of code for decades ago, then it will call PAM all the time.  Yes, it will cope with PAM not being in the system without abending or otherwise complaining.  I expect it is also looking for and would call if found the Librarian interface module (used to use SYBSYS=LAM for automatic JCL access for that one) - at least that what FIle Master did.  Actually, it might only try LAM if PAM didn't work first.\r\n\r\nAnyway, we're not here to help you understand the workloads that might happen to run on your system(s), but to assist with IZSAM problems and fix IZSAM defects, and neither of these things appear to be present in this case.\r\n\r\nSince no IZSAM issues have been raised, I expect we may now close this case."
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "exit",
    "info": "smf exit management facility(zemf). avialable on cbt tape. zemfmstr"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "optimizer",
    "type": "report",
    "info": "https://knowledge.broadcom.com/external/article?articleNumber=68481"
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "upgrade",
    "info": "High level steps to upgrade a zOS version.\r\n1. Check for the supported version that you are planning to upgrade to.\r\n2. Apply Co-exisstence and fallback maintenance. Run the FIXCAT for any preventive maintenance for the upgrade. Apply the preventive maintenance.\r\n4. Run a compatibility check for all the ISV products running on the system. \r\n5. Apply the required maintenance or upgrade the product to version compatible with.\r\n6. Identify the major changes in zOS for the new release (ex: for z/OS V2R5 HFS to zFS, SDSF from ISFPRMxx to RACF rules. TN3270 AT-TLS, UCSA is not supported with V2.4, SMTP to CSSMTP) and other nitty gritties going through the updrade manual.\r\n7. Place a request in shopz for the zOS release as a server pac order.(we can do a CBPDO order).\r\n8. use the CUSTOMPAC Installation panels install the server pac. (we need to provide the volumes, catalog, naming convention and many other parms) or it depends on site to site now a days we get a dump with the smp/e and everything pax file and your restore it.\r\n9. Once you have new RES pack ready. \r\n10. Plan to IPL the test system with the new respack. (need to update all the parmlibs and proclibs as required any catalog or security changes bases on ther version of zOS) and then apply any usermods. Fix any issues wrt to the stc and other errors in the syslog.\r\n11. Check with other tech team (cics, db2, network, security for any usermods or changes as required and have them impemented.\r\n12. "
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "NFS",
    "info": "Network file system(NFS).\r\nNFS used to access z/OS UNIX System Services (z/OS UNIX) data, which conforms to portable operating system interface (POSIX) standards.\r\nThe z/OS NFS server is a Virtual File Server with regards to z/OS UNIX, a POSIX application with regards to z/OS Language Environment®, and a generic server with regards to z/OS Communications Server."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA-7",
    "type": "security",
    "info": "to check the current security setup issue the command /DISPLAY,ST=SEC"
  },
  {
    "Vendor": "ibm",
    "component/product": "cbac",
    "type": "migration",
    "info": "Could you please let me know how to migrate the contents of CA-DADS Plus control file to IBM CBAC control file? \r\n\r\nThe recommended method is to use the CBAC File Maintenance Utility (FMU) to add a record for each file, transient data queue, transaction ID, and program in the CICS region that you want to be processed by CBAC. You can also do this via the CBAC ISPF Administration Interface but it should be easier/faster to use the FMU. Also, if you decide you want to start over again (i.e., delete a control file and repopulate it, you can use the same JCL member you used the first time.\r\n\r\nThis is a manual process. For example, if you have a CICS region that has 100 application files that you want CBAC to control, the recommended method is to use the FMU to process 100 FMU “ADD FILE” commands, i.e., one command for each file record to be added."
  },
  {
    "Vendor": "ibm",
    "component/product": "cbac",
    "type": "migration",
    "info": "If  it is indeed the region control file, there are several ways to populate      it after it has been initialized. They can use the CBAC File Maintenance  Utility (FMU)\r\n\r\nMay I know once the control file is initialized, using CBAC FMU Update Region Filerequest(YES) option will populate the contents of the CICS region files along with the last status it was used. In that case would I still need the MIGRATE JCL(CBKMIGRT) run to copy the contents of the file control of CADADS to IBM CBAC.\r\n\r\nAs previously mentioned, the options on the FMU “UPDATE REGION” command that control the dynamic creation of CBAC control file records is determined by the UPDATE REGION command parameters that begin with “UNDEFINED” (e.g., “UNDEFINEDFILE”, UNDEFINEDTDQUEUE, etc.), as well as the CREATERECORD and SYSCREATE command. Please read the documentation for those parameters in order to fully understand how/when control file records are dynamically created.\r\n\r\nDepending on CBAC’s ability to dynamically create a control file record for a CICS object (file, transient data queue, etc.) when an attempt is made to process that object when it is not currently defined to CBAC has its limitations. For example, dynamically\r\n\r\ncreating an object record for an application file in the CBAC control file does not give you the ability to provide primary or alternate data set names values for the newly created file object record.  \r\n\r\nThe CBKMIGRT sample program does not have any direct relationship to dynamically creating CBAC control file records. It’s purpose is to give you sample code that you can modify to convert commands issued by another product’s equivalent of the CBAC Batch Request Utility (BRU) into commands that can be used with the CBAC BRU. It is not used to copy records from another product’s control file to the CBAC control file."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "manuals",
    "info": "https://www.ibm.com/docs/en/workload-automation/10.1.0?topic=messages-eqqz000-eqqz908"
  },
  {
    "Vendor": "ibm",
    "component/product": "RACF",
    "type": "tss 2 racf",
    "info": "migrating from tss to racf questionnaire\r\nhttps://form.jotform.com/231512925776360"
  },
  {
    "Vendor": "compuware",
    "component/product": "fileaid",
    "type": "panvalet usage",
    "info": "On the Primary Option panel of File-AID, type command: TSO XVJLOOK.  If FACM00 parameter ENABLE_PANVALET_SUPPORT=Y (which is the default), then File-AID calls Panvalet to determine if each dataset is a Panvalet dataset. So, even when processing non-Panvalet datasets, you will see calls to the PANVALET modules."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "difference",
    "info": "1.\tNje/RJE jobs have to re-done as the jes3 and jes2 nje are completely different – applications needs to check the logic and rewrite. JES3 has an inbuilt facility to trigger jobs in multiple lpars. (SMF record for the NJE team).  We need to write a job and get the details of jobs running the nje/rje."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "setup",
    "info": "DASD connected tracker should work without XCF or NCF type of tracker. \r\nEQQSUDS ddname (of tracker ) is being shared with controller as submit/release ddname in the controller (or as DASD destination in ROUTOPTS), same is true with EQQJCLIB, EQQINCWK."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "setup",
    "info": "EQQW047W  SUBMIT/RELEASE RECORDS WERE LOST BECAUSE THE SUBMIT/RELEASE DATA SET BECAME FILLED WITH UNPROCESSED RECORDS   during the initial setup of DASD communication."
  },
  {
    "Vendor": "ibm",
    "component/product": "omegamon",
    "type": "setup",
    "info": "Security setup for logon to Omegmon in TSS.\r\nThe 1C-06 violations indicate the acid is not authorized to the facility (with ID=21). To find the facility needed, do one of the following:\r\n1) Issue TSS MODI FAC(ALL) and look for the facility with ID=21.\r\n2) Run the TSSUTIL report with the LONG option. There will be a FACILITY column that has the facility in it. (Without the LONG option, only the facility ID is shown in the FFM column.)\r\nOnce you know the facility, add it to the acid:\r\nTSS ADD(xxxxxxx) FACILITY(fac)\r\nTSS REFRESH(xxxxxxx) JOBNAME(*)\r\nWhere ‘fac’ is the facility needed. \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "hardware",
    "type": "links",
    "info": "Link to check for IBM Mainframe hardware types."
  },
  {
    "Vendor": "tonesoft",
    "component/product": "trx",
    "type": "setup",
    "info": "if we want to know from where the default dataset allocaitons are happening for SYSPROC, SYSEXEC and other DD while logon, please chekc the output from TSO TRX LIST and find the PROFILE name next to dataset in the cocatenation,"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "setup",
    "info": "If we use RCLEAN=YES during the setup using XCF for communicaitons. then we dont need to setup the groups in couple datasets. "
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "setup",
    "info": "Datastore is used if we are restarting a job from the central system to the tracker system."
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "upgrade",
    "info": "Workflow for zOS V25 to zOS V3.1\r\nThe preferred way is for you to install the z/OS Coexistence PTFs which are necessary for z/OS, on your system using FIXCAT IBM.Coexistence.z/OS.*. In that FIXCAT, the current level of the z/OS Upgrade Workflow(s) will be installed via a PTF into your /usr/lpp/bcp/upgrade directory. The name of the Workflows (including the z16 Workflow!) are pretty obvious. For instance, zOS3.1_From_zOS2.4_Upgrade_Workflow.xml .  Just point z/OSMF Workflow to that location.\r\n\r\nThis process is described in IBM Documentation which is here: https://lnkd.in/eiYVUSPU.\r\n#IBMz #IBMzOS #IBMzOSMF"
  },
  {
    "Vendor": "beta systems",
    "component/product": "xinfo",
    "type": "theory",
    "info": "This software can help identify all of the batch linkage that can break as jobs/flows are moved to other scheduling tools and/or environments. It can also identify all of the dead jobs, contentions between jobs and several other situations that can be cleaned up. Basically, it can help clean up the batch schedules and reduce research of the schedules to make these conversations/migrations easier."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "tss",
    "type": "security",
    "info": "setting group and profile defintions.\r\nhttps://knowledge.broadcom.com/external/article/103502/add-a-group-and-profile-on-same-top-secr.html\r\n\r\nTSS ADD(acid) PROFILE(IZUADMIN,IZADMNGP)\r\nwill add IZUADMIN as a profile and IZAMDNGP as a group. "
  },
  {
    "Vendor": "ibm",
    "component/product": "rmm",
    "type": "conversion ",
    "info": "if converting from CA-1 to RMM\r\nensure that the subsystem during the migraiton is defined as the last subsystem in the IEFSSNxx. \r\nThis would Help CA-1 to start first and RMM would not worry much about the system tapes."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "ca7",
    "type": "connectivity",
    "info": "when JCL are using NODE=xxxxx and submitting jobs to other servers.\r\nThe NODE statement points to the CCI node name. This name is defined on the server where the UJMA agent is running. This is not defined to CA 7. You can look in the CCITCGPW or CCITCPSSL task you are running for the nodes in the NODE=xxxxxxx parm to see what server the UJMA is running with that CCI node name."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "ca7",
    "type": "connectivity",
    "info": "CCI running on the mainframe can connect to CCI running on different lpars as indicated here below. These definitions are found in the CCIPARMS dataset.\r\n\r\nCAICCI CAICCI   CONNECTED TO CAICCI CCISY0  -- statement for CCITCPGW\r\n\r\nCAICCI CAICCI   CONNECTED TO CAICCI CCISY1  -- statement for CCITCPGW  \r\n\r\n---  \r\n\r\nCCI running on the mainframe can also connect to CCI running the UJMA agent on distributed server (windows, linux, etc). These connection are usually driven from the distributed server side, but they can be driven from the CCIPARMS dataset also:\r\n\r\n08:24:43  CAS9603I - CAICCI CAICCI   CONNECTED TO CAICCI VA1PXAW2              \r\n08:24:44  CAS9855I Task 7 has connection from il3qlwlp113(10.76.138.137):13445 \r\n08:24:44  CAS9603I - CAICCI CAICCI   CONNECTED TO CAICCI IL3QXASW              \r\n08:24:44  CAS9855I Task 8 has connection from il3dlwl113dp(10.76.138.95):58611 "
  },
  {
    "Vendor": "Broadcom",
    "component/product": "CA7",
    "type": "connectivity",
    "info": "CA-7 can have agents running on different server and we can submit jobs. It also has UJMA (Universal job management agent).\r\nUJMA is a component of CA-7. TO see all the UJMA agents connect check CCITCPGW task of CA-Common services and check its output."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "ca7",
    "type": "connectivity",
    "info": "In our CA7TOUNI(or similar proc) we specify the NODE=xxxxxx. The PGM will attempt to send the job to the NODE VIA CICTCPGW. If the NODE is connected and UJMA is running, CCI will send it there."
  },
  {
    "Vendor": "ibm",
    "component/product": "zsam",
    "type": "theory",
    "info": "to get a report of import logs. Check the option \"IQ Import logs\" in Administration reports.\r\n\r\nwhen you delete libraries from your systems, you need to run an IQ scan again and import the data using FULLREMATCH=Y as this is a parameter that will mark delete libraries in the Repository that are not in the IQ data. Marking them deleted means they will no longer show in the Reports. To physically delete them from the Repository they need to run the Physical Delete job HSISPDEL."
  },
  {
    "Vendor": "Broadcom",
    "component/product": "ca7",
    "type": "autosys",
    "info": "submitting jobs from CA-7 to AUTOSYS(distributed scheduling - broadcom product).\r\nCA7 jobs use parameters in a  JCL SYSIN DD statement that reference : NODE and SUBFILE to direct the (CCI) communication session to the appropriate Autosys production server and introduce an event (Autosys Job name).     NODE references an Autosys ALIAS (XXXXXXXX – YY or  VAxxxxASW - APy) , SUBFILE is the specific Autosys job to run.  Each CA7 job also has a credential stored in a Security.CNTL PDS dataset used to authenticate on the Autosys server to run the job."
  },
  {
    "Vendor": "IBM",
    "component/product": "rmm",
    "type": "CA-1 to RMM",
    "info": "Question 1): Could you kindly confirm whether we can remove the IEFSSNxx member & dynamically activate the DFRM by issuing command. And also please confirm we can bring up DFRMM STC's without activating the DFRM. \r\n\r\nAnswer 1) : Yes, as you will see the instructions in RMM I&C guide, it instructs you to issue the SETSSI command and then it asks you to update the IEFSSNxx if you would like the SSI activated with IPL. If you do not want to have the DFRM SSI activated with IPL, you will need to issue the SETSSI command before you bring up DFRMM\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmm",
    "type": "CA-1 to RMM",
    "info": "Question 2) : For enabling the RMM in IFAPRD member, do we need to enable it along with IPL. If we enable in IFAPRDxx member, whether the system will consider the DFRM subsystem & we will get any WTOR for DFRMM during the IPL.\r\n\r\nAnswer 2) : You can define the enablement policy for DFSMSrmm with the IPL or after. It only verifies the enablement policy when DFRMM subsystem is activated and DFRMM started task has started.\r\nSo, you can update your IFAPRDxx parmlib member and enable FEATURENAME(DFSMSRMM) with the IPL. Or if you prefer, you can update your IFAPRDxx after the IPL and before you issue the SETSSI, issue SET PROD=xx which refers to your IFAPRDxx.\r\n"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "tss",
    "type": "theory",
    "info": "The PROTECTED attribute when added to an ACID makes the user unable to logon to system. it is usually set on STC ID's"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "Condition codes",
    "info": "If we need jobs with a specific CC to be marked as normal completion, follow the below steps.\r\nif we need ABC with RC=08  or XYZ with RC=145 to 200 maked as successful in IzWS\r\nEQQPARM DD:\r\nContorller parm\r\n\r\nINCLUDE NOERROR(MEM1, MEM2)  -- reduce the lines in Contorller parm. we can write the statements in a different member.\r\njobname.stepname.procstepname.errorcode\r\n\r\njobname == jobname\r\nstepname == EXEC PROC step name\r\nPROCSTEPNAME == EXEC PGM setp name\r\nERRORCODE == \r\n\r\nNOERROR LIST(jobname.stepname.procstepname.errorcode)"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "email",
    "info": "if we need to send an email when a job abend.\r\nuse the ALERTS steatment with MAIL option in the Controller PARMLIB."
  },
  {
    "Vendor": "ibm",
    "component/product": "racf",
    "type": "migration",
    "info": "TSS to RACF Migration.\r\nConvert TSS User ACIDs to RACF Userids\r\nConvert Departments, Divisions, and Zones into RACF Owning Groups\r\nConvert PROFILES into RACF Permission Groups\r\nCreate Groups for HLQs That Are Not Currently Defined for DSN HLQs (Required by RACF)\r\nConverts All XAUTH Records and Ownership Records into Dataset and General Resource Rules\r\nBuild Executable RACF Commands into PDS for Later Execution\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "condition steps",
    "info": "How to run steps for different APPLID's for the same job. Similar to the //#JI,SCH=000 statement of CA-7\r\n//Jobcard\r\n//*%OPC SCAN\r\n//*%OPC BEGIN ACTION=INCLUDE,\r\n//*%OPC       COMP=(&OADID..EQ.applid) --- checks for APPLID is equal to applid and runs the next statements.\r\n//STEP1 EXEC PGM=xxxx\r\n//STEP2 EXEC PGM=xxxx\r\n//*%OPC END ACTION=INCLUDE\r\n//*%OPC BEGIN ACTION=INCLUDE2,\r\n//*%OPC       COMP=(&OADID..EQ.applid1) --- checks for APPLID is equal to applid1 and runs the next statements.\r\n//STEP3 EXEC PGM=xxxx\r\n//STEP4 EXEC PGM=xxxx\r\n//*%OPC END ACTION=INCLUDE"
  },
  {
    "Vendor": "ibm",
    "component/product": "db2",
    "type": "security",
    "info": "DB2 security internal or external. and it effects any security migration."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "noerror",
    "info": "To use the NOERROR keyword for a specific job or started task steps, the even writer options, as specified in the EWTROPTS can be in tracker parms also.  initializaiton statement, must be set as follows\r\nThe STEPEVENTS keyword must either spcifiy ALL or ZERO\r\nThe RETCODE keyword must specify HIGHEST."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "commands",
    "info": "Command to refresh the NOERROR conditions\r\nF TWSC,NEWNOERR  -- TWSC is the controller\r\nF TWSC,NOERRLST"
  },
  {
    "Vendor": "ibm ",
    "component/product": "izws",
    "type": "theory",
    "info": "email notifical for failed jobs.\r\nSending an email when an alert condition occurs:\r\n1. Add the EQQSMTP and EQQEMAIL DD statements to the Z controller JCL procedure. \r\n      EQQPCS01 creates the EQQSMTP Dataset\r\n      //EQQSMTP DD SYSOUT=(B,SMTP)  in the controller jcl\r\n3. Set the MAIL parameter in the ALERTS statement. \r\n4. Ensure that the MAILOPTS MAILEXTWRT is set to the actual JES external writer used by the Communication Server SMTP (CSSMTP).\r\n5. Optionally store your customized JCL member, to be used for sending the emails, in the EQQEMAIL data s"
  },
  {
    "Vendor": "ibm",
    "component/product": "cics",
    "type": "error",
    "info": "DFHWB1008 xxxxxxxx CICS Web environment initialization is complete.                                          \r\n +DFHSR0618 xxxxxxxx An illegal macro call or reference to the CSA or TCA has caused the abend which follows   \r\n +DFHAP0001 xxxxxxxx An abend (code 0C4/ASRD) has occurred at offset X'00000004' in module CBKCMNDS.           \r\n +DFHME0116 xxxxxxxx \r\n\r\nThis error occurs when a commands members for a tool is not linkedited to work with the CICS version running on the system.\r\n\r\nwe can check the commands member here CBKCMNDS to see the links are established or not.\r\n\r\nwe would have to check the apply job for the tool or the linkedit job ran to establish connectivity with CICS.                                                                                           \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "email notificaiton -1",
    "info": "below are the steps to be followed for email notificaiton through email in IzWS.\r\n\r\nEnsure CSSMTP installed on a jesplex where the controller runs\r\n\r\n2. set the controller parameters\r\n\r\nALERTS   MAIL    (ERROROPER:MAILERR)\r\nMAILOPTS MAILFROM('MichaelA@hcl.com')\r\n         MAILDOMAIN('hcl.com')       \r\n         MAILEXTWRT('WRPLXI')    <---- jes external writer\r\n3. add in the controller proc\r\n//EQQSMTP   DD  SYSOUT=(S,INTRDR)\r\n//EQQEMAIL  DD  DISP=SHR,DSN=ZWS.TWS95C.V9R5.EMAIL\r\n4. create a RULES -  ZWS.TWS95C.V9R5.EMAIL(RULES)\r\nFILTER(&ALERCOND=ERROROPER)                                             \r\nHEADER(                                                                 \r\n  TO: MichaelA@hcl.com                                                  \r\n  Subject: Job &OJOBNAME in error)                                      \r\nTEXTMEMBER(MAILERR)                                                     \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "email notificaiton -2",
    "info": "5. create mail text - ZWS.TWS95C.V9R5.EMAIL(MAILERR)    \r\nError found in Occurence with token: &OTOKEN     \r\nApplication is: &OADID   &ODMY1                  \r\nThe operation number is: &OOPNO                  \r\nThe job is running on workstation: &OWSID        \r\nJobid: &OJOBID and Jobname: &OJOBNAME            \r\nThe error code is: &OERRCODE                     \r\n\r\nEQQEMAIL dataset attributes can be found in the EQQPCS01 installation JCL - ZWS.DA.V9R5.SEQQSAMP(EQQPCS01)\r\n\r\n//ALLOCSTC EXEC PGM=IEFBR14                                            \r\n//*                                                                    \r\n//SYSPRINT DD SYSOUT=&FPCLA                                            \r\n//SYSUT1   DD DSN=&PFIX..EMAIL,                                        \r\n//         DCB=(RECFM=FB,BLKSIZE=3120,LRECL=80),UNIT=&UNIT,            \r\n//         SPACE=(CYL,(1,1,10)),DISP=(NEW,CATLG)                       \r\n//*      \r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "email notificaiton -3",
    "info": "\r\nList of Variables available:\r\nALERCOND - Alert condition\r\nOADID    - Application ID\r\nOADOWNER - Occurence owner\r\nOAUGROUP - Authority group\r\nODMY1    - Occurence input arrival date in DDMMYY format\r\nOERRCODE - Error Code\r\nOJOBID   - JOB IB\r\nOJOBNAME - Operation job name\r\nOOPNO    - Operation number within the occurence, right-justified and padded with zeros\r\nOTOKEN   - Occurence Token\r\nOWSID    - Workstation ID for current operation\r\nRESNAME  - Resource Name\r\nRESWTTM  - Resource Waiting Time\r\nTASKNAME - Task Name"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "exit",
    "info": "IEFACTRT -- receives control on the normal or abnormal termination of each job step and job. Multiple products uses this exit to gather job realted information. Products like CA7, IzWS, OPSMVS, STROBE"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "MAI",
    "type": "theory",
    "info": "/ command on the mai panel to check for all teh available commands"
  },
  {
    "Vendor": "Broadcom",
    "component/product": "MAI",
    "type": "theory",
    "info": "/files -- to check for datasets for MAI\r\nwe can use the UAMS dataset and then use fileaid to look into it."
  },
  {
    "Vendor": "IBM",
    "component/product": "izws",
    "type": "ETT triggers",
    "info": "For the ETT (event based triggers) to work, IBM recommend to  change “SRREAD=NO  “ to “SRREAD=YES “ and re assemble the exit “IEFU83”"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "trigger",
    "info": "when we are trying to use the ETT trigger to get a job submitted when a dataset is created. we need to ensure that the ETT trigger option is activated in OPTION 9 :  sercvice functions or in the TRACKER parmlib.\r\n\r\nalso, ensure that the exits speceficed in the SMFPRMxx are added to the PROGxx exit statements.\r\n\r\nin tracker we need to have EQQJCL. Define the dataset to be monitored to the IzWS using teh EQQLSJCL default job name. ETT actiosn needs to be defined in the JOb definition. Once the EQQLSJCL has been run the dataset poiting to EQQJCL DD in tracker stc. the member is EQQDSLST in the JCL library. In the shared environment we need to make sure all the tracker are using the same EQQJCL DD.\r\nOnce F trackername,NEWDSLST."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "iefactrt-1",
    "info": "What I suggest is to assemble manually the IEFACTRT exit using a different load module name like TWSACTRT and putting\r\nthe load module into linklist instead of LPALIB.\r\nThis is a sample of the JCL I use to assemble the exits (it assembles and links all 3 exits but you would just need to run the step ACTRT  after the PROC::\r\n//ASSEM    PROC                                                   \r\n//ASMH     EXEC PGM=ASMA90,PARM='NODECK,OBJECT,XREF(SHORT),LIST'  \r\n//SYSPRINT DD  SYSOUT=*                                           \r\n//SYSLIB   DD  DISP=SHR,DSN=SYS1.MACLIB,UNIT=SYSDA                \r\n//         DD  DISP=SHR,DSN=SYS1.MODGEN,UNIT=SYSDA                \r\n//         DD  DISP=SHR,DSN=ZWS.DA.V10R1M0.SEQQMAC0               \r\n//SYSIN    DD  DISP=SHR,DSN=ZWS.DA.V10R1M0.SEQQSAMP(&SOURCE)      \r\n//SYSLIN   DD  DISP=SHR,DSN=your.OBJ(&OBJECT)                     \r\n//SYSUT1   DD  UNIT=SYSDA,SPACE=(CYL,(2,1))                       \r\n//*                                                               \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "iefactrt-2",
    "info": "//LKED     EXEC PGM=IEWL,REGION=2M,                               \r\n//         PARM='NCAL,LIST,LET,RENT,SIZE=(400K,80K)'              \r\n//SYSPRINT  DD  SYSOUT=*                                          \r\n//SYSUT1    DD  UNIT=SYSDA,SPACE=(CYL,(2,1))                      \r\n//SYSLMOD   DD  DISP=SHR,DSN=your.linklib                         \r\n//EXITLIB   DD  DISP=SHR,DSN=your.obj                             \r\n//END      PEND                                                   \r\n//*                                                              \r\n//ACTRT    EXEC ASSEM,SOURCE=EQQACTR1,OBJECT=TWSACTRT      \r\n//LKED.SYSLIN    DD  *                                     \r\n INCLUDE EXITLIB(TWSACTRT)                                 \r\n NAME    TWSACTRT(R)                                       \r\n/*                                                         \r\n//UJI      EXEC ASSEM,SOURCE=EQQUJI1,OBJECT=TWSUJI         \r\n//LKED.SYSLIN    DD  *                                     \r\n INCLUDE EXITLIB(TWSUJI)                                   \r\n NAME    TWSUJI1(R)                                        \r\n/*                                                         \r\n//U83      EXEC ASSEM,SOURCE=EQQU831,OBJECT=TWSU83         \r\n//LKED.SYSLIN    DD  *                                     \r\n INCLUDE EXITLIB(TWSU83)                                   \r\n NAME    TWSU831(R)                                        \r\n/*                                                        \r\n \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "iefactrt-3",
    "info": "This used an \"object\" library which is just a small PDS you can allocate with LRECL=80 and RECFM=FB.  1 cylinder will be more than enough.\r\nAfter assembling and getting the TWSACTRT load module , check the size in your linklist library and see if it is F50 or something else.\r\nYou will need to run an F LLA,REFRESH command.\r\nThen in the parmlib member that you created during the meeting   PROGTT,  leave in the 2 delete statements for IEFACTRT and OPMVACEX. and change the EXIT ADD statement for SYSJES3.IEFACTRT to be MODULE(TWSACTRT) followed by FIRST\r\nbasically:\r\nEXIT ADD EXITNAME(SYSJES3.IEFACTRT) MODNAME(TWSACTRT)  FIRST\r\nThen issue command SET PROG=TT\r\nThe command  D PROG,EXIT,EX=SYSJES3.IEFACTRT,DIAG should just show the load module TWSACTRT\r\nCycle the tracker at this point\r\nThen submit a job from outside of workload scheduler for z/OS  and see if in the EQQEVDS file of the tracker you\r\nsee a B3J record.\r\nIf you do, the issue may be solved.  You can then submit a job from zWS and verify that it tracks to completed status.\r\n\r\nIf you are still not getting the B3J record  I will need to do another screen share with you and if that doesn't resolve\r\nthe issue I will need to ask my level 3 team to assist and suggest some documentation to collect."
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca-7",
    "type": "exit",
    "info": "CA-7 use exit SASSU84 to collect the job status from the system. it is dynamicaly added when CAS9 is started."
  },
  {
    "Vendor": "ibm",
    "component/product": "cbt",
    "type": "free tools",
    "info": "www.cbttape.org"
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca7",
    "type": "status",
    "info": "job that we can run to identify the status of CA-7\r\n//STEP1 EXEC PGM=CAL2ENVR\r\n//STEPLIB DD DISP=SHR,DSN=ca7 loadlib\r\n//SYSPRINT DD SYSOUT=*"
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca7",
    "type": "exit",
    "info": "TSO CAISMFU -- to list the exit for CA products."
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca7",
    "type": "exit",
    "info": "CA 7 tracks jobs via the SMF exit SASSU84 based on SMF TYPE 30 records.\r\n\r\nCA 7 does not make use of the  IEFACTRT SMF exit. "
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca7",
    "type": "env",
    "info": "//AL2ENVR JOB (ACCTINFO),PGMR,CLASS=A                                 \r\n//*----------------------------------------------------------------***\r\n//* JOB TO REPORT STATUS OF CA 7 SYSTEM ENVIRONMENT                   \r\n//*                                                                   \r\n//* NOTE : CHANGE THE JOB CARD AND NAME OF CA 7 LOAD LIBRARY          \r\n//*----------------------------------------------------------------***\r\n//*                                                                   \r\n//STEP0001  EXEC PGM=CAL2ENVR                                         \r\n//STEPLIB   DD  DISP=SHR,DSN=cai.CAL2LOAD        <== CA 7 LOADLIB     \r\n//SYSPRINT  DD  SYSOUT=*  "
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca7",
    "type": "exit",
    "info": "CA-7 not tracking the job status.\r\nAs we discussed on the  Zoom link with you today we recreated issue on your Test system where you made the changes to the IBM SMF exits IEFU83 for module TWSU831 and IEFUJI for module TWSUJI1 like you did in production.\r\n\r\nYou ran a CA 7 job on TEST system and job was submitted and ended successfully but was still in RDY queue and not tracked by CA 7. Then you backed out the changes to the IBM SMF exits and ran same CA7 job on TEST system and job ended successfully and was tracked by CA 7 as completed.\r\n\r\nAs we concluded on the Zoom call issue seems to be with the changes made to IBM SMF exits for TWS modules and somehow those changes are overlaying SMF indicator 7 thus causing jobs not to be tracked in CA 7.\r\n\r\nWe will need to determine if it is feasible to change the SMF indicator from 7 to another value in order to for jobs to be tracked by CA 7 if  changes are made to  the IBM SMF exits for the TWS modules in order to resolve this issue.\r\n\r\nIt is risky changing the SMF indicator from 7 to another value as this could other issues to CA 7 job processing.  We will need to research this further and update this case when our research is complete.  "
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca7",
    "type": "exit",
    "info": "CA-7 job status tracking\r\nCA 7, by default, uses one byte in the SMF common area userid field. The default byte is the 8th byte of this area with SMFO(7).  You can change this option to use the high-order byte of the reader-time field with SMFO(T).  \r\n\r\nNOTE: You will need to ensure that you do not have another application that may be using this.\r\n\r\nYou need to do the following in your CA 7 Test environment to make these changes and test this works.\r\n\r\n1.    Run CAS9 for CA7 only with L2OPTS DD GLOBAL DELETE ALL\r\n\r\n2.   Run CAS9 for CA7 only with normal L2OPTS dd but replacing SMFO(7) with SMFO(T).  If SMFO is not there, then add\r\n      SMFO(T)\r\n\r\n3.  Bring up CA 7, ICOM on your TEST environment and run jobs to test these CAS9 changes and to verify if jobs are tracked under CA 7 with changes made to  the IBM SMF exits for the TWS modules"
  },
  {
    "Vendor": "ibm",
    "component/product": "smf",
    "type": "exit",
    "info": "Any exits that we specify in SMFPRMxx needs to have an entry in PROGxx. Also, we cannot have any other exits other than IEF* in SMFPRMxx. \r\nSUBSYS(xxx,type(()), exit()) overrides the entry in SYS(xxx,type(()), exit())."
  },
  {
    "Vendor": "ibm",
    "component/product": "storage",
    "type": "command",
    "info": "D SMS,LIB(ALL),DETAIL -- provide the details of all the tape infor, (Scratch volumes, total drives and so on)"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "commadn",
    "info": "*F Q,R -- to release the job to execute."
  },
  {
    "Vendor": "ibm",
    "component/product": "dump",
    "type": "command",
    "info": "D D,T,AUTODSN=ALL\r\nTo DISPLAY the titles of all, or the one hundred most recent, automatically allocated dump data sets"
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA-7",
    "type": "command",
    "info": "command to shutdown CA7ONL.\r\nlogon to ca-7 and issue the command /shutdown,z3 enter twice."
  },
  {
    "Vendor": "IBM",
    "component/product": "izws",
    "type": "setup",
    "info": "IzWS in the same sysplex cannot have 2 controllers in the same name."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "setup",
    "info": "for ETT trigger we need to have IEFU83 exit assmenbled as TWSU831 or so. We need to update exit  code with SRREAD=YES for the ETT trgger to work.\r\n\r\nThe dataset that gets created needs to be udpated so the SMF 15 gets created which is pulled by IzWS to trigger the job.  if using IEBGENR to create the dataset have the dataset in SYSUT2 and not SYSUT1.\r\n\r\nThe tracker collects all the smf records 14, 15 and so.\r\n\r\nWE need to run the job EQQLSJCL will create a member EQQDSLST which will have the dataset names to be tracked. this job has to be run on all the systems where the datasets would be tracked. \r\n\r\nWe need to issue the command F twst,newdslst -- refresh eqq dslist."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "commands",
    "info": "to issue mvs commands in batch in JES3\r\n//step1 exec pgm=ikjeft01\r\n//systsprt dd sysout=*\r\n//systsin dd *\r\n OC  -- is an opsmvs command\r\n D A,L\r\nSET PROG=XX\r\nSETPROG APF,aDD,"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "commands",
    "info": "making use of the //COMMAND JCL statement.  The documentation link provides clarification on syntax, location in JCL, and examples.  However, please note that in order to allow COMMAND JCL statements in the job stream to be honored (and executed) by JES3, you will need to verify your CIPARM settings; particularly the AUTH= and COMMAND= settings.\r\n\r\nNote that the default for CIPARM COMMAND= is IGNORE (which means the command is ignored and treated as a no-op), so you would need to change the AUTH= and COMMAND= to meet your specific needs."
  },
  {
    "Vendor": "ibm",
    "component/product": "Izws",
    "type": "setup",
    "info": "RESTART option in IzWS.\r\nWe have coustmized the Datastore , however whenever we issue the \"RC\" command for restart and clean , it has below warning message .\r\n\r\n04/08 06.49.53 EQQM643W OPERINFO FOR NCDARPER (JOB00452) NOT RETRIEVED. REASON: 0006 CN(INTERNAL) \r\n\r\nEQQM643W OPERINFO FOR NCDARPER (JOB00457) NOT RETRIEVED. REASON: 0004  \r\n\r\nbecause the length of your  DSTOPTS  parameter is not correct \r\n 05/02 12.29.51 EQQZ015I INIT STATEMENT:   HDRJOBNAME(JOBNAME)\r\n 05/02 12.29.51 EQQZ015I INIT STATEMENT:   HDRSTEPNAME(STEPNAME)\r\n 05/02 12.29.51 EQQZ015I INIT STATEMENT:   HDRPROCNAME(PROCSTEP)\r\n 05/02 12.29.51 EQQZ015I INIT STATEMENT:   HDRJOBLENGTH(20)\r\n 05/02 12.29.51 EQQZ015I INIT STATEMENT:   HDRSTEPLENGTH(29)\r\n 05/02 12.29.51 EQQZ015I INIT STATEMENT:   HDRPROCLENGTH(38)"
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA-7",
    "type": "report cleanup",
    "info": "To cleanup the LPRRN output in a PS\r\nLPRRN cleanup\r\n1.        X ALL\r\n2.        F '                                       ' 1 all\r\n3.        F '1LPRRN,JOB=*' 1 all\r\n4.        F 'JOB=*' 2 all\r\n5.        F DEADLINE 16 all\r\n6.        F SPEC/RUN 54 all\r\n7.        DEL NX ALL\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "|| symbol",
    "info": "use pipe symbol to add multiple variable to form a row.\r\nC = SAY\r\nD = TO\r\nF = BYE\r\nA = C || D || F\r\nSAY A \r\n\r\nANS : SAYTOBYE"
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca-7",
    "type": "report cleanup",
    "info": "FSTRUC clenup\r\n\r\nF 'network structure for ca-7 jobs' all\r\nF '1FSTRUC' 1  all\r\nF 'FORECAST FOR CA-7 JOBS' all\r\nF 'START TIME :' 13 all\r\nF LEV# 2 all\r\nF ‘                                            ‘ 1 all\r\nDEL NX all"
  },
  {
    "Vendor": "broadcom",
    "component/product": "TSS",
    "type": "commands",
    "info": "//TSSCFILE EXEC PGM=TSSCFILE                         \r\n//PRINT   DD SYSOUT=*                                \r\n//OUT    DD DSN=cfile.output.dataset,    \r\n//             DISP=(,CATLG),                        \r\n//             UNIT=SYSALLDA,SPACE=(CYL,(5,5),RLSE), \r\n//             RECFM=FB,LRECL=300,DSORG=PS           \r\n//IN        DD *                                                 \r\nTSS LIST(ACIDS) TYPE(USER) DATA(ALL)                 \r\nTSS LIST(ACIDS) TYPE(PROFILE) DATA(ALL)              \r\nTSS LIST(ACIDS) TYPE(GROUP) DATA(ALL)                \r\nTSS LIST(ACIDS) TYPE(DCA) DATA(ALL)                  \r\nTSS LIST(ACIDS) TYPE(VCA) DATA(ALL)                  \r\nTSS LIST(ACIDS) TYPE(DEPT) DATA(ALL)                 \r\nTSS LIST(ACIDS) TYPE(DIV) DATA(ALL)   \r\nTSS LIST(ACIDS) TYPE(SCA) DATA(ALL)   \r\nTSS LIST(ACIDS) TYPE(LSCA) DATA(ALL)  \r\nTSS LIST(ACIDS) TYPE(ZONE) DATA(ALL)  \r\nTSS LIST(ACIDS) TYPE(ZCA) DATA(ALL)   \r\nTSS LIST(ALL) DATA(ALL)               \r\nTSS LIST(STC) DATA(ALL)               \r\nTSS LIST(RDT) DATA(ALL)               \r\nTSS LIST(DLF) DATA(ALL)               \r\nTSS LIST(FDT) DATA(ALL)               \r\nTSS LIST(NDT) DATA(ALL)               \r\nTSS LIST(APPCLU) DATA(ALL)            \r\nTSS LIST(AUDIT) DATA(ALL)             \r\n/*     \r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca-7",
    "type": "report cleanup",
    "info": "command to cleanup LJOB,JOB=*,LIST=RQJOB job output.\r\n\r\nF '                                              ' 1 all\r\nf '1LJOB,JOB=*' 1 all\r\nf 'JOB=*' 2 all\r\nf '----JCL----' 11 all\r\nf 'ID  MEMBER' 12 all\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca-7",
    "type": "report cleanup",
    "info": "command to cleanup LJOB,JOB=*,LIST=DEPJ job output.\r\n\r\nF '                                              ' 1 all\r\nf '1LJOB,JOB=*' 1 all\r\nf 'JOB=*' 2 all\r\nf '----JCL----' 11 all\r\nf 'ID  MEMBER' 12 all\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA-7",
    "type": "report cleanup",
    "info": "Command to cleanup LJOB,JOB=XXX,LIST=NODD\r\nF '                                              ' 1 all\r\nf 'LJOB,JOB=' 2 all\r\nf '----JCL----' 11 all\r\nf 'ID  MEMBER' 12 all\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "function",
    "info": "FIND -- Finds  a word(ABC) in a string(C1) and marks the value as 1  A = (C1,'ABC')\r\nPOS  -- Finds chars in a string and provides the postions of 1st search char  A = ('XYZ',C1)"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "function",
    "info": "SLECT WHEN OTHERWISE END\r\nSELECT\r\nWHEN(T1=1) THEN COLUMN2 = \"TRIG\"\r\nWHEN(S1=1) THEN COLUMN2 = \"SSCN\"\r\nOTHERWISE COLUMN2 = \"AUTO\"\r\nEND\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "cbac",
    "type": "commands",
    "info": "RUNCEMT,CICS(xxxx),COMMAND(CEMT PERFORM SHUTDOWN) -- cannot be used to shutdown CICS.\r\n\r\nCBAC and CICS development have after extensive analysis, concluded that a CBAC RUNCEMT command to execute a PERFORM SHUTDOWN is not going to work due to the existing design of how CICS does shutdown processing and how it handles EXCI API/SPI requests"
  },
  {
    "Vendor": "ibm",
    "component/product": "omegamon",
    "type": "commands",
    "info": "The CONS command issue is related to OMEGAMON not finding a console with Master authority on the system the command is issued on. When z/OS Version 1.8 was introduced the Master console was no longer supported in favor of one or more consoles being given Master authority. If a console ID is not provided OMEGAMON attempts to find the lowest console ID with Master authority. If one is found the command will support use of the associated CONS minor commands LINE, ACTN and MNT.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "ready prompt",
    "info": "If we dont get ready prompt when logging of. Please execute the below rexx.\r\nADDRESS TSO"
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA-7",
    "type": "setup",
    "info": "We can run the job CA07SVCT to check for the SMF indicator bit set or not."
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "commands",
    "info": "to identify if any jobs are waiting for any allcations.\r\n*I S A -- to identify any jobs waiting for allocations\r\n*I S A=Jxxxx -- to identify the jobs watiing for allocaitons"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "commands",
    "info": "*F J=xxxx,C -- to cancel a job.\r\nC U=userod -- cancel a tso user."
  },
  {
    "Vendor": "IBM",
    "component/product": "SMF",
    "type": "EXit",
    "info": "IEFUSI -- exit work with the region parm of the jobs. if we are activating the exit then we need to have it in SYS(xx) and SYS(JES3(xx)) and SYS(JES2(XX))"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "general",
    "info": "2. How to determine how long are reports retained in the CA-VIEW catalog before being migrated to tape? \r\n   How can I determine if reports are retained by number of generations or by days.\r\n . At the next View backup following report collection (SARINIT parameters DAYS=xxxxxxx and TIME=hhmm), reports that have not yet been backed up to tape, get backed up to tape. \r\n . In Phase 2 of the View backup, the retention parameters determine how long something is kept on disk and for how long on tape. \r\n   For what retentions are used, please look at the following:\r\n . . SARINIT parameters NGEND and NGENT (retention on disk and tape)\r\n . . If there is a //SARPATAB DD statement in your SARSTC task, it points to the Expanded Retention Option (ERO) table, which indicates retention for individual reports. "
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "general",
    "info": "1. How to find out on average, how many reports do CA-VIEW per day (per instance)?\r\n . In the SARSTC task log, please note the SARBKT62 message for Phase 1:\r\nSARBKT62  Standard backup cycle ending phase 1.  Of mmmm reports on database, nnnn were processed.\r\n . The \"nnnn\" value indicates how many reports were collected. \r\n . Please note the number of reports processed, add up their values for several days, then divide that by the number of days, to determine an average."
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "Report",
    "info": "3. How to find out how many reports are currently cataloged by each instance of CA-VIEW?\r\n\r\n . Run SARBCH /LIST, for a list of all reports (disk and tape) for the database:\r\n\r\n//XXXXXXXX JOB ...                                                \r\n//SARBCH   EXEC PGM=SARBCH,PARM='VIEW_HLQ'  <=== MODIFY DB NAME   \r\n//STEPLIB  DD  DISP=SHR,DSN=VIEW.CVDELOAD     <=== MODIFY, IF USED\r\n//SYSPRINT DD  SYSOUT=*                                           \r\n//REPORT   DD   SYSOUT=*                                          \r\n//SYSIN    DD   *                                                 \r\n/LIST ID=* GEN=*                                                  \r\n/*                                                                \r\n//     "
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "general",
    "info": "5. How to determine if features such as report indexing or cross-report indexing in use?  \r\n   If so  please describe a few examples of how reports are indexed.  \r\n   What is the maximum number of indices per report?\r\n . In the View Sysout Selection List, scrolling to the right will show the \"D T O I\" columns, which indicate if a report resides on the disk layer, on tape, on optical disk, and if it is indexed.  \r\n   A \"Y\" in the \"I\" column indicates that the report is indexed. \r\n . There is no quick method to see if a report takes part in cross-report indexing. \r\n   You would have to look at each View logical view (command DEF VIEW), to see if the cross-report indexing field is set to YES. \r\n   The maximum number of index levels for a report is 8. \r\n   The number of records that can contain an index is up to what is in the report. "
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "general",
    "info": "6. How to determine if the function of Job Name Translation Tables in use? \r\n\r\n . CA Deliver uses the Jobname Translation Table. \r\n\r\n   In a RMOSTC task, look at //RMOJTAB DD DSN=... to find the name of the member that contains the table. \r\n\r\n   CA View has no Jobname Translation Table. "
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "general",
    "info": "9. How to determine if CA-View is using an exit?\r\n\r\n . For a View exit, look at the CVDESRC library, to see if there is any exit source that has been altered. \r\n\r\n   Also, look at the CVDEJCL library, to see if there are JCL streams that were modified to submit an assembly of an exit."
  },
  {
    "Vendor": "lrs",
    "component/product": "VPS",
    "type": "commands",
    "info": "commands to activate, stop, inactivate a printer in VPS\r\nF stc,ACT,printername\r\nF stc,STO,printername\r\nF stc,INA,printername\r\nF stc,REA,printername "
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "batch",
    "info": "batch rexx to issue MVS commands using IKJEFT01\r\n//STEP1 EXEC PGM=IKJEFT01,PARM='xxxxx yyyy' -- xxxx is the rexx YYYY is the argument.\r\n//SYSEXEC DD DISP=SHR,DSN=rexx danm where the XXXX member is available.\r\n//SYSTSPRINT DD SYPUT=*\r\n//SYSTSIN DD *\r\nCONSOL ACTIVATE NAME(zzzz)  -- zzzz can be any value from 2 to 8 chars and must beging with @ / #/ $.\r\nCONSOLE SYSCMD(mvs command)\r\nCONSOLE DEACTIVATE\r\n/*\r\nthe userid needs to have access to teh CONSOLE command and the MVS commands being issued.\r\nAlso ahve access to MVS.MCSOPER.console_name"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "general",
    "info": "Parms that determin the Deliver processing reports.\r\n1)The JOBCLSL initialization parameter is required. You must specify a value for this parameter for Deliver to operate properly.RMOPARMS JOBCLSL and SYSCLSL are used, together, to determine if any sysout is to be processed pre-spool.\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "general",
    "info": "How to make delvier not process the reports.\r\n\r\nwe cannot make delvier not process any reports when it is up and running as the values for JOBCLSL and SYSCLSL are mandatory.  we can have the DELIVER stopped is the only option.\r\nIf you have the Ca Deliver parameter SETCMD=YES then there are some parameters that can be modified while the Deliver task is active including JOBCLSL and SYSCLSL.\r\n\r\nThe Syntax is :\r\n\r\nF RMOSTC,SET initparm=operand where\r\nRMOSTC represents your STC name\r\ninitparm represents the initialization parameter you want to setoperand represents the value to which you want to set the initialization parameter.\r\n\r\nYou can read more about it in the following link of our tech doc :\r\n\r\nhttps://techdocs.broadcom.com/us/en/ca-mainframe-software/traditional-management/ca-deliver/14-0/reference/operator-commands.html#concept.dita_119a2ded543a2e979ccdef96049ec4d447bf44b3_SetanInitializationParameterWhileCADeliverIsRunning\r\n\r\nIf SETCMD=NO then the Deliver task would need to be recycled to pick up the change to JOBCLSL and SYSCLSL.\r\n\r\nLet me know if you have any other questions or thoughts."
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "general",
    "info": "VIEW running without monitoring any class/dest.\r\n1) The CLASS parameter in SARINIT should be changed to the desired class you want VIEW to collect the output from. Recycle the SARSTC post the SARINIT parameter change.\r\n2) Regarding View , It collects the reports from spool for archival based on three SARINIT initialization criteras:\r\n\r\n  - CLSL : This parameter specifies a list of one to eight SYSOUT classes used to select SYSOUT for archival. When you specify CLSL, also specify, NEWCLSL to prevent a print-archival-print loop. If neither CLSL, DEST, nor FORM is specified, all SYSOUT is archived.\r\nNOTE : If you specify no class by default VIEW will consider ALL clases\r\n\r\n  - DEST : This parameter specifies the destination (remote name) used to select SYSOUT for archival.\r\n  - FORM : This parameter specifies the one to eight character forms  name used to select SYSOUT for archival. When FORM is specified,  NEWFORM should also be specified to prevent a print-archival-print loop. If neither CLSL, DEST, nor FORM is specified, all SYSOUT is archived.\r\n\r\nNow if you want to STOP View from collecting output from the JES spool you would have to :\r\n . Set SARINIT FORM=.... to a bogus value (like FORM=9999). \r\n . Recycle SARSTC. \r\n\r\nThe above would be preferred to changing anything in CLSL or DEST. \r\nTo resume collection, run SARINIT to change the FORM=... back to what it was previously and, again, recycle SARSTC. "
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "general",
    "info": "Also there's a parameter called NARCCLSL which can help you exclude few classes incase you do not want  them to be managed by View.\r\n\r\nNARCCLSL :This parameter specifies a list of one to eight SYSOUT classes that View is NOT to archive. Any SYSOUT originally output to one of the classes is selected and processed but is not archived. In general, the classes should also be specified for automatic printing, or the SYSOUT is deleted.\r\n\r\nYou can read about it in detail from the link below:\r\n\r\nhttps://techdocs.broadcom.com/us/en/ca-mainframe-software/traditional-management/ca-view/14-0/reference/initialization-parameters/initialization-parameter-statements.html#concept.dita_4ef5e01c-c3e6-4438-a2bb-6fb37a0918c5_NARCCLSL"
  },
  {
    "Vendor": "ibm",
    "component/product": "tadz",
    "type": "common",
    "info": "in general the stcs are HSI*"
  },
  {
    "Vendor": "IBM",
    "component/product": "JES3",
    "type": "STC CLASS",
    "info": "How to determine the JES3 msgcalss for the STC that is being used.\r\nThe JES3 STANDARDS statement has a STCPMID parm of 02.\r\n\r\nSTANDARDS,CARDS=(50,W),CICNT=(0,1),FAILURE=CANCEL,PRTY=3,SETUP=THWS,\r\nBYTES=(999999,W),STCPMID=02,PAGES=(100,W),DBGCLASS=Z,JESMSG=NOTSO,  \r\nLINES=(100,W),TSOPROC=TS,MAXASST=5000,MAXJOBST=0000,PSTCNT=(5,5)    \r\n\r\nThis points to a CIPARM statement with PARMID=02\r\n\r\nCIPARM,PARM=(00012000099931E00011Z),PARMID=02,REGION=256M\r\n\r\nThe last character in the PARM field indicates the default MSGCLASS sysout class for started tasks"
  },
  {
    "Vendor": "IBM",
    "component/product": "JES2",
    "type": "STC CLASS",
    "info": "How to detemine the JES2 MSGCLASS for STC.\r\nIssue the command /$D JOBCLASS(STC),ALL -- it would list the MSGCLASS that STC started on the system would use."
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "STC Archival",
    "info": "in JES2 -- we need to chekc for the MSGCLASS in the JOBCLASS(STC)\r\nin JES3 look for STCPMID=xx statement and then look for PARMID=xx statement and we need to check the last char of PARM=(xxxxx) value to identify the MSGCLASS that the STC are pointed to."
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA7",
    "type": "proc",
    "info": "we can a seperate proclib concatenation for CA-7 that works only for CA-7.\r\nWe can use the Driver proc (DPROC). we need add a CARPROC DD statement in CA-7"
  },
  {
    "Vendor": "ibm",
    "component/product": "performance",
    "type": "tools",
    "info": "Mainframe Monitoring tools\r\nOmegamon\r\nBMC AMI Ops Monitoring(Formerly Mainview)\r\nSysview\r\nASG TMON\r\n\r\nCode Profiling tools\r\nIBM APA\r\nTRITUNE\r\nStrobe\r\nMacro4 Freezeframe\r\nCA Mainframe Aapplication Tuner(CA MAT)\r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "performance",
    "type": "tools",
    "info": "Mainframe Performance Reporting tools\r\nIBM Z IntelliMagic Vision for z/OS \r\nPivotor from EPS inc\r\nIBM Z Performance and Capacity Analytics (IZPCA)\r\nMXG \r\nCA MICS\r\nIBM Tivoli Decision Support for z/OS(TDSz)\r\nSyncsort™ Capacity Management\r\nZetaly Service Intelligence\r\nSAS ITRM\r\nzWorkload Reporter \r\nEasySMF for z/OS\r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "performance",
    "type": "tools",
    "info": "DB2 SQL monitoring tools\r\nIBM Query Monitor\r\nBMC Apptune\r\nCA Detector\r\n\r\nSMF Streaming tools\r\nIBM Common Data Provider for z Systems (CDPz) \r\nPrecisely’s Ironstream\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "Report",
    "info": "dumping the DIST and DEST values for report definitions.\r\n//JOBCARD...\r\n//STEP1    EXEC PGM=RMOGRW                                    \r\n//*STEPLIB  DD DISP=SHR,DSN=your.deliver.CVDELOAD <--MODIFY IF USED!           \r\n//SORTWK01 DD UNIT=SYSDA,SPACE=(CYL,(5),,CONTIG)              \r\n//SORTWK02 DD UNIT=SYSDA,SPACE=(CYL,(5),,CONTIG)              \r\n//SORTWK03 DD UNIT=SYSDA,SPACE=(CYL,(5),,CONTIG)              \r\n//SYSUDUMP DD SYSOUT=*                                        \r\n//SYSOUT   DD SYSOUT=*                                        \r\n//SYSPRINT DD SYSOUT=*                                        \r\n//PRTFILE  DD SYSOUT=*,DCB=(RECFM=FBA,LRECL=133,BLKSIZE=13300)\r\n//SYSIN    DD *                                               \r\n/CONTROL DATABASE=your.deliver.dbhlq               <--MODIFY DBHLQ!!\r\n/DEFINE I BIN(4)                                              \r\n/DO I = 1 TO NDID BY 1                                        \r\n/ PRINT RID 'REPORT ID' COL(1)                                \r\n/ PRINT DISTID 'DIST ID' COL(34)                              \r\n/ PRINT EDIT(I,'9999') 'ENTRY NO' COL(66)                     \r\n/ PRINT OUT 'OUT'                                             \r\n/ PRINT DEST 'DEST'                                           \r\n/ PRINT JOB 'JOB'                                             \r\n/ NEXT DISTID                                                 \r\n/END                                                          \r\n/*                                                            \r\n//\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca7",
    "type": "command",
    "info": "to add a user requirement to a ca-7 job.\r\nADDRQ,JOB=XXXX,USR=JOB-IS-A-TEST-JOB-DONT-RUN"
  },
  {
    "Vendor": "asg",
    "component/product": "projcl",
    "type": "setup",
    "info": "if we dont want to use the automatic proclib concatenation. we need to update the member pointed by JPCONFIG DD and make dssistcconsole = no and recycle the STC."
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA-1",
    "type": "setup",
    "info": "2.\tCan we manage the tape that go to scratch in RMM, we would like to avoid any tapes going to scratch by mistake? In the past I heard the because someone has mistakenly updated the scratch input a customer has lost lot of tapes and it went into lot of escalations.\r\n\r\nTapes are  currently returned to scratch by the CA-1 TMSCLEAN utility which is run daily as part of Job UCCSRTTL.  The DFRMM equivalents are VRSEL end EXPROC.  I have been running VRSEL and EXPROC while DFRMM has been running in warning mode and comparing the list of scratch volumes produced.\r\n\r\nTapes are managed by CA-1 according to expiration date specified in JCL at creation.  Certain expiry dates have special meaning, EXPDT=99000 means retain while dataset is cataloged and EXPDT=99365 means permanent retention.  Specific expiry dates or retention periods that don't match the special dates are honored and tapes are returned to scratch after those dates.  The absence of an expiry date is treated as catalog retention.\r\n\r\nDFRMM has been configured to manage tapes according to the same rules.\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA-1",
    "type": "setup",
    "info": "4.\tHow easy/difficult is it to backout the change during a weekday when the systems are up and running and what steps needs to be followed.\r\nBackout will be difficult.  Tapes created exclusively under DFRMM after CA-1 has been stopped will have to be identified and updated in the CA-1 TMC manually should backout to CA-1 be needed.\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "Report",
    "info": "Job to dump Deliver DBASE\r\n//JOBCARD\r\n//STEP1 EXEC PGM=RMODBASE\r\n//STEPLIB\r\n//SYSPRINT DD SYSOUT=*\r\n//RMOUNLD DD DSN=..\r\n//           DCB=(LRECL=8192,BLKSIZE=27998,RECFM=VB),\r\n//           SPACE=(CYL,(100,70),RLSE)\r\n//SYSIN DD *\r\nNAME deliver DB name\r\nUNLAOD"
  },
  {
    "Vendor": "lrs",
    "component/product": "vps",
    "type": "setup",
    "info": "from JCL check for CNTL dataset. Look for VPSSTART member and look for MLISTMEM to check for a member that has PRINTER definitions."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmm",
    "type": "command ",
    "info": "TSO RMM LC -- to check the journal and CDS full %  and many other parms"
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "notes",
    "info": "The XPAF profile for each of the STC points to a destination printer and if it converts to PCL format or apa format and so on the profile member. that each STC is pointing to PROFDD"
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "notes",
    "info": "When the reports reached deliver, it will append the PRSET print definitons to it and if we have a destinaton defined to it and it is set to Y then it reprints to JES.  from there if XPAF is present it would pickup the report and try ot send it to teh destination. the destination are mostly JES FSS.\r\nDelvier does not do any changes to the report like converting to AFP, APA, PDF. it would only add hte PRSET and send it to JES3/JES2"
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "notes",
    "info": "The PRSET printer setup members are loaded into the database via the PLOAD funciton of RMODBASE utility"
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "notes",
    "info": "XPAF classifies each document it processes as belonging to one of six types: NM, DJDE, JCL, XES, PCL5, AFPX, or AFPA."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "notes",
    "info": "NM Indicates a native mode (printer-ready) document. If a document is created and submitted without any extended JCL keywords, DJDE packets, XES criteria, or AFP attributes, then XPAF will process it as native mode."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "notes",
    "info": "DJDE Indicates a DJDE document. If a document includes one or more of these\r\ncharacteristics, then XPAF will process it as DJDE mode:\r\n• The keyword PRMODE=DJDE is specified on the OUTPUT\r\nstatement in the JCL.\r\n• The first record in the data stream contains a valid IDEN, and that\r\nIDEN matches the IDEN value specified in the initialization\r\nparameter.\r\nFor any dataset that contains DJDE extended JCL keywords or a valid\r\nIDEN in the first data record, XPAF assumes DJDE processing even if\r\nPRMODE=LINE. However, if any AFP attributes are associated with the\r\ndocument, then AFP mode will override DJDE mode."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "notes",
    "info": "JCL Indicates a document that uses extended JCL keywords. If a document\r\nincludes one or more extended JCL keywords, XPAF will process it as\r\nJCL mode. However, if any AFP attributes are associated with the\r\ndocument, then AFP mode will override JCL mode."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "notes",
    "info": "XES Indicates an XES document. If a document includes one or more of these\r\ncharacteristics in the first record, then XPAF will process it as XES mode:\r\n• It includes a X'27' carriage control value.\r\n• It includes the ‘=UDK=’ character string.\r\nIf any AFP attributes are associated with the document, then AFP mode\r\nwill override XES mode."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "notes",
    "info": "AFPX Indicates a page-formatted document. Refer to the description of AFPA\r\nbelow. Although page-formatted and AFP documents are two different\r\ntypes of data streams, XPAF uses the same code for converting each type\r\nof document to a format supported by Xerox printers. Therefore, this\r\nexplanation uses the term “AFP attributes” to refer to characteristics that\r\nmay apply to either page-formatted or AFP documents.\r\n"
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "notes",
    "info": "AFPA Indicates an AFP document. If a document includes one or more of these\r\ncharacteristics, XPAF will process it as AFP:\r\n• Any record within the data stream includes a X'5A' carriage control\r\nvalue.\r\n• The keywords FCB and/or UCS are included on the DD statement in\r\nthe JCL.\r\n• The keywords CHARS, FCB, FORMDEF, PAGEDEF,\r\nPRMODE=PAGE, and/or UCS are included on the OUTPUT\r\nstatement in the JCL.\r\nFor any dataset that contains AFP extended JCL keywords or contains a\r\n5A carriage control in the first data record, XPAF assumes AFP\r\nprocessing, no matter what value has been specified for the PRMODE.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "rmm",
    "type": "command",
    "info": "S DFRMM,OPT=MAIN -- to start RMM and it would run continously. baded on mode in EDGPRMxx member it would take actions."
  },
  {
    "Vendor": "ibm",
    "component/product": "jcl",
    "type": "submit jobs",
    "info": "we can submit a job using the below proc.\r\n//JOB PROC CLASS='A',\r\n//         LIST='*\",\r\n//         DSN='dataset form where we need the jobs to be submitted',\r\n//         N='name of the job' --> can we be overridden with the start command.\r\n//IEFPROC EXEC PGM=IEBEDIT\r\n//SYSPRINT DD SYSOUT=&LIST\r\n//SYSUT1 DD DDNAME=IEFRDER\r\n//SYSUT2 DD SYSOUT=(&CLASS, INTRDR),DCB=BLKSIZE=80\r\n//SYSIN DD DUMMY\r\n//IEFRDER DD DISP=SHR,DNS=&DSN.(&N.)\r\n\r\nwe can use the commands  \"S JOB,N=jobname\" (ensure that there is a member with that jobname in the PDS mentioned with DSN parm."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmm",
    "type": "ca-1 to rmm",
    "info": "1. allocate RMM control datasets -- use alter RECLAIMCA (no need to do re-org and reclaim the empty space). and allocate a control id.\r\n2. allocate the journal datasets  -- daily backup to be setup.\r\n3. use sort to extract the data from CA-1.  TMC contorl record / DSNB record / TMC volume record.\r\n4. conver and create records that can be loaded into RMM.\r\n5. def table to mimiced from CA-1\r\n6. run rmm in record, warning and then final in protect mode.\r\n7. run a utility EDGHSKP to check on the \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "relase a job",
    "info": " +F J=1632,P=xx   -- command to release a job in JES3  J=job number and P=priority"
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm ",
    "type": "theory-1",
    "info": "WLM\r\nWLM distributes the system resources based on the goals defined in the service class   \r\nEach work load in the z/OS is assigned to a service class based on the rules are setup in WLM  \r\n\r\nWLM goal achievements can be found in RMF monitoring tool and z/OS monitoring tools such as Omegmon for z/OS, Mainview for z/OS, CA sysview for z/OS etc.\r\n\r\nWLM ensures that workloads are prioritized according to their significance, from the highest priority to the lowest.\r\n\r\nA service class can miss its goal due to delays in Processor/Storage/DASD/Sub system/Operator/ENQ. \r\nActions can be taken according to the type of delay like adjusting the goal/importance level of the service class, holding the low importance workloads to allow room for high importance level. \r\n\r\nIf possible, low importance batch work load can be moved to time period when system load is less. \r\nThis will help to meet batch SLAs, also reducing the 4HRA peak.\r\n"
  },
  {
    "Vendor": "ibm ",
    "component/product": "wlm ",
    "type": "theory-2",
    "info": "WLM capping to control the Licensing costs\r\nSoft capping(Defined Capacity limit) can be defined at the LPAR level to control the Licensing costs.\r\nLicensing costs can be controlled for a group of LPARs by defining Group capacity as well.\r\nCompilers, Debugging tools, SCM tools can be restricted to run in certain LAPRs to control the licensing cost.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "wlm ",
    "type": "theory-3",
    "info": "Work load management in Batch scheduling tools\r\nBatch scheduling tools such as IBM TWSz, Control M, CA ESP etc have capability to define Critical paths in the batch. \r\nThey continuously calculates the Estimated completion time of critical paths. \r\nWhen estimate completion time of the end job(SLA job) in the Critical path misses its defined completion time, they will generate alert to the Monitoring team and respective parties can be informed about the delay.\r\n\r\nOnline work load management\r\nFor online workloads such CICS, IMS , alters can be setup in the monitoring tools for those subsystems to created alerts \r\n•\twhen there too many abends in a transaction\r\n•\twhen CPU consumption of a transaction crosses defined threshold\r\n•\tWhen run time of a transaction crosses defined threshold\r\n"
  },
  {
    "Vendor": "bmc",
    "component/product": "AMI",
    "type": "theory",
    "info": "BMC Compuware Thruput Manager(BMC AMI Ops Automation for Batch ThruPut)\r\nThruPut Manager AE works with  job scheduler to manage batch more effectively and complete batch window earlier. \r\nWhen the system is under stress, ThruPut Manager AE escalates the most important workload, deferring the less important if necessary. \r\n\r\nSave Monthly Software Costs\r\nThruPut Manager AE monitors capacity utilization (the 4 hour rolling average) to further save software costs when sub-capacity pricing is used.\r\nIt automatically constrains low importance batch as a peak approaches and resumes normal service as it passes. This results in significant monthly software savings with no impact to online service or mission critical batch.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "PARSING",
    "info": "use the PARSE command to split the input line into variables.\r\nPARSE VALUE input line WITH Var1 'conditonto spli' var2 'condition split'"
  },
  {
    "Vendor": "broadcom",
    "component/product": "Ca-11",
    "type": "theory",
    "info": "interface with CA-1 to be removed.\r\nS806 for TMSSV C occurs when the option CA-1 is still set to YES.  Options need to be changed so that CA-1 is set to NO. Options can be dynamically changed without taking down CA 11.  \r\nJob AL7UOPT in the CAL7SAMP library would have to be run to change the CA 1 option value. \r\nAfter AL7UOPT runs successfully, a refresh of the U11OPT option module is needed to pick up the changes.  \r\nLLA refresh will also have to be done if Cailib is in linlkist.  \r\n\r\nTo refresh the options issue the following DBAS command: \r\ncomchar REFRESH MOD=U11OPT \r\nTo verify the changes took place you can issue the following DBAS command: \r\ncomchar DISPLAY OPTIONS \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "ett triggers",
    "info": "use the JCL EQQ*JCL to update the dataset trigger name and then submit the job. A table EQQDSLST is updated with the datsets names. the EQQDSLST member would be in the dataset taht is pointed by EQQJCLIB DD in Tracker STC.\r\n\r\nissue the command F tracker subsystem,NEWDSLST"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "ett triggers",
    "info": "ensure to create a new job for the trigger status to be changed as NOT AVAIABLE for the next run of the ETT trigger"
  },
  {
    "Vendor": "ibm",
    "component/product": "utility",
    "type": "iebcopy",
    "info": "to copy only certain member from input to output PDS with replace.\r\n//JOBCARD\r\n//step1 exec pgm=iebcopy\r\n//ddI dd dsn\r\n//ddO dd dsn\r\n//sysin dd *\r\n COPY INDD=((DDI,R)),OUTDD=DDO\r\n      SELECT MEMBER=xxxx\r\n      SELECT MEMBER=xxxx\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "dump",
    "info": "REIZDP rexx use to get special resource details from the daily dump\r\nREIZFL rexx use to get the ADID and the jobs under each ADID -- job flow\r\nREIZFLRE rexx use to get the entir adid, addep, adsr for all the jobs in IzWS "
  },
  {
    "Vendor": "broadcom",
    "component/product": "NDM",
    "type": "theory",
    "info": "There was no notification because the NDM jobstep submitted the process asynchronously when you should have submitted the process synchronously.    When you do not code MAXDELAY on the NDM process PROC statement, the NDM file transfer is processed asynchronously. \r\n \r\nFor asynchronous ... When the batch job runs the NDM step, NDM does a syntax check and returns a non-zero return code to the job if the syntax check fails.   If the syntax check passes, NDM passes a zero return code to the job and submits the process for execution.  The file transfer runs asynchronous to the batch job.   The batch job does not wait for the file transfer to complete successfully or fail.\r\n \r\nFor synchronous ... When the batch job runs the NDM step, NDM will perform a syntax check and returns a non-zero return code to the job if the syntax check fails.   If the syntax check passes, NDM will submit the process for execution.   The file transfer runs synchronous to the batch job and the batch job will wait for a return code from NDM based on the status of the file transfer.  MAXDELAY is used in the NDM control cards on the PROC statement to serialize the batch job with the file transfer.\r\n \r\n If MAXDELAY is used, NDM will set a non-zero return code if the file transfer fails, or the MAXDELAY interval is exceeded.   If the interval is exceeded, NDM will return a non-zero return code and the file transfer will continue to execute to completion.  If the file transfer completes, NDM will return a zero return code.\r\n \r\n\r\nIf you look up that X-message, you'll see it originated from the Linux NDM node and not from the mainframe NDM node.    \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "active/pending",
    "info": "Job to activate or deactivate an application in IzWS\r\n\r\n000100 //WAPLPEN1 JOB (544,015,1,00000),'RAVIS',MSGLEVEL=(1,1),         \r\n000200 //           REGION=0M,MSGCLASS=Z,                               \r\n000300 //           PRTY=06,NOTIFY=&SYSUID,CLASS=SYSPROG                \r\n000400 //JCLSTP JCLLIB ORDER=OEM.TWS.SEQQSAMP.GSP1                      \r\n000500 //RUNPIF  EXEC EQQYXJPB                                          \r\n000600 //OUTDATA  DD SYSOUT=*,LRECL=4096                                \r\n000700 //OUTBL    DD SYSOUT=*                                           \r\n000800 //SYSIN    DD *                                                  \r\n000900 OPTIONS DBMODE(UPDATE)                                           \r\n001100 ADSTART ADID(APP#ALD0035C#010) STATUS(P) NEW_STATUS(A)          \r\n001400 /* \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "if we want to change the order in which the app are listed, we can use the REORDER command.\r\nif we want to access an app without using the line command S, we cna use the command START appid on the command line."
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "2.\tIf another group needs access to an app then update that profile member with the needed application name."
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "3.\tTo check what is the profile currently being used by a user.\r\na.\tAdmin  1. Profile administration  view user profile (provide the user id)  select the user  select common  we can see the application list ID.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "5.\tTo add an application specific to a user.\r\na.\tAdmin  1. Profile administration  view user profile (provide the user id)  select the user  select sessions  then give L as a line command to one of the options and it would list all the applications that are available to be assigned to a user  then A to add the app to the users logon.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "6.\tWe need to do RESET on the command line when we do any changes to users profile."
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "7.\tSwap keys to jump between 2 open sessions.\r\na.\tAdmin  1. Profile administration  view user profile (provide the user id)  select the user  select trigger  Select an entry and provide the keys that you want to use for swapping between sessions and the  provide the DIALOG name as KLSNEXTS\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "8.\tUsers coming from LAN and have issue with logon to TSO in CL/SS.\r\na.\tThis happens as their logon IDs are different when logging onto supersession(specific to lfg the user might be using their LANID). We need to update their app TSO profile to use the userid and password that is valid for TSO and not the lan id.\r\nb.\tAdmin  1. Profile administration  view user profile (provide the user id)  select the user  select sessions  select the TSO session that is having issue  M to modify the session definition and in Userdata field provide LOGON  USERID/&vsspswd (&vsspswd is constant and usreid needs to be change to the TSO userid).\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "theory",
    "info": "There is no guarantee that a sequence of jobs submitted will run in the submitted order, lots of things affect how quickly a job goes through conversion and is then eligible for an initiator.\r\n\r\nTo do that, on JES3 you will have to set up a DJC network of these jobs.  See the //*NET JES3 control statement in the JCL Ref manual.\r\n\r\n//*NET statement \r\nPurpose: Use the //*NET statement to define the dependencies between jobs in a dependent job control (DJC) network. JES3 sets up a network of dependent jobs and executes them in a specific order. (Once set up, the structure of a DJC network cannot be changed unless all of the jobs in the network are resubmitted.) Jobs belonging to a DJC network cannot be registered with the automatic restart manager (ARM).\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "theory",
    "info": "JES3 2 JES2 difference with job selection.\r\nFirstly with JES3, the JCL Interpreter scans the JCL at submission time, unlike JES2 which scans the JCL at the time of execution. That means that if you submit 2 jobs at the same time, the second job requiring a dataset that is created in the first job, JES3 will cancel the second job immediately as the dataset does not exist. The exception to this is if the dataset is a +1 GDG. Since in our case the compile job is the one that creates the Object Deck for the second job to use, the file for the object deck will not exist until the compile has ended and we do not expect it to exist."
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "gtf trace-1",
    "info": "STEPS to get a GTF Trace.\r\n//GTFDATA PROC MEMBER=GTFPARM                                                 \r\n//IEFPROC EXEC PGM=AHLGTF,PARM='MODE=EXT,DEBUG=NO,TIME=YES',           *      \r\n//  TIME=1440,REGION=2880K                                                    \r\n//IEFRDER DD   DSNAME=USER.BUFFER2,UNIT=SYSDA,SPACE=(CYL,10),          *      \r\n//             DISP=(NEW,CATLG)                                               \r\n//SYSLIB  DD   DSNAME=USER.PARMLIB(&MEMBER),DISP=SHR                          \r\n//        PEND                                                                \r\n                                                                             \r\n\r\nNote:  When you start GTF use a suffix of the system, otherwise it will       \r\n  use the CUA number of the device that the trace file resides on which       \r\n  makes it difficult to stop. Ex:  S GTF.new                                  \r\n                                                                           \r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "gtf trace-2",
    "info": "1) Connect to the server with your client and stop at CLSS Main menu          \r\n\r\n2) Obtain the Telnet luname from panel KLGLGON1 or D TCPIP,Tn3270d,T,CONN,IPADDR=10.1.100.33                   \r\n\r\n3) Start GTF as follows:                                                      \r\n\r\n  S GTF.gtfname                              (can be up to 3 characters)      \r\n  nn AHL125A  RESPECIFY TRACE OPTIONS OR REPLY U                              \r\n  R nn,TRACE=USRP                                                             \r\n  IEE600I REPLY TO nn IS;TRACE=USRP                                           \r\n  TRACE=USRP                                                                  \r\n  nn AHL101A  SPECIFY TRACE EVENT KEYWORDS --USR=                             \r\n  R nn,USR=(FEF,FF1)                                                          \r\n  IEE600I REPLY TO 08 IS;USR=(FEF,FF1)                                        \r\n  USR=(FEF,FF1)                                                               \r\n  nn AHL102A  CONTINUE TRACE DEFINITION OR REPLY END                          \r\n  R nn,END                                                                    \r\n  IEE600I REPLY TO nn IS;END                                                  \r\n  END                                                                         \r\n\r\n4) Logon to target                                                            \r\n\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "network",
    "type": "gtf trace-3",
    "info": "5) On a different session Go into HelpDesk and select the userid              \r\n   to locate the CLSS virtual luname                                          \r\n\r\n6) Start VTAM Buffer traces                                                   \r\n   F NET,TRACE,TYPE=BUF,ID=telnet_luname,AMOUNT=FULL                          \r\n   F NET,TRACE,TYPE=BUF,ID=clss_virtluname,AMOUNT=FULL                        \r\n\r\n7) Recreate problem                                                           \r\n\r\n8) Capture a screen shot of the errant output if possible                     \r\n\r\n10) Disabling the traces                                                      \r\n    F NET,NOTRACE,TYPE=BUF,ID=telnet_luname                                   \r\n    F NET,NOTRACE,TYPE=BUF,ID=clss_virtluname                                 \r\n11) \r\nDo a D A,LIST\r\nto identify the device number for the STC that is started.\r\nP devicenumber to stop the GTF.                                                               \r\n\r\n12) Terse and FTP us the trace                          "
  },
  {
    "Vendor": "broadcom",
    "component/product": "Ca7",
    "type": "cleanup",
    "info": "Cleanup for LJOB,JOB=*,LIST=TRIG\r\nX ALL\r\nF '                              ' 1 all\r\nF '1LJOB,JOB=*' 1 all\r\nF 'JOB=*' 2 all\r\nF '----JCL----' 11 All\r\nF '-NAME-' 25 all\r\nDEL NX ALL"
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "F VTPGSP1,KLGCAPLT  -- refreshes the members where we have session for each group assinged. it is the member KLGCAPLT that has all the gorup profiles. the member is in **.RLSCMDS dataset."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "dump",
    "info": "D GRS,C\r\nD GRS,RES=(SYSZDRK,*)"
  },
  {
    "Vendor": "broadcom",
    "component/product": "DADSplus",
    "type": "thoery",
    "info": "CEMT I FILE   will only show files that have a FCT(File Control Table) entry.  If DBD002D1 does not have a FCT entry you will not see it using CEMT I FILE.\r\n...\r\nWhen you add the DBDNAME(DBD002D1) to DADS you tell DADS how to allocate the file to CICS at startup time as shown below. Attached to the CICS LOG is the DADSLOG that shows all the resources defined to DADS (files ,classes , DBDNAMES, ETC) allocated to CICS at startup time. Page 3-13 of the User's guide explains the DBD  allocation parameters as shown on the screen below.\r\nAPPLID XXXXXX               CA-DADS/PLUS  4.0  \r\n                            DBD DEFINITION ADD                                  \r\n     \r\n COMMAND  ===>  A                                                               \r\n                                                                                \r\n    TYPE  ===>  D   DBDNAME ===> DBDTEST            SCREEN 01 OF   02           \r\n                                                                                \r\n     DDNAME   DSNAME                                       DISP                 \r\n 1.  ________ ____________________________________________ ___                  \r\n 2.  ________ ____________________________________________ ___                  \r\n 3.  ________ ____________________________________________ ___                  \r\n 4.  ________ ____________________________________________ ___                  \r\n 5.  ________ ____________________________________________ ___                  \r\n                                                                                \r\n ALLOC/OPEN AT COLD START   ===> Y Y OPEN AFTER ONLINE ALLOC ===> Y             \r\n ALLOC/OPEN AT WARM START   ===> A Y EFFECTIVE DATE(YYYY/DDD) ===> 0000/000     \r\n ALLOC/OPEN AT EMER RESTART ===> A Y CURRENT STA DL1 OR DBCTL N/A               \r\n                                                                                \r\n LAST PROCESSED=                                                                \r\n                                                                                \r\n -------------------------------------------------------------------------------\r\n PF3-END    PF4-EXIT   PF6-CLASS  PF8-NEXT   PF9-TRAN   PF10-PROG  PF11-AUTO   \r\n\r\n.....\r\n\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "DADSplus",
    "type": "theory",
    "info": "In a DADS Batch interface jobs you can allocate and deallocate the DBDNAME. \r\n\r\nSee Chapter 12 of the User's Guide Batch Interface – Dynamic Allocation \r\n\r\nPage 12-23 and 12-24 shows the batch interface job parameters available for DBD names to run  DADS batch interface jobs.\r\n\r\n\r\n//SYSIN    DD *                          \r\nFUNCTION=DADS,APPLID=(YOUR APPLID,QUEUE)    \r\nREQUEST=(FUNCTION,TYPE,OPTION)  \r\n\r\nFunction\r\nA  Allocate a file, DBD, transient data queue or class. \r\nD  Close and deallocate the file, DBD, transient data queue or class. \r\n\r\nTYPE\r\nD  DBD\r\n\r\nDBD Options available\r\nD,R,S,G,E,A\r\n\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "notes",
    "info": "If you need to have Deliver insert DJDE's into it's output (i.e. OUT=Y) then you will in deed need to add the specific DJDE parameters and values for those parameters into a PRSET member, load the PRSET member to the database via execution of a RMODBASE PLOAD, and then link that specific PRSET member to the report on the CA Deliver - Report Definition Attributes screen via the \"PRSET  ===>\"  field.\r\nFor more information see:\r\nPrinter Setup Member\r\nDefine Banner Pages to Print on a Xerox 9700 Printer \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "security refresh",
    "info": "if any changes are made to the security of IzWS. we either have to recycle the task or issue the commands\r\nUse the modify command (F xxxx,P=GEN followed by F xxxx,S=GEN) to stop and restart the general service subtask.\r\n\r\nxxxx is the controller STC."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "security refresh",
    "info": "if we use any class other than IBMOPC to secure the resoruces, then we need to update the class names in RACF class descriptor and router table and reassemble the ICHFR02 ane ipl the system for the classes to be picked up."
  },
  {
    "Vendor": "broadcom",
    "component/product": "deliver/view",
    "type": "DJDE - PRSET",
    "info": "- If you want DJDE''s in your Deliver output AND the report data does not already have DJDE's in it (By way of embedded DJDE's by the application program OR by way of an OUTPUT DD statement in the jobs JCL), then you would be required to a create a PRSET member that contains the desired DJDE's, and link that PRSET member to the report via the Deliver Report definition attributes screen.\r\n- If the APPLICATION PROGRAM that creates the reports is embedding DJDE's into the report data before Deliver collect is, then those DJDE's will be carried through to the Deliver output, without the need for a PRSET member.\r\n- If DJDE's are being assigned to a report via an OUTPUT STATEMENT in the jobs JCL before it is collected by Deliver, then those DJDEs should be carried through to the Deliver output, without the need for a PRSET member.\r\n- If you send a report through Deliver that already has DJDE's in it when Deliver collects it  AND you create a PRSET member that assigns additional DJDE's, then the output from Deliver would likely contain all of the DJDE's from all sources.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "rexx",
    "type": "edit macros",
    "info": "we can write edit macros to do some repetitive tasks in PDS.\r\n\r\n/* REXX */\r\nISREDIT MACRO\r\nISREDIT \"F 'LJOB,JOB=*' 2 all\" and so on\r\nISREDIT \"DEL NX ALL\"\r\nISREDIT SAVE\r\n\r\nif we write this in a member MAC1 and save it to the SYSEXEC/SYSPROC concat and in a PDS emmber if we issue MAC1. it will execute the commands in the member."
  },
  {
    "Vendor": "ibm",
    "component/product": "rmm",
    "type": "ispf",
    "info": "REXX member to have\r\n/* REXX */\r\n\"EXEC 'SYS1.SEDGEXE1(EDGRMLIB)'\""
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "command",
    "info": "RESET -- after changes are done to the profile then the user needs to issue the command RESET so their active session is updated."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "theory",
    "info": "To determine the document (input) format of the report, XPAF use the following algorithm:\r\n\r\n•        Document Format Set by User Exit 02  (Yes, use specified format)\r\n\r\n•        PRMODE=PAGE  (Yes, AFP)\r\n•        First record CC = x’5A’ (Yes, AFP)\r\n•        PAGEDEF or FORMDEF (Yes, AFP)\r\n•        If not using XJCFSIM and CHARS Specified (Yes, AFP)\r\nIf none of the above match, the document is NOT AFP\r\n•        PRMODE=DJDE  (Yes, DJDE)\r\n•        DJDE in first record (Yes, DJDE)\r\n•        Any DJDE related Extended JCL Keywords  (Yes, DJDE)\r\nIf none of the above match, the document is not DJDE, and is the document format is set to LINE.\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "to update keys that can be used swap between the sessions.\r\nADMIN --> select profile --> select global --> triggers --> add a new key as F24,KLSNEXTS"
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "theory",
    "info": "to make CICS appl invocation ask for a userid and password. In the APPL definion add DIALOG NAME as LCICS. this would force the user to provide userid and password again when logging onto CICS."
  },
  {
    "Vendor": "ibm",
    "component/product": "tadz",
    "type": "common",
    "info": "Dump to chekc on what pgms the jobs are using and calling it.\r\n//STEP1 EXEC PGM=HSIZPEEK\r\n//STEPLIB DD DISP=SHR,DSN=\r\n//HSIZDATA DD DSN=xxxx.XX.XXX,DISP=(NEW,CATLG),UNIT=3390,SPACE=(CYL,(10,10),RLSE)\r\n\r\nWith this dump we can see job and the pgms they are using and the pgms they are calling."
  },
  {
    "Vendor": "ibm",
    "component/product": "fileaid",
    "type": "options",
    "info": "TSO XVJLOOK -- provides us with the list of options that are currently enabled in FILEAID.\r\nthe options are from CMSC parmlib poiting to FACM00 -- we can enable/disable Librarian/panvalet link for Fielaid."
  },
  {
    "Vendor": "Xerod",
    "component/product": "Xpaf",
    "type": "data type",
    "info": "Line Mode -- consist of only carriage control commands and data.\r\nDJDE -- Control statement the specify how a document should be printed on a centralized printer.\r\n     -- Code DJDEs direclty in a datastream or use an application to produce a data stream containing DJDE.\r\nXES  -- XES data streams contain printer command prefixed with user defined keys which dynamically change printers for                          \r\n        decentralized printers.\r\nPage formatted -- are line mode data streams that have been formatted using Xerox page format.\r\nAFP -- fixed or Variable length records, line mode data formatted using AFP JCL keywords\r\nVIPP\r\nOther(In pass-through mode) -- if the printer supports the printer command language of the data stream and the data is not structured.\r\nAPA -- APA Citation style of report formatting - 1 in margins all around, page numbers right-justified, heading centered etc."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "printer types",
    "info": "Centralized printers : are referred to as LCDS --> DJDE or metacode printers. Centralized printers are either connect directly through channel subsytem to the host or through TCP/IP\r\nPCL printers : \r\nPDF : web/email."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "theory",
    "info": "XPAF can convert Linemode, LCDS, XES and AFP to PDF documents and email them."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "theory",
    "info": "If a the actual printer does not support DUPLEX printing then XPAF does not do."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "theory",
    "info": "2 subsystems : XOAF - Xerox Output Administrative Facility\r\n               XOSF -- Xerox output services facility"
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "XOAF",
    "info": "Xerox output administrative facilit :\r\nManages resoruces needed for printing -- resoruces are fonts, images, forms or logos that are required.\r\nthe resource can be stored in the printer or a pds on the mainframe or inline in the data stream."
  },
  {
    "Vendor": "Xerox",
    "component/product": "xpaf",
    "type": "XOSF",
    "info": "Xerox output services facility : \r\ninterfaces: with zOS to accept documents for JES, convert them to the intended format for the sepcificed printer and transmit them.\r\nXOSF acts as a FSS to obtain the data from JES spool and maintain the control of printer\r\nDcoument processing : \r\nMetacode datastream consist of ASCII print records that include Carriage control commands for positioning, indexing and orientation.\r\nXES data : prefixed by a user defined key which signals the printer to recognize the character or character that follow.\r\nPDF DAta : PDF data streams for printing on PDF printers"
  },
  {
    "Vendor": "xerox",
    "component/product": "xpaf",
    "type": "xosf",
    "info": "if the data is not needed for conversion then XOSF sends the data stream direclty to the printer and is called as Native data after resource conditioning is complete.\r\n1. A PCL document can be sent directly to a PCL-Printer without XPAF altering the datastream.\r\n2. During DJDE document processing, XPAF uses extended JCL keywords to insert DJDE's.\r\n    -- for centralized printer no more processing. the print will have DJDE commands and the extended JCL keywords\r\n    -- if sent to PCL printer then XPAF converts the DJDE commands to XES commands and then XES to PCL commands\r\n    -- if sent to PDF printer then XPAF converts the DJDE commands to XES commands and then XES to PDF commands"
  },
  {
    "Vendor": "xerox",
    "component/product": "xpaf",
    "type": "xosf",
    "info": "3. XES reprots can be printed on PCL printers.\r\n--if sent to PCL printer then XPAF converts XES to PCL commands\r\n    -- if sent to PDF printer then XPAF converts XES to PDF commands"
  },
  {
    "Vendor": "xerox",
    "component/product": "xpaf",
    "type": "xosf",
    "info": "4. Page formatted data :\r\nif sent to centralized printer then XPAF converts the page format to metacode commands\r\nif sent to PCL then page format to XES and them XES to PCL commands\r\nif sent to PDF then page format to XES and then XES to PDF commands"
  },
  {
    "Vendor": "xerox",
    "component/product": "xpaf",
    "type": "xosf",
    "info": "5. Page formatted data :\r\nif sent to centralized printer then XPAF converts the AFP Commands to metacode commands\r\nif sent to PCL then AFP Commands to XES and them XES to PCL commands\r\nif sent to PDF then AFP commands to XES and then XES to PDF commands"
  },
  {
    "Vendor": "xerox",
    "component/product": "xpaf",
    "type": "xosf",
    "info": "6. For example,\r\nthe data stream for a PCL document does not require a print command conversion by XPAF before being sent to a PCL-capable printer. XPAF does not perform any conversion, conditioning, or validation on resources included in a pass-through document. All of the information required to print the document must be contained within the data stream because the data stream is sent directly to the printer without being altered."
  },
  {
    "Vendor": "xerox",
    "component/product": "xpaf",
    "type": "xosf",
    "info": "During XPAF processing, printer profile parameters override initialization parameters, and extended JCL keywords override initialization and/or printer parameters."
  },
  {
    "Vendor": "xerox",
    "component/product": "xpaf",
    "type": "xosf",
    "info": "use the command S XJCLPROC,P=DISPLAY to check if the extended JCL support is installed for XPAF. if the proc is not found then check for IPL log. and look for commands S XJCLPROC,P=LOAD / S XJCLPROC,P=INSTALL\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "jcl",
    "info": "JCL to pass parms in SYSIN while using IzWS\r\n//STEPSR  EXEC PGM=EQQEVPGM  \r\n//*%OPC SCAN                                                  \r\n//*%OPC SETVAR TRESNAME=TVAR                              \r\n//*                                                                                      \r\n//EQQMLIB DD DISP=SHR,DSN=OEM.TWS.SEQQMSG0.GSP1        \r\n//EQQMLOG DD SYSOUT=*                                  \r\n//SYSIN DD *                                           \r\nSRSTAT &TRESNAME. SUBSYS(TWPT) AVAIL(YES)\r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "SA+netview",
    "type": "update",
    "info": "Once we change any rules in SA+Netview, we either have to recycle the task or we need to refresh the cache\r\n%MEMSTOUT rulename"
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "update",
    "info": "if we have to update any applicaiton setup like the command it executes or Inital dailog and so on. Check the memver KLSCAPLS member of **.RLSCMDS dataset.\r\nOnce we update any application definiton issue the command\r\nF stcname,KLSCAPLS"
  },
  {
    "Vendor": "ibm",
    "component/product": "tws",
    "type": "Special resoruce ",
    "info": "if the usage value of the SR is USAGE(X) then it is a job that is in IzWS. if USAGE(S) then it is a logical resoruce that we are trying satisy for different use casesS"
  },
  {
    "Vendor": "broadcom",
    "component/product": "jcl check",
    "type": "theory",
    "info": "1. To see your current JCLCheck runtime options, it's best to run a batch JCLCheck job, and review the list of options from the JCLCheck SYSPRINT.\r\nExample:  \r\nDEFAULT  PARAMETERS: CTL FULL JOB LIST XREF PXREF(RPT)                          \r\nOPTS     PARAMETERS: AU CCLIST(999)                                             \r\nOPTIONS IN EFFECT: AUTOPROC() CSI CTLSCAN() HCD OPTIONS(OPTS) PROC(PROC00) CCLIST(999) FULLLIST JOB JOBSEV\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "jcl check",
    "type": "theory",
    "info": "2. JCLCheck can be customized to enforce an environment's standards and rules.  Rosa already mentioned these options in the previous updates: \r\n•\t The REXX interface.  This is activated by using runtime option STDREXX(rexxname).  This is the current and recommended method. \r\n•\t Job Control Standards (JCS).  This is the old method.  The rules are stored in a VSAM file (STDRULE DD), and must be compiled and linked into a JCLCheck module. This option is activated by using runtime option STANDARD(name).\r\n•\t Assembler exits.  This is activated by using runtime option DYN(exitname).\r\n•\t COBOL exits.  This is activated by using runtime option COB(exitname).\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "jcl check",
    "type": "theory",
    "info": ". The fact that you found VSAM file SYS2.JCLCHECK.STDRULE tells me that JCS (Job Control Standards) was set up.  If you did not see runtime option STANDARD(name) then JCS was not activated (i.e., not used).  In ISPF, runtime option STANDARD is set in the following panel: \r\n- JCKSPF panelid JCK0203\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "jcl check",
    "type": "theory",
    "info": "4. If you would like to see which standards/rules are set up in SYS2.JCLCHECK.STDRULE, then do the following in your ISPF session: \r\n    a. Edit CAZ2CLS0(JCKSTD) and change the ALLOC statement to: ALLOC FI(STDRULE) DA('SYS2.JCLCHECK.STDRULE') SHR REUS\r\n    b. Execute JCLCheck CLIST \"TSO JCKSTD\".  This allows you to see a list of defined STANDARD names. \r\n    c. Run the following job to display a STANDARD name: \r\n//STEP00  EXEC PGM=CAZ1RLST,PARM='your_standard_name'                   \r\n//STEPLIB  DD DISP=SHR,DSN=your.jclcheck.caz2load    \r\n//STDRULE  DD DISP=SHR,DSN=SYS2.JCLCHECK.STDRULE  \r\n//SYSPRINT DD SYSOUT=*                                        \r\n//SYSOUT   DD SYSOUT=*   \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "commands",
    "info": "TO start the izws without releasing any schedules   - need to chekc on the working\r\nS stcname,MANUAL\r\n\r\nto modify IzWS to run with scheduled when running in manual mode\r\nF stcname,AUTOSUBMIT=Y  / ASUTOSUBMIT=N to stop scheuled stops\r\n\r\nto release any job that is in HOLD status\r\nF stcname,RELEASE=jobname"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "theory",
    "info": "to start IzWS without any job submission.\r\nUpadate the parmlib option JOBSUBMIT to NO in JTOPTION section."
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA-7",
    "type": "theory",
    "info": "Update the pamrlib XXXXX.CA7.JCLLIB(ONLINER3) RUNOPT=(SCAN) to NSTA"
  },
  {
    "Vendor": "broadcom",
    "component/product": "ca-7",
    "type": "theory",
    "info": "to dispaly the CA7 optns. issue the command F ca7stc,Display options"
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA-11",
    "type": "theory",
    "info": "to dispaly the CA-11 optns. issue the command F ca11,Display options"
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "import",
    "info": "Issue while importing an application into IzWS.\r\nthe error message EQQX274E is not given by WAPL but it is due to a \r\n\r\nfailure in writing on the AD VSAM file.\r\nFollowing is the description of the error:\r\nEQQX274E\r\nAN I/O REQUEST SPECIFIES TOO LARGE RECORD SIZE\r\nExplanation: The request to create or modify a record resulted in the record exceeding the maximum size of the VSAM\r\nrecord.\r\nSystem action: The request is rejected.\r\nSystem programmer response: Check the record size against the VSAM file definition. For more information, refer to the\r\nPlanning and Installation\r\nUser response: Contact your system programmer.\r\nThere is a technote on this that you can find at this link:\r\nhttps://www.ibm.com/support/pages/eqqx274e-eqqx300e-when-creating-or-modifying-twsz-application\r\n\r\nThe only thing that customer can do in order to fit the big application in the AD is to \r\nallocate the AD VSAM file with a bigger MAXRECL.\r\nThe one allocated with the installation job (EQQPCS01) has following size specified: 131072\r\nA bigger value can be specified, if needed. After having allocated a new AD file, the content of the old one must be copied in the new one, and a restart of the controller is needed.\r\n\r\nIf the questions is: how much enlarge the MAXRECL? in the Installation and Planning manual there is a section that explain how long is each section of an AD record (Table 26. Calculations of VSAM data set size). A manual calculation should be done by customer basing on his application definition OR simply double the value given the EQQPCS01 sample \r\nand retry.\r\n\r\nI suggest also to customer to check if Apar APAR= PH56087 . ABEND S0C4 OCCURS IN EQQYTOPX ADDING AN OCCURENCE TO THE CP\r\n\r\n\r\n\r\nis applied in his environment (PTF for 10.1 is UI94505) in order to avoid a 0C4 abend \r\n\r\nin EQQYTOPX running such scenario.\r\n\r\nI hope these info helps"
  },
  {
    "Vendor": "xerox",
    "component/product": "xpaf",
    "type": "JDL",
    "info": "XPAF uses JDL command while convering AFP to PCL.\r\nthese commands have a source code called as JSL.\r\n\r\ngenerally the source code is in **.JSL.PDS library. we can find member with the JDL command names"
  },
  {
    "Vendor": "ibm",
    "component/product": "CL/SS ",
    "type": "commands",
    "info": "/F taskname,NTD KLSSOPTS '??' -- lists all teh active options\r\n/f taskname,NTD KLSTSDLG\r\n/f taskname,flush\r\n\r\nuse the command /f taskname,NTD KLSSOPTS 'xxxxxx' -- we can change the KLSSTART otpions used during the start up."
  },
  {
    "Vendor": "ibm",
    "component/product": "izws",
    "type": "dump",
    "info": "IzWS Database dump\r\n\r\nthe below job dumps all the applicaitons startign with APP*\r\n\r\n\r\n//MYJCLLIB JCLLIB ORDER=OEM.TWS.INSTALL.JCL.GSP1                        \r\n//PIFSTEP EXEC EQQYXJPX,                                                \r\n// SUBSYS=TWPC                                                          \r\n//OUTDATA  DD SYSOUT=*,LRECL=4096                                       \r\n//OUTBL DD DSN=OEM.TWS.APPL.DB.BACKUP(+1),                              \r\n// DISP=(NEW,CATLG,DELETE),                                             \r\n// SPACE=(TRK,(50,50),RLSE),                                            \r\n// DCB=OEM.TWS.TWCT.DEVOP.LIST.ALLAPP.BKOCT02                           \r\n//*---------------------------------------------                        \r\n//SYSIN DD *                                                            \r\nOPTIONS STRIP(Y) EXPAND(N) SELECT(Y)                                    \r\nLOADDEF AD* DATA(-)                                                     \r\nLIST ADCOM ADID(APP*)                                                   \r\n/*                                                                      \r\n"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "plugins",
    "info": "https://ibm.biz/zOSMFPortfolio -- single location to identify all the plugins that are currently available for zOSMF"
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "Parmlib management",
    "info": "REST API  URL :\r\nhttps://zosmfHost:zosmfPort/zosmf/parmlib/v1/LOAD/Validate?deep=true -- validates all the active parmlib syntaxes\r\nhttps://zosmfhost:zosmfport/zosmf/parmlib/BPXPRM/Validate -- validates all the BPXPRMxx parmlib available in the sytems and letus us know the active BPXPRMxx parmlib\r\nhttps://zosmfhost:zosmfport/zosmf/parmlib/BPXPRM/validate?member=BPXPRMA4,DATASET=SYS1.PRMLIB.ZOSB -- Validate the BPXPRMA4 parmlib for any syntax issues.\r\n\r\nAll the options will let us know What could be the error and What update might help us to resolve the issue."
  },
  {
    "Vendor": "ibm",
    "component/product": "zosmf",
    "type": "rest api",
    "info": "1. Open the desktop UI for zoSMF\r\n2. select : reference center ICON\r\n3. double click : zOSMF rest API ICON : Open AI document for all the REST API's available for zOSMF\r\n4. Expand the API that you would like to use and fill the options and run  it. "
  },
  {
    "Vendor": "ibm",
    "component/product": "zOAU",
    "type": "Theory",
    "info": "IBM Z Open Automation Utilities (ZOAU) is a runtime for interacting with MVS facilities and automating tasks on z/OS via UNIX shell commands or modern scripting languages."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOAU",
    "type": "Theory",
    "info": "z/OS dataset Manipulation --  access datasets. ALlocate, delete, edit\r\nz/OS job management -- start and manage jobs. Submit/cancel/list job/list dd\r\nz/OS cosole -- Display the console log (last 1 min, 1 hr and so on). Issue a console command\r\nz/OS APF -- we can list/update APF dataset list."
  },
  {
    "Vendor": "ibm",
    "component/product": "zOS",
    "type": "sending data",
    "info": "FTP -- REgular ftp to send the data in a unsecured format.\r\nSFTP -- Open SSH secured file transfer using encrypted SSH tansport\r\n "
  },
  {
    "Vendor": "ibm ",
    "component/product": "izws",
    "type": "Dump",
    "info": "STC dump when IzWS stuck...\r\nBefore any actions and recycle  \r\n\r\n\r\n1)  please take two console dump, \r\ncaught a few minutes (3 minutes) away from each other)  \r\nthis is an example of the slip \r\n\r\nDUMP COMM=(reason for taking dump)\r\nR xx,JOBNAME=(ZZZZ),CONT \r\nR xx,SDATA=(COUPLE,ALLNUC,LPA,LSQA,PSA,RGN,SQA,TRT,CSA,GRSQ,XESDATA,WLM),END\r\nwhere:\r\n\r\nxx Specify the replay number ID.\r\nZZZZ Specify the name of the controller. \r\n\r\n2) GRS commands to show if there is some ENQ condition:  \r\nD GRS,C   and D GRS,RES(SYSZDRK,*).ALSO check if there are any CP batch jobs running\r\n\r\n3) APARTAPE  it will be required before a restarting  IzWS  task\r\n\r\n4) system log (syslog)"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "report",
    "info": "to product a report with the no. of days left for online and tape. \r\n/CONTROL DATABASE= your VIEW db hlq  \r\n         RULER=YES                       \r\n/TITLE 'Listing of Sysout retention'     \r\n/                                        \r\n/SORT ARCHDATE-D                         \r\n/   PRINT ID       'ID'                  \r\n/   PRINT EDIT(GEN,'ZZZZ9') '  GEN'      \r\n/   PRINT EDIT(SEQ,'ZZZZ9') '  SEQ'      \r\n/   PRINT ARCHDATE 'ARCH DATE'           \r\n/   PRINT DRETPD   'DISK DAYS'           \r\n/   PRINT TRETPD   'TAPE DAYS'           \r\n/   PRINT TGENS    'Remain TGEN'         \r\n/   PRINT DGENS    'Remain DGEN'         \r\n/   PRINT EROID    'ERO ID'              \r\n/   END                                  \r\n/END     \r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "optimier",
    "type": "report",
    "info": "if we want to know which modules are compiled using optimizer then \r\n//MRS EXEC pGM=CAOUMRS\r\n//STEPLIB DD DISP=SHR,DSN=CCS load lib and lpalib\r\n//SYSLIB DD DISP=SHR,DSN=user program loadlib\r\n//SYPRINT DD SYSOUT=*"
  },
  {
    "Vendor": "ibm",
    "component/product": "zos",
    "type": "autoipl",
    "info": "AutoIPL can re-IPL z/OS®, or take a stand alone dump (SADMP), or take a SADMP and have SADMP re-IPL z/OS when it has finished. The desired actions are represented in an AutoIPL policy, which you state in a DIAGxx parmlib member that the system checks at wait state time."
  },
  {
    "Vendor": "ibm",
    "component/product": "ispf",
    "type": "SAVE list",
    "info": "We can use the command SAVE xxxx on any 3.4 dataset list or inside a PDS to save the DATASET Names and the Dataset attributes into Userid.xxxx.Datasets or Userid.xxxxx.Members"
  },
  {
    "Vendor": "ibm",
    "component/product": "utility",
    "type": "Idcams",
    "info": "IDCAMS utility to rename pS/PDS datasets\r\n//STEP1 EXEC PGM=IDCMAS\r\n//SYSPRINT DD SYSOUT=*\r\n//SYSIn DD *\r\nALTER 'old.name' -\r\nNEWNAME ('new.name')"
  },
  {
    "Vendor": "broadcom",
    "component/product": "librarian",
    "type": "copy - JOb",
    "info": "Copying a librarian source member to a PDS\r\n//LIBRSTP1 EXEC PGM=AFOLIBR,PARM='NRJS,NJTA'   \r\n//SYSPRINT DD  SYSOUT=*                                    \r\n//MASTER   DD  DISP=SHR,DSN=hlq.mlq.your.MASTER  \r\n//OSJOB    DD  DSN=hlq.mlq.LIBR.OSJOB,             \r\n//         DISP=(NEW,CATLG,DELETE),                        \r\n//         SPACE=(CLY,(10,1),RLSE),                        \r\n//         DCB=(RECFM=FB,LRECL=80,BLKSIZE=80),             \r\n//         VOL=SER=(vvvvvv)                                \r\n//SYSIN    DD  *                                           \r\n-OPT GPO                                                   \r\n-SEL NAME=,EXEC(R),TEMP,NOCHK     \r\n-END                                                       \r\n/*                                                         \r\n/* --------------------------------------------------------\r\n//LIBRSTP2 EXEC PGM=AFOLIBR,PARM='NRJS,NJTA'               \r\n//SYSPRINT DD  SYSOUT=*                                    \r\n//INDEX    DD  SYSOUT=*                                    \r\n//LIST     DD  SYSOUT=*                       \r\n//OSJOB    DD  DISP=SHR,DSN=hlq.mlq.THEPDS.or.PDSE      \r\n//MASTER   DD  DISP=SHR,DSN=hlq.mlq.your.MASTER  \r\n//SYSIN    DD  DISP=SHR,DSN=hlq.mlq.LIBR.OSJOB     \r\n/*"
  },
  {
    "Vendor": "broadcom",
    "component/product": "librarian",
    "type": "REXX",
    "info": "Rexx to copy a Librarian source member to PDS\r\naddress TSO                                                 \r\nx = outtrap('alloc.')                                       \r\n/* Specify the member to copy/extract */                     \r\nsin.1 = '-SEL 'memb',EXEC(R)'                               \r\n/* Now allocate SYSIN as a temporary file .... */           \r\n\"alloc f(sysin) unit(vio) new sp(1 1) block(1)\",             \r\n   \"recfm(f b) lrecl(80) reuse\"                             \r\n\"execio 1 diskw sysin (stem sin. finis\"                     \r\n/* but DON'T free it */                                     \r\n                                                             \r\n/* Allocate the output file */                               \r\n\"alloc f(OSJOB) da('\"temp_ds\"')  shr reuse\"                 \r\n/* ... and the LIBRARIAN \"PDS\" */                           \r\n\"alloc f(MASTER) da('\"pds_name\"') shr reuse\"                 \r\n                                                             \r\n\"alloc file(sysprint) dummy shr reuse\"                                 \r\n                                                             \r\n/* Call LIBRARIAN to extract the file */                     \r\naddress ispexec \"select pgm(AFOLIBR) parm('NRJS,NJTA')\"     \r\nsave_rc = rc                                                 \r\n\"free f(SYSIN SYSPRINT MASTER OSJOB)\"                       \r\nx = outtrap('OFF') "
  },
  {
    "Vendor": "ibm",
    "component/product": "CBAC",
    "type": "TSQ",
    "info": "Some cics regions may have coded a pgm to remove TSQ.\r\nCBAC needs TSQ and it will fail if it TSQ is removed.\r\n\r\ndefine a fully generic TSModel with PREFIX(+) specifying the desired EXPIRYINTMIN.  "
  },
  {
    "Vendor": "ibm",
    "component/product": "IzWS",
    "type": "Include statement",
    "info": "TO create a job that woul run different steps with different SCHID's in IzWS. We need to use INCLUDE or EXCLUDE based on the need.\r\n//JOBCARD\r\n//*%OPC SCAN\r\n//*%OPC BEGIN ACTION=INCLUDE/EXCLUDE\r\n//*%OPC COMP=(&OADID..EQ.(APP#ABC#001,APP#ABC#002)\r\n//step1 exec\r\n//\r\n//*%OPC END ACTION=INCLUDE/EXCLUDE\r\n\r\nNOTE : Please ensure the COMP statement when &OADID is expanded in not crossing the  71 chr in the row. we can continue in next line if we have more APP#xxx#YYY to be added.\r\n\r\nthe above will run the steps only when it is executing in APPLID APP#ABC#001 or APP#ABC002.\r\n\r\nthis is equivalent to #JI, #JO in CA-7"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "retention period",
    "info": "View/deliver retetion period are maintained a datset SARPTAB DD. We can dump the EROID for each report from View and compare that with the SARPTAB DD output to check for retention days"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "data",
    "info": "When the report from View/Deliver is sent to CMOD or any other printer location. we need to have the FORM / FONT /  IMAGE files available. they can be at the CMOD location or on mainframe."
  },
  {
    "Vendor": "Xerox",
    "component/product": "XPAf",
    "type": "image/font/form",
    "info": "The image/font/form members are provided as PDS libraries and they are loaded into PDS during the installation."
  },
  {
    "Vendor": "broadcom",
    "component/product": "CA-7",
    "type": "theory",
    "info": "JCL search order in CA-7 for execution.\r\n\r\nEvery job by defintion will have JCL ID tagged. In CA-7 all JCL's PDS are tagged with an ID. you can also have an ALT ID defined for each of the JCL PDS IDS so CA-7 would look into the ALT ID agagint the JCL PDS before picking up a jcl for execution."
  },
  {
    "Vendor": "broadcom",
    "component/product": "sysview",
    "type": "security",
    "info": "batch job to dump SYSVIEW security : check the STATUS command to identify the LOAD, GSVXSCFG, CNM4BSEC datasets\r\n//step1 exec pgm=GSVXSECL\r\n//steplib dd \r\n//gsvxscfg dd\r\n//CNM4BSEC DD\r\n//sysprint dd sysout=*"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "report",
    "info": "//STEP0010 EXEC PGM=RMOGRW                                    \r\n//STEPLIB DD DSN=HLQ.CADLVR.CVDELOAD.PROD.GSP1,DISP=SHR      \r\n//        DD DSN=HLQ.CAVIEW.CVDELOAD.PROD.GSP1,DISP=SHR      \r\n//SYSOUT   DD SYSOUT=*                                        \r\n//SYSPRINT DD SYSOUT=*                                        \r\n//PRTFILE DD SYSOUT=*                                         \r\n//SYSIN    DD *                                               \r\n/CONTROL SEQ=RID DATABASE=deliver DB NAME\r\n/DEFINE RIDHOLD CHAR(32)                                      \r\n/IF HRDATE > 0                                                \r\n/IF RID NE RIDHOLD                                            \r\n/PRINT RID 'REPORT ID' COL(1)                                 \r\n/PRINT HRJOB 'JOBNAME' COL(33)                                \r\n/PRINT HRJID 'JOB ID' COL(42)                                 \r\n/PRINT HRDATE 'LST RUN DT' COL(51)                            \r\n/PRINT HRTIME 'LST RUN TM' COL(62)                            \r\n/SET RIDHOLD = RID                                            \r\n/END                                                          \r\n/END\r\n/END\r\n"
  },
  {
    "Vendor": "IBM",
    "component/product": "RACF",
    "type": "Conversion ",
    "info": "When we are moving from TSS to RACF. the syslog dataset when backedup will have the owner as SYSLOG.*BYPASS* .. RACF will not have have the *BYPASS* profile. RACF will only look for +MASTER+ as the owner for SYSLOG. IN JES3 the global systme is having the owner as *BYPASS*"
  },
  {
    "Vendor": "ibm",
    "component/product": "RACF",
    "type": "error",
    "info": "ICH408I is the message to look for any errors for RACF."
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "JOBCLSL",
    "info": "THe JOBCLSL parm in Deliver will let deliver know which JOB classes to monitor for the outputs to be captured.\r\nthe SYSCLSL parm will let deliver the class that are to be captured and archived"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "ARCH parm",
    "info": "ARCH parm in deliver report definition\r\n0 indicates no archival to be done to the view\r\n1 archive and \r\nblank default archive criteria specified in the initialization parms"
  },
  {
    "Vendor": "ome - Tone",
    "component/product": "fileaid",
    "type": "trace ",
    "info": "We can issue teh command \"SET TRACE ON\" on the main panel to get the trace of any errors\r\n\"SET TRACE OFF\""
  },
  {
    "Vendor": "Xerox",
    "component/product": "XPAf",
    "type": "thoery",
    "info": "the default PAGEDEF/FORMDEF that are used with each XPAF task are mentioned in the PARMLIB. we need to add F1 to the default FORMDEF and P1 to PAGEDEF to the default to get their names"
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "Banner",
    "info": "Each report defined to Deliver will have BANNER added. it is a text page that gets appended as first page in the report.FI the report definition does not have a banner then a default BANNER is added to the report. we can chekc the default report defined by displaying the options of the deliver STC. F deliverstc,DISPLAY. Look for BANNER parm.                                  if you want to check the content of any BANNER logon deliver and issue the cmmand \"DISPLAY\" and look for B option to list the defined BANNER and select a specific banner to check the content."
  },
  {
    "Vendor": "broadcom",
    "component/product": "view/deliver",
    "type": "banner/prset",
    "info": "//STEP1 EXEC PGM=RMODBASE\r\n//STEPLIB DD \r\n//SYSPRINT DD\r\n//RMOUNLD DD \r\n//SYSIN DD *\r\nNAME deliver db name\r\nUNLOAD\r\n/*"
  },
  {
    "Vendor": "ibm",
    "component/product": "jes3",
    "type": "NJE",
    "info": "when using JES3 NJE to route jobs between nodes\r\nthe default USERID to be used for submitting jobs in the nodes is setup in SETROPS of RACF"
  },
  {
    "Vendor": "ibm",
    "component/product": "git dbb",
    "type": "setup",
    "info": "https://community.ibm.com/community/user/blogs/mathieu-dalbin/2025/07/11/optimize-your-gitlab-infrastructure-with-the-zos-n"
  },
  {
    "Vendor": "ibm",
    "component/product": "explorer",
    "type": "theory",
    "info": "Has the following options\r\nIBM Explorer for zOS\r\nCICS explorer / Tools\r\nIMS enterprise suite explorer for development\r\nRational team concert\r\nWebsphere MQ explorer"
  },
  {
    "Vendor": "ibm",
    "component/product": "explorer",
    "type": "theory",
    "info": "Remote system explorer -- 2 task needs to run on mainframe -- RSED(Remote system explorer demon. provides connectivty tot eh remote systems explorer prespective to a zOS system, helps in accessing the zOS datasets and unix files). and JMON(Jes job monitor server to provide info. on jobs)"
  },
  {
    "Vendor": "ibm",
    "component/product": "explorer",
    "type": "theory",
    "info": "The tool is installed in your local system. To connect to a mainframe, we need to chekc the HOST connection and add a sytem to the list. once we provide the IP and other details and conect we will be able to see 5 line items unnder the new HOST name in the Remote SYstems VIEW seciton. (zOS unix fies, zOS Unix shells, MVS files, TSO commands, JES)"
  },
  {
    "Vendor": "ibm",
    "component/product": "explorer",
    "type": "theory",
    "info": "To access to the connected Host is either through FTP(view jobs and output) or zOSMF(view jobs and output and cancel it) and remote system"
  },
  {
    "Vendor": "ibm",
    "component/product": "explorer",
    "type": "theory",
    "info": "We can create Sequential file / PDS and VSAM file. We can compare teh files. we can also compare the job outputs."
  },
  {
    "Vendor": "ibm",
    "component/product": "explorer",
    "type": "theory",
    "info": "Launching the remote shell session we can issue TSO and UNIX commands"
  },
  {
    "Vendor": "ibm",
    "component/product": "explorer",
    "type": "theory",
    "info": "In remote systems view we can access JES JOBS and do the following actions :\r\nHOLS, CANCEL, Purge, Release, ShoewJCL(SJ) and resubmit"
  },
  {
    "Vendor": "ibm",
    "component/product": "CBAC",
    "type": "Theory",
    "info": "IBM CBAC doesn’t have the panel options like DADS and all allocation/Deallocation should be done via batch job only.           KBKM is IBM CBAC transaction, when you enter ityou will be able to see the Status of CBAC,if its active in the region,when it was started.\r\n\r\nYou can start/stop CBAC via KBKM START and KBKM STOP commands.\r\n"
  },
  {
    "Vendor": "broadcom",
    "component/product": "DADSplus",
    "type": "Theory",
    "info": "DADS/DADA/DADB/DADC transactions \r\nDADS has panel options in CICS regions"
  },
  {
    "Vendor": "ibm",
    "component/product": "omegamon",
    "type": "security",
    "info": "For Omegamon for CICS,we are currently using internal security(ie) with the Omegamon product there are security members where we mention the level of passwords to be used for each command and no external security exits/routines for RACF or Top Secret are being used."
  },
  {
    "Vendor": "ibm",
    "component/product": "CBAC",
    "type": "security",
    "info": "For IBM CBAC there are no constraints with security.User who can login to CICS will be able to issue KBKM transaction to Start/Stop CBAC.Otherwise there is no security setup done for this product."
  },
  {
    "Vendor": "ibm",
    "component/product": "IzWS",
    "type": "dump",
    "info": "ETT trigger definition dump\r\n//JOBCARD\r\n//MYJCLLIB JCLLIB ORDER=\r\n//PIFSTEP EXEC EQQYXJPX,SUBSYS=tws sub system\r\n//OUTDATA DD SYSOUT=*\r\n//OUTBL DD SYSOUT=*\r\n//SYSIN DD *\r\nOPTIONS STRIP(Y) EXPAND(N) SELECT(Y)\r\nLAODDEF * \r\nLIST ETT "
  }
]
